{
  "base_url": "https://lark-parser.readthedocs.io/en/stable/",
  "mapped_urls": [
    "https://lark-parser.readthedocs.io/en/stable",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html",
    "https://lark-parser.readthedocs.io/en/stable/_static/lark_cheatsheet.pdf",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html",
    "https://lark-parser.readthedocs.io/en/stable/forest.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html",
    "https://lark-parser.readthedocs.io/en/stable/how_to_use.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/47174f1088585b541b7296c461639c79/eval_csv.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/2cc75b757e7515472722c8c02d4fe4e4/error_reporting_lalr.py",
    "https://lark-parser.readthedocs.io/en/stable/classes.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/7cc2abf4fecd3796ed4ad6d455bda349/indented_tree.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/347194332333371dddab71778db00fd5/py3to2.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/179842700c93c6cca88ed33e1b99eb9c/json_parser.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9e5ca2d2f34acae5a9391bd4b16a935f/conf_lalr.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/3933bf173c425fd28a9c4d7c72b8eca1/python_parser.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9056f9d3440746d8fe151c31173e18e6/qscintilla_json.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/3ed7cc698fc366fe253eac6ecf76ee3e/conf_lalr.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/207f80f4ec59e1e363837373665f649f/turtle_dsl.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/59e28e5e93b13914beea3268d124ef92/eval_json.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/grammar.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/57b38708c982e98764460c3e288a1ff5/reconstruct_python.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/bfeb22cff3ae6c24841aad8c5a95d047/create_ast.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9d7d9d95319f4514ab7247f8eb86ddf0/tree_forest_transformer.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/98afe2f1c3b9485fcb8bdeebbbf0234f/main.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/calc.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/63680f346bf793a45964b4e687bde3d9/calc.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/b9abd703bb1b061d8ae5f6ab1b9393e8/lark_grammar.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/1e229dcdb521be752d4349e61ead59d1/qscintilla_json.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/f034a71a096a9049dcf409ec85c36943/conf_earley.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/composition",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/6dea8dbfb244508aaa3b8283470f8c2d/prioritizer.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/index.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/b0239cee17ba033b2ccfffe66491b86e/fruitflies.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/5811ce5e933efd9af1ae8e52d16a3a4f/custom_lexer.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/3a11fd47a1fb670a6759747d618a244e/error_handling.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/adf07a4514e9cfb278aef018e6994028/reconstruct_json.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/60290154124d6b16926446036bb711d6/python_parser.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/11091a0f6990e281219479476971fa12/eval_json.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/3b0766c1f76ff2904339853615cf4943/reconstruct_python.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/7279f5d640bfe9814468a2adf38516d5/error_reporting_lalr.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/222c07e0396620c7fabb1da7fda69ca9/json_parser_main.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/4667ab58050962ac05455b953c59244f/custom_lexer.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html",
    "https://lark-parser.readthedocs.io/en/stable/philosophy.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/6619e43bab1bed7430fa709940e67aa2/templates.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/how_to_develop.html",
    "https://lark-parser.readthedocs.io/en/stable/tools.html",
    "https://lark-parser.readthedocs.io/en/stable/json_tutorial.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/c1123c2587eda70bc64752df00c577b1/py3to2.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9cadc23f6b1e9e52f35d3cb0a28053b0/turtle_dsl.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9edfb38ad3bc19fc2b92c728275b9008/main.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9ebc86868010e2fc400ecf1ef8a5aa4a/fruitflies.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html",
    "https://lark-parser.readthedocs.io/en/stable/parsers.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/2f68c21f7729a47e57d3ae345753e407/lark_grammar.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/ca074bdcc9170e436dcd2f779e4a4285/error_reporting_earley.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/3c07a7adfbea6387847af2b079a58ed6/prioritizer.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/de026e34f2e30342f31740044e683d7b/eval_csv.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/1bc3cb4e14f2c898c0bf16247304d5b2/conf_earley.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/ee39a682704904d3f08f1d957831c955/_json_parser.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/fc674523e7ef0712dfc331b1ddd10972/dynamic_complete.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/50b59008a60a728670b293084a6fe042/calc.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/4b6a9b4fb62278f5d7a70e5b2900ff58/indented_tree.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/visitors.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/5a9e0a0dc353e4a9357e2204639f6c76/error_handling.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/55c526745700131cb7096e508b392be7/json_parser_main.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/08132b45db8ea39c7a8efd8acc048de2/create_ast.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/6d1927842b20958cbf08c916e786d2d0/_json_parser.py",
    "https://lark-parser.readthedocs.io/en/stable/tree_construction.html",
    "https://lark-parser.readthedocs.io/en/stable/features.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/9897e3d2b4b242b1ded5769f50c0eea1/json_parser.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/22081051f999d4e0753796b91b344ee3/dynamic_complete.py",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/2d7086e8ce7628b916237820c20847e4/tree_forest_transformer.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html",
    "https://lark-parser.readthedocs.io/en/stable/recipes.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/d3b43c711b7f9a6aeee99f79cf861539/templates.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html",
    "https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/bdb62f1189ee436f5378982a91ecc1cf/error_reporting_earley.ipynb",
    "https://lark-parser.readthedocs.io/en/stable/_downloads/e6911b819cf4afa1ca68b5be22630e13/reconstruct_json.py",
    "https://lark-parser.readthedocs.io/en/stable/examples/standalone"
  ],
  "scraped_documents": [
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Standalone example\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/standalone/index.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html \"Example Grammars\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html \"Standalone Parser\")\n\n* * *\n\n# Standalone example [](https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html\\#standalone-example \"Permalink to this heading\")\n\nTo initialize, cd to this folder, and run:\n\n```\n./create_standalone.sh\n\n```\n\nOr:\n\n```\npython -m lark.tools.standalone json.lark > json_parser.py\n\n```\n\nThen run using:\n\n```\npython json_parser_main.py <path-to.json>\n\n```\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_json_parser_main_thumb.png)\n\n[Standalone Parser](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html#sphx-glr-examples-standalone-json-parser-main-py)\n\nStandalone Parser\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/standalone/)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/standalone/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Standalone example — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone",
        "status_code": 200,
        "scrape_id": "aa7edc80-c97f-4409-9196-0211d8afa452",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.263Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/e6911b819cf4afa1ca68b5be22630e13/reconstruct_json.py",
      "markdown": "```\n\"\"\"\nReconstruct a JSON\n==================\n\nDemonstrates the experimental text-reconstruction feature\n\nThe Reconstructor takes a parse tree (already filtered from punctuation, of course),\nand reconstructs it into correct text, that can be parsed correctly.\nIt can be useful for creating \"hooks\" to alter data before handing it to other parsers. You can also use it to generate samples from scratch.\n\"\"\"\n\nimport json\n\nfrom lark import Lark\nfrom lark.reconstruct import Reconstructor\n\nfrom _json_parser import json_grammar\n\ntest_json = '''\n    {\n        \"empty_object\" : {},\n        \"empty_array\"  : [],\n        \"booleans\"     : { \"YES\" : true, \"NO\" : false },\n        \"numbers\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\n        \"strings\"      : [ \"This\", [ \"And\" , \"That\", \"And a \\\\\"b\" ] ],\n        \"nothing\"      : null\n    }\n'''\n\ndef test_earley():\n\n    json_parser = Lark(json_grammar, maybe_placeholders=False)\n    tree = json_parser.parse(test_json)\n\n    new_json = Reconstructor(json_parser).reconstruct(tree)\n    print (new_json)\n    print (json.loads(new_json) == json.loads(test_json))\n\ndef test_lalr():\n\n    json_parser = Lark(json_grammar, parser='lalr', maybe_placeholders=False)\n    tree = json_parser.parse(test_json)\n\n    new_json = Reconstructor(json_parser).reconstruct(tree)\n    print (new_json)\n    print (json.loads(new_json) == json.loads(test_json))\n\ntest_earley()\ntest_lalr()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/e6911b819cf4afa1ca68b5be22630e13/reconstruct_json.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/e6911b819cf4afa1ca68b5be22630e13/reconstruct_json.py",
        "status_code": 200,
        "scrape_id": "23b5a8f5-09a1-427d-a8bc-d6778f4d6ffd",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/c1123c2587eda70bc64752df00c577b1/py3to2.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Python 3 to Python 2 converter (tree templates)\\n\\nThis example demonstrates how to translate between two trees using tree templates.\\nIt parses Python 3, translates it to a Python 2 AST, and then outputs the result as Python 2 code.\\n\\nUses reconstruct_python.py for generating the final Python 2 code.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\nfrom lark.tree_templates import TemplateConf, TemplateTranslator\\n\\nfrom lark.indenter import PythonIndenter\\nfrom reconstruct_python import PythonReconstructor\\n\\n\\n#\\n# 1. Define a Python parser that also accepts template vars in the code (in the form of $var)\\n#\\nTEMPLATED_PYTHON = r\\\"\\\"\\\"\\n%import python (single_input, file_input, eval_input, atom, var, stmt, expr, testlist_star_expr, _NEWLINE, _INDENT, _DEDENT, COMMENT, NAME)\\n\\n%extend atom: TEMPLATE_NAME -> var\\n\\nTEMPLATE_NAME: \\\"$\\\" NAME\\n\\n?template_start: (stmt | testlist_star_expr _NEWLINE)\\n\\n%ignore /[\\\\t \\\\f]+/          // WS\\n%ignore /\\\\\\\\[\\\\t \\\\f]*\\\\r?\\\\n/   // LINE_CONT\\n%ignore COMMENT\\n\\\"\\\"\\\"\\n\\nparser = Lark(TEMPLATED_PYTHON, parser='lalr', start=['single_input', 'file_input', 'eval_input', 'template_start'], postlex=PythonIndenter(), maybe_placeholders=False)\\n\\n\\ndef parse_template(s):\\n    return parser.parse(s + '\\\\n', start='template_start')\\n\\ndef parse_code(s):\\n    return parser.parse(s + '\\\\n', start='file_input')\\n\\n\\n#\\n# 2. Define translations using templates (each template code is parsed to a template tree)\\n#\\n\\npytemplate = TemplateConf(parse=parse_template)\\n\\ntranslations_3to2 = {\\n    'yield from $a':\\n\\t    'for _tmp in $a: yield _tmp',\\n\\n    'raise $e from $x':\\n    \\t'raise $e',\\n\\n    '$a / $b':\\n\\t    'float($a) / $b',\\n}\\ntranslations_3to2 = {pytemplate(k): pytemplate(v) for k, v in translations_3to2.items()}\\n\\n#\\n# 3. Translate and reconstruct Python 3 code into valid Python 2 code\\n#\\n\\npython_reconstruct = PythonReconstructor(parser)\\n\\ndef translate_py3to2(code):\\n\\ttree = parse_code(code)\\n\\ttree = TemplateTranslator(translations_3to2).translate(tree)\\n\\treturn python_reconstruct.reconstruct(tree)\\n\\n\\n#\\n# Test Code\\n#\\n\\n_TEST_CODE = '''\\nif a / 2 > 1:\\n    yield from [1,2,3]\\nelse:\\n    raise ValueError(a) from e\\n\\n'''\\n\\ndef test():\\n\\tprint(_TEST_CODE)\\n\\tprint('   ----->    ')\\n\\tprint(translate_py3to2(_TEST_CODE))\\n\\nif __name__ == '__main__':\\n\\ttest()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/c1123c2587eda70bc64752df00c577b1/py3to2.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/c1123c2587eda70bc64752df00c577b1/py3to2.ipynb",
        "status_code": 200,
        "scrape_id": "e29eab1f-0887-4d4e-bebb-e6f025eb75f7",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9edfb38ad3bc19fc2b92c728275b9008/main.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Grammar Composition\\n\\nThis example shows how to do grammar composition in Lark, by creating a new\\nfile format that allows both CSV and JSON to co-exist.\\n\\n1) We define ``storage.lark``, which imports both ``csv.lark`` and ``json.lark``,\\n  and allows them to be used one after the other.\\n\\n  In the generated tree, each imported rule/terminal is automatically prefixed (with ``json__`` or ``csv__),\\n  which creates an implicit namespace and allows them to coexist without collisions.\\n\\n2) We merge their respective transformers (unaware of each other) into a new base transformer.\\n   The resulting transformer can evaluate both JSON and CSV in the parse tree.\\n\\n  The methods of each transformer are renamed into their appropriate namespace, using the given prefix.\\n  This approach allows full re-use: the transformers don't need to care if their grammar is used directly,\\n  or being imported, or who is doing the importing.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from pathlib import Path\\nfrom lark import Lark\\nfrom json import dumps\\nfrom lark.visitors import Transformer, merge_transformers\\n\\nfrom eval_csv import CsvTreeToPandasDict\\nfrom eval_json import JsonTreeToJson\\n\\n__dir__ = Path(__file__).parent\\n\\nclass Storage(Transformer):\\n    def start(self, children):\\n        return children\\n\\nstorage_transformer = merge_transformers(Storage(), csv=CsvTreeToPandasDict(), json=JsonTreeToJson())\\n\\nparser = Lark.open(\\\"storage.lark\\\", rel_to=__file__)\\n\\ndef main():\\n    json_tree = parser.parse(dumps({\\\"test\\\": \\\"a\\\", \\\"dict\\\": { \\\"list\\\": [1, 1.2] }}))\\n    res = storage_transformer.transform(json_tree)\\n    print(\\\"Just JSON: \\\", res)\\n\\n    csv_json_tree = parser.parse(open(__dir__ / 'combined_csv_and_json.txt').read())\\n    res = storage_transformer.transform(csv_json_tree)\\n    print(\\\"JSON + CSV: \\\", dumps(res, indent=2))\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9edfb38ad3bc19fc2b92c728275b9008/main.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9edfb38ad3bc19fc2b92c728275b9008/main.ipynb",
        "status_code": 200,
        "scrape_id": "c7c027e4-e50c-44fc-b2d8-9b9d0ebc2ced",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9cadc23f6b1e9e52f35d3cb0a28053b0/turtle_dsl.py",
      "markdown": "```\n\"\"\"\nTurtle DSL\n==========\n\nImplements a LOGO-like toy language for Python’s turtle, with interpreter.\n\"\"\"\n\ntry:\n    input = raw_input   # For Python2 compatibility\nexcept NameError:\n    pass\n\nimport turtle\n\nfrom lark import Lark\n\nturtle_grammar = \"\"\"\n    start: instruction+\n\n    instruction: MOVEMENT NUMBER            -> movement\n               | \"c\" COLOR [COLOR]          -> change_color\n               | \"fill\" code_block          -> fill\n               | \"repeat\" NUMBER code_block -> repeat\n\n    code_block: \"{\" instruction+ \"}\"\n\n    MOVEMENT: \"f\"|\"b\"|\"l\"|\"r\"\n    COLOR: LETTER+\n\n    %import common.LETTER\n    %import common.INT -> NUMBER\n    %import common.WS\n    %ignore WS\n\"\"\"\n\nparser = Lark(turtle_grammar)\n\ndef run_instruction(t):\n    if t.data == 'change_color':\n        turtle.color(*t.children)   # We just pass the color names as-is\n\n    elif t.data == 'movement':\n        name, number = t.children\n        { 'f': turtle.fd,\n          'b': turtle.bk,\n          'l': turtle.lt,\n          'r': turtle.rt, }[name](int(number))\n\n    elif t.data == 'repeat':\n        count, block = t.children\n        for i in range(int(count)):\n            run_instruction(block)\n\n    elif t.data == 'fill':\n        turtle.begin_fill()\n        run_instruction(t.children[0])\n        turtle.end_fill()\n\n    elif t.data == 'code_block':\n        for cmd in t.children:\n            run_instruction(cmd)\n    else:\n        raise SyntaxError('Unknown instruction: %s' % t.data)\n\ndef run_turtle(program):\n    parse_tree = parser.parse(program)\n    for inst in parse_tree.children:\n        run_instruction(inst)\n\ndef main():\n    while True:\n        code = input('> ')\n        try:\n            run_turtle(code)\n        except Exception as e:\n            print(e)\n\ndef test():\n    text = \"\"\"\n        c red yellow\n        fill { repeat 36 {\n            f200 l170\n        }}\n    \"\"\"\n    run_turtle(text)\n\nif __name__ == '__main__':\n    # test()\n    main()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9cadc23f6b1e9e52f35d3cb0a28053b0/turtle_dsl.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9cadc23f6b1e9e52f35d3cb0a28053b0/turtle_dsl.py",
        "status_code": 200,
        "scrape_id": "5495b3b0-9f4e-4320-b812-b7522da94448",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Lark Grammar\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/lark_grammar.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html \"Parsing Indentation\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html \"Handling Ambiguity\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html#sphx-glr-download-examples-lark-grammar-py)\nto download the full example code\n\n# Lark Grammar [](https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html\\#lark-grammar \"Permalink to this heading\")\n\nA reference implementation of the Lark grammar (using LALR(1))\n\n```\nimport lark\nfrom pathlib import Path\n\nexamples_path = Path(__file__).parent\nlark_path = Path(lark.__file__).parent\n\nparser = lark.Lark.open(lark_path / 'grammars/lark.lark', rel_to=__file__, parser=\"lalr\")\n\ngrammar_files = [\\\n    examples_path / 'advanced/python2.lark',\\\n    examples_path / 'relative-imports/multiples.lark',\\\n    examples_path / 'relative-imports/multiple2.lark',\\\n    examples_path / 'relative-imports/multiple3.lark',\\\n    examples_path / 'tests/no_newline_at_end.lark',\\\n    examples_path / 'tests/negative_priority.lark',\\\n    examples_path / 'standalone/json.lark',\\\n    lark_path / 'grammars/common.lark',\\\n    lark_path / 'grammars/lark.lark',\\\n    lark_path / 'grammars/unicode.lark',\\\n    lark_path / 'grammars/python.lark',\\\n]\n\ndef test():\n    for grammar_file in grammar_files:\n        tree = parser.parse(open(grammar_file).read())\n    print(\"All grammars parsed successfully\")\n\nif __name__ == '__main__':\n    test()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: lark_grammar.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/b9abd703bb1b061d8ae5f6ab1b9393e8/lark_grammar.py)\n\n[`Download Jupyter notebook: lark_grammar.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/2f68c21f7729a47e57d3ae345753e407/lark_grammar.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/lark_grammar.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Lark Grammar — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html",
        "status_code": 200,
        "scrape_id": "7b56d91f-83be-4176-9b59-d03f2cb2ca45",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2f68c21f7729a47e57d3ae345753e407/lark_grammar.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Lark Grammar\\n\\nA reference implementation of the Lark grammar (using LALR(1))\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import lark\\nfrom pathlib import Path\\n\\nexamples_path = Path(__file__).parent\\nlark_path = Path(lark.__file__).parent\\n\\nparser = lark.Lark.open(lark_path / 'grammars/lark.lark', rel_to=__file__, parser=\\\"lalr\\\")\\n\\n\\ngrammar_files = [\\n    examples_path / 'advanced/python2.lark',\\n    examples_path / 'relative-imports/multiples.lark',\\n    examples_path / 'relative-imports/multiple2.lark',\\n    examples_path / 'relative-imports/multiple3.lark',\\n    examples_path / 'tests/no_newline_at_end.lark',\\n    examples_path / 'tests/negative_priority.lark',\\n    examples_path / 'standalone/json.lark',\\n    lark_path / 'grammars/common.lark',\\n    lark_path / 'grammars/lark.lark',\\n    lark_path / 'grammars/unicode.lark',\\n    lark_path / 'grammars/python.lark',\\n]\\n\\ndef test():\\n    for grammar_file in grammar_files:\\n        tree = parser.parse(open(grammar_file).read())\\n    print(\\\"All grammars parsed successfully\\\")\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2f68c21f7729a47e57d3ae345753e407/lark_grammar.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2f68c21f7729a47e57d3ae345753e407/lark_grammar.ipynb",
        "status_code": 200,
        "scrape_id": "1ede819a-5857-4d79-806b-a463ce105b6e",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/parsers.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Parsers\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/parsers.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/features.html \"Features\") [Next](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html \"JSON parser - Tutorial\")\n\n* * *\n\n# Parsers [](https://lark-parser.readthedocs.io/en/stable/parsers.html\\#parsers \"Permalink to this heading\")\n\nLark implements the following parsing algorithms: Earley, LALR(1), and CYK\n\n## Earley [](https://lark-parser.readthedocs.io/en/stable/parsers.html\\#earley \"Permalink to this heading\")\n\nAn [Earley Parser](https://www.wikiwand.com/en/Earley_parser) is a chart parser capable of parsing any context-free grammar at O(n^3), and O(n^2) when the grammar is unambiguous. It can parse most LR grammars at O(n). Most programming languages are LR, and can be parsed at a linear time.\n\nLark’s Earley implementation runs on top of a skipping chart parser, which allows it to use regular expressions, instead of matching characters one-by-one. This is a huge improvement to Earley that is unique to Lark. This feature is used by default, but can also be requested explicitly using `lexer='dynamic'`.\n\nIt’s possible to bypass the dynamic lexing, and use the regular Earley parser with a basic lexer, that tokenizes as an independent first step. Doing so will provide a speed benefit, but will tokenize without using Earley’s ambiguity-resolution ability. So choose this only if you know why! Activate with `lexer='basic'`\n\n**SPPF & Ambiguity resolution**\n\nLark implements the Shared Packed Parse Forest data-structure for the Earley parser, in order to reduce the space and computation required to handle ambiguous grammars.\n\nYou can read more about SPPF [here](https://web.archive.org/web/20191229100607/www.bramvandersanden.com/post/2014/06/shared-packed-parse-forest)\n\nAs a result, Lark can efficiently parse and store every ambiguity in the grammar, when using Earley.\n\nLark provides the following options to combat ambiguity:\n\n1. Lark will choose the best derivation for you (default). Users can choose between different disambiguation strategies, and can prioritize (or demote) individual rules over others, using the rule-priority syntax.\n\n2. Users may choose to receive the set of all possible parse-trees (using ambiguity=’explicit’), and choose the best derivation themselves. While simple and flexible, it comes at the cost of space and performance, and so it isn’t recommended for highly ambiguous grammars, or very long inputs.\n\n3. As an advanced feature, users may use specialized visitors to iterate the SPPF themselves. There is also [a 3rd party utility for iterating over the SPPF](https://github.com/chanicpanic/lark-ambig-tools).\n\n\n**lexer=”dynamic\\_complete”**\n\nEarley’s “dynamic” lexer uses regular expressions in order to tokenize the text. It tries every possible combination of terminals, but it matches each terminal exactly once, returning the longest possible match.\n\nThat means, for example, that when `lexer=\"dynamic\"` (which is the default), the terminal `/a+/`, when given the text `\"aa\"`, will return one result, `aa`, even though `a` would also be correct.\n\nThis behavior was chosen because it is much faster, and it is usually what you would expect.\n\nSetting `lexer=\"dynamic_complete\"` instructs the lexer to consider every possible regexp match. This ensures that the parser will consider and resolve every ambiguity, even inside the terminals themselves. This lexer provides the same capabilities as scannerless Earley, but with different performance tradeoffs.\n\nWarning: This lexer can be much slower, especially for open-ended terminals such as `/.*/`\n\n## LALR(1) [](https://lark-parser.readthedocs.io/en/stable/parsers.html\\#lalr-1 \"Permalink to this heading\")\n\n[LALR(1)](https://www.wikiwand.com/en/LALR_parser) is a very efficient, true-and-tested parsing algorithm. It’s incredibly fast and requires very little memory. It can parse most programming languages (For example: Python and Java).\n\nLALR(1) stands for:\n\n- Left-to-right parsing order\n\n- Rightmost derivation, bottom-up\n\n- Lookahead of 1 token\n\n\nLark comes with an efficient implementation that outperforms every other parsing library for Python (including PLY)\n\nLark extends the traditional YACC-based architecture with a _contextual lexer_, which processes feedback from the parser, making the LALR(1) algorithm stronger than ever.\n\nThe contextual lexer communicates with the parser, and uses the parser’s lookahead prediction to narrow its choice of terminals. So at each point, the lexer only matches the subgroup of terminals that are legal at that parser state, instead of all of the terminals. It’s surprisingly effective at resolving common terminal collisions, and allows one to parse languages that LALR(1) was previously incapable of parsing.\n\n(If you’re familiar with YACC, you can think of it as automatic lexer-states)\n\nThis is an improvement to LALR(1) that is unique to Lark.\n\n### Grammar constraints in LALR(1) [](https://lark-parser.readthedocs.io/en/stable/parsers.html\\#grammar-constraints-in-lalr-1 \"Permalink to this heading\")\n\nDue to having only a lookahead of one token, LALR is limited in its ability to choose between rules, when they both match the input.\n\nTips for writing a conforming grammar:\n\n- Try to avoid writing different rules that can match the same sequence of characters.\n\n- For the best performance, prefer left-recursion over right-recursion.\n\n- Consider setting terminal priority only as a last resort.\n\n\nFor a better understanding of these constraints, it’s recommended to learn how a SLR parser works. SLR is very similar to LALR but much simpler.\n\n## CYK Parser [](https://lark-parser.readthedocs.io/en/stable/parsers.html\\#cyk-parser \"Permalink to this heading\")\n\nA [CYK parser](https://www.wikiwand.com/en/CYK_algorithm) can parse any context-free grammar at O(n^3\\*\\|G\\|).\n\nIts too slow to be practical for simple grammars, but it offers good performance for highly ambiguous grammars.\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/parsers.html)**[stable](https://lark-parser.readthedocs.io/en/stable/parsers.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Parsers — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/parsers.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/parsers.html",
        "status_code": 200,
        "scrape_id": "94fefe6a-b416-4413-a344-69b0912b80af",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/7279f5d640bfe9814468a2adf38516d5/error_reporting_lalr.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Example-Driven Error Reporting\\n\\nA demonstration of example-driven error reporting with the LALR parser\\n(See also: error_reporting_earley.py)\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark, UnexpectedInput\\n\\nfrom _json_parser import json_grammar   # Using the grammar from the json_parser example\\n\\njson_parser = Lark(json_grammar, parser='lalr')\\n\\nclass JsonSyntaxError(SyntaxError):\\n    def __str__(self):\\n        context, line, column = self.args\\n        return '%s at line %s, column %s.\\\\n\\\\n%s' % (self.label, line, column, context)\\n\\nclass JsonMissingValue(JsonSyntaxError):\\n    label = 'Missing Value'\\n\\nclass JsonMissingOpening(JsonSyntaxError):\\n    label = 'Missing Opening'\\n\\nclass JsonMissingClosing(JsonSyntaxError):\\n    label = 'Missing Closing'\\n\\nclass JsonMissingComma(JsonSyntaxError):\\n    label = 'Missing Comma'\\n\\nclass JsonTrailingComma(JsonSyntaxError):\\n    label = 'Trailing Comma'\\n\\n\\ndef parse(json_text):\\n    try:\\n        j = json_parser.parse(json_text)\\n    except UnexpectedInput as u:\\n        exc_class = u.match_examples(json_parser.parse, {\\n            JsonMissingOpening: ['{\\\"foo\\\": ]}',\\n                                 '{\\\"foor\\\": }}',\\n                                 '{\\\"foo\\\": }'],\\n            JsonMissingClosing: ['{\\\"foo\\\": [}',\\n                                 '{',\\n                                 '{\\\"a\\\": 1',\\n                                 '[1'],\\n            JsonMissingComma: ['[1 2]',\\n                               '[false 1]',\\n                               '[\\\"b\\\" 1]',\\n                               '{\\\"a\\\":true 1:4}',\\n                               '{\\\"a\\\":1 1:4}',\\n                               '{\\\"a\\\":\\\"b\\\" 1:4}'],\\n            JsonTrailingComma: ['[,]',\\n                                '[1,]',\\n                                '[1,2,]',\\n                                '{\\\"foo\\\":1,}',\\n                                '{\\\"foo\\\":false,\\\"bar\\\":true,}']\\n        }, use_accepts=True)\\n        if not exc_class:\\n            raise\\n        raise exc_class(u.get_context(json_text), u.line, u.column)\\n\\n\\ndef test():\\n    try:\\n        parse('{\\\"example1\\\": \\\"value\\\"')\\n    except JsonMissingClosing as e:\\n        print(e)\\n\\n    try:\\n        parse('{\\\"example2\\\": ] ')\\n    except JsonMissingOpening as e:\\n        print(e)\\n\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/7279f5d640bfe9814468a2adf38516d5/error_reporting_lalr.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/7279f5d640bfe9814468a2adf38516d5/error_reporting_lalr.ipynb",
        "status_code": 200,
        "scrape_id": "52e7917d-657f-42d1-84a6-37cc6d048814",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9ebc86868010e2fc400ecf1ef8a5aa4a/fruitflies.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Handling Ambiguity\\n\\nA demonstration of ambiguity\\n\\nThis example shows how to use get explicit ambiguity from Lark's Earley parser.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import sys\\nfrom lark import Lark, tree\\n\\ngrammar = \\\"\\\"\\\"\\n    sentence: noun verb noun        -> simple\\n            | noun verb \\\"like\\\" noun -> comparative\\n\\n    noun: adj? NOUN\\n    verb: VERB\\n    adj: ADJ\\n\\n    NOUN: \\\"flies\\\" | \\\"bananas\\\" | \\\"fruit\\\"\\n    VERB: \\\"like\\\" | \\\"flies\\\"\\n    ADJ: \\\"fruit\\\"\\n\\n    %import common.WS\\n    %ignore WS\\n\\\"\\\"\\\"\\n\\nparser = Lark(grammar, start='sentence', ambiguity='explicit')\\n\\nsentence = 'fruit flies like bananas'\\n\\ndef make_png(filename):\\n    tree.pydot__tree_to_png( parser.parse(sentence), filename)\\n\\ndef make_dot(filename):\\n    tree.pydot__tree_to_dot( parser.parse(sentence), filename)\\n\\nif __name__ == '__main__':\\n    print(parser.parse(sentence).pretty())\\n    # make_png(sys.argv[1])\\n    # make_dot(sys.argv[1])\\n\\n# Output:\\n#\\n# _ambig\\n#   comparative\\n#     noun\\tfruit\\n#     verb\\tflies\\n#     noun\\tbananas\\n#   simple\\n#     noun\\n#       fruit\\n#       flies\\n#     verb\\tlike\\n#     noun\\tbananas\\n#\\n# (or view a nicer version at \\\"./fruitflies.png\\\")\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9ebc86868010e2fc400ecf1ef8a5aa4a/fruitflies.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9ebc86868010e2fc400ecf1ef8a5aa4a/fruitflies.ipynb",
        "status_code": 200,
        "scrape_id": "992e1f4d-f820-4fa9-ae10-38a9f1e479c1",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3b0766c1f76ff2904339853615cf4943/reconstruct_python.py",
      "markdown": "```\n\"\"\"\nReconstruct Python\n==================\n\nDemonstrates how Lark's experimental text-reconstruction feature can recreate\nfunctional Python code from its parse-tree, using just the correct grammar and\na small formatter.\n\n\"\"\"\n\nfrom lark import Token, Lark\nfrom lark.reconstruct import Reconstructor\nfrom lark.indenter import PythonIndenter\n\n# Official Python grammar by Lark\npython_parser3 = Lark.open_from_package('lark', 'python.lark', ['grammars'],\n                                        parser='lalr', postlex=PythonIndenter(), start='file_input',\n                                        maybe_placeholders=False    # Necessary for reconstructor\n                                        )\n\nSPACE_AFTER = set(',+-*/~@<>=\"|:')\nSPACE_BEFORE = (SPACE_AFTER - set(',:')) | set('\\'')\n\ndef special(sym):\n    return Token('SPECIAL', sym.name)\n\ndef postproc(items):\n    stack = ['\\n']\n    actions = []\n    last_was_whitespace = True\n    for item in items:\n        if isinstance(item, Token) and item.type == 'SPECIAL':\n            actions.append(item.value)\n        else:\n            if actions:\n                assert actions[0] == '_NEWLINE' and '_NEWLINE' not in actions[1:], actions\n\n                for a in actions[1:]:\n                    if a == '_INDENT':\n                        stack.append(stack[-1] + ' ' * 4)\n                    else:\n                        assert a == '_DEDENT'\n                        stack.pop()\n                actions.clear()\n                yield stack[-1]\n                last_was_whitespace = True\n            if not last_was_whitespace:\n                if item[0] in SPACE_BEFORE:\n                    yield ' '\n            yield item\n            last_was_whitespace = item[-1].isspace()\n            if not last_was_whitespace:\n                if item[-1] in SPACE_AFTER:\n                    yield ' '\n                    last_was_whitespace = True\n    yield \"\\n\"\n\nclass PythonReconstructor:\n    def __init__(self, parser):\n        self._recons = Reconstructor(parser, {'_NEWLINE': special, '_DEDENT': special, '_INDENT': special})\n\n    def reconstruct(self, tree):\n        return self._recons.reconstruct(tree, postproc)\n\ndef test():\n    python_reconstructor = PythonReconstructor(python_parser3)\n\n    self_contents = open(__file__).read()\n\n    tree = python_parser3.parse(self_contents+'\\n')\n    output = python_reconstructor.reconstruct(tree)\n\n    tree_new = python_parser3.parse(output)\n    print(tree.pretty())\n    print(tree_new.pretty())\n    # assert tree.pretty() == tree_new.pretty()\n    assert tree == tree_new\n\n    print(output)\n\nif __name__ == '__main__':\n    test()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3b0766c1f76ff2904339853615cf4943/reconstruct_python.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3b0766c1f76ff2904339853615cf4943/reconstruct_python.py",
        "status_code": 200,
        "scrape_id": "bfffde84-f89b-460f-9393-8a0c35475331",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.874Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/1bc3cb4e14f2c898c0bf16247304d5b2/conf_earley.py",
      "markdown": "```\n\"\"\"\nEarley’s dynamic lexer\n======================\n\nDemonstrates the power of Earley’s dynamic lexer on a toy configuration language\n\nUsing a lexer for configuration files is tricky, because values don't\nhave to be surrounded by delimiters. Using a basic lexer for this just won't work.\n\nIn this example we use a dynamic lexer and let the Earley parser resolve the ambiguity.\n\nAnother approach is to use the contextual lexer with LALR. It is less powerful than Earley,\nbut it can handle some ambiguity when lexing and it's much faster.\nSee examples/conf_lalr.py for an example of that approach.\n\n\"\"\"\nfrom lark import Lark\n\nparser = Lark(r\"\"\"\n        start: _NL? section+\n        section: \"[\" NAME \"]\" _NL item+\n        item: NAME \"=\" VALUE? _NL\n\n        NAME: /\\w/+\n        VALUE: /./+\n\n        %import common.NEWLINE -> _NL\n        %import common.WS_INLINE\n        %ignore WS_INLINE\n    \"\"\", parser=\"earley\")\n\ndef test():\n    sample_conf = \"\"\"\n[bla]\n\na=Hello\nthis=\"that\",4\nempty=\n\"\"\"\n\n    r = parser.parse(sample_conf)\n    print (r.pretty())\n\nif __name__ == '__main__':\n    test()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/1bc3cb4e14f2c898c0bf16247304d5b2/conf_earley.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/1bc3cb4e14f2c898c0bf16247304d5b2/conf_earley.py",
        "status_code": 200,
        "scrape_id": "76458534-0ed1-4871-bddc-e0d74f91d12e",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/5a9e0a0dc353e4a9357e2204639f6c76/error_handling.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Error handling using an interactive parser\\n\\nThis example demonstrates error handling using an interactive parser in LALR\\n\\nWhen the parser encounters an UnexpectedToken exception, it creates a\\nan interactive parser with the current parse-state, and lets you control how\\nto proceed step-by-step. When you've achieved the correct parse-state,\\nyou can resume the run by returning True.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Token\\n\\nfrom _json_parser import json_parser\\n\\ndef ignore_errors(e):\\n    if e.token.type == 'COMMA':\\n        # Skip comma\\n        return True\\n    elif e.token.type == 'SIGNED_NUMBER':\\n        # Try to feed a comma and retry the number\\n        e.interactive_parser.feed_token(Token('COMMA', ','))\\n        e.interactive_parser.feed_token(e.token)\\n        return True\\n\\n    # Unhandled error. Will stop parse and raise exception\\n    return False\\n\\n\\ndef main():\\n    s = \\\"[0 1, 2,, 3,,, 4, 5 6 ]\\\"\\n    res = json_parser.parse(s, on_error=ignore_errors)\\n    print(res)      # prints [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\\n\\nmain()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/5a9e0a0dc353e4a9357e2204639f6c76/error_handling.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/5a9e0a0dc353e4a9357e2204639f6c76/error_handling.ipynb",
        "status_code": 200,
        "scrape_id": "c160693f-9fc8-4a06-a681-c0ba3ff779da",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.074Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/4667ab58050962ac05455b953c59244f/custom_lexer.py",
      "markdown": "```\n\"\"\"\nCustom lexer\n============\n\nDemonstrates using a custom lexer to parse a non-textual stream of data\n\nYou can use a custom lexer to tokenize text when the lexers offered by Lark\nare too slow, or not flexible enough.\n\nYou can also use it (as shown in this example) to tokenize streams of objects.\n\"\"\"\nfrom lark import Lark, Transformer, v_args\nfrom lark.lexer import Lexer, Token\n\nclass TypeLexer(Lexer):\n    def __init__(self, lexer_conf):\n        pass\n\n    def lex(self, data):\n        for obj in data:\n            if isinstance(obj, int):\n                yield Token('INT', obj)\n            elif isinstance(obj, (type(''), type(u''))):\n                yield Token('STR', obj)\n            else:\n                raise TypeError(obj)\n\nparser = Lark(\"\"\"\n        start: data_item+\n        data_item: STR INT*\n\n        %declare STR INT\n        \"\"\", parser='lalr', lexer=TypeLexer)\n\nclass ParseToDict(Transformer):\n    @v_args(inline=True)\n    def data_item(self, name, *numbers):\n        return name.value, [n.value for n in numbers]\n\n    start = dict\n\ndef test():\n    data = ['alice', 1, 27, 3, 'bob', 4, 'carrie', 'dan', 8, 6]\n\n    print(data)\n\n    tree = parser.parse(data)\n    res = ParseToDict().transform(tree)\n\n    print('-->')\n    print(res) # prints {'alice': [1, 27, 3], 'bob': [4], 'carrie': [], 'dan': [8, 6]}\n\nif __name__ == '__main__':\n    test()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/4667ab58050962ac05455b953c59244f/custom_lexer.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/4667ab58050962ac05455b953c59244f/custom_lexer.py",
        "status_code": 200,
        "scrape_id": "c00b3f37-c18e-4d86-9b0b-a34e1924f08b",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/ca074bdcc9170e436dcd2f779e4a4285/error_reporting_earley.py",
      "markdown": "```\n\"\"\"\nExample-Driven Error Reporting\n==============================\n\nA demonstration of example-driven error reporting with the Earley parser\n(See also: error_reporting_lalr.py)\n\"\"\"\nfrom lark import Lark, UnexpectedInput\n\nfrom _json_parser import json_grammar   # Using the grammar from the json_parser example\n\njson_parser = Lark(json_grammar)\n\nclass JsonSyntaxError(SyntaxError):\n    def __str__(self):\n        context, line, column = self.args\n        return '%s at line %s, column %s.\\n\\n%s' % (self.label, line, column, context)\n\nclass JsonMissingValue(JsonSyntaxError):\n    label = 'Missing Value'\n\nclass JsonMissingOpening(JsonSyntaxError):\n    label = 'Missing Opening'\n\nclass JsonMissingClosing(JsonSyntaxError):\n    label = 'Missing Closing'\n\nclass JsonMissingComma(JsonSyntaxError):\n    label = 'Missing Comma'\n\nclass JsonTrailingComma(JsonSyntaxError):\n    label = 'Trailing Comma'\n\ndef parse(json_text):\n    try:\n        j = json_parser.parse(json_text)\n    except UnexpectedInput as u:\n        exc_class = u.match_examples(json_parser.parse, {\n            JsonMissingOpening: ['{\"foo\": ]}',\n                                 '{\"foor\": }}',\n                                 '{\"foo\": }'],\n            JsonMissingClosing: ['{\"foo\": [}',\\\n                                 '{',\\\n                                 '{\"a\": 1',\\\n                                 '[1'],\\\n            JsonMissingComma: ['[1 2]',\\\n                               '[false 1]',\\\n                               '[\"b\" 1]',\\\n                               '{\"a\":true 1:4}',\\\n                               '{\"a\":1 1:4}',\\\n                               '{\"a\":\"b\" 1:4}'],\\\n            JsonTrailingComma: ['[,]',\\\n                                '[1,]',\\\n                                '[1,2,]',\\\n                                '{\"foo\":1,}',\\\n                                '{\"foo\":false,\"bar\":true,}']\\\n        }, use_accepts=True)\\\n        if not exc_class:\\\n            raise\\\n        raise exc_class(u.get_context(json_text), u.line, u.column)\\\n\\\ndef test():\\\n    try:\\\n        parse('{\"example1\": \"value\"')\\\n    except JsonMissingClosing as e:\\\n        print(e)\\\n\\\n    try:\\\n        parse('{\"example2\": ] ')\\\n    except JsonMissingOpening as e:\\\n        print(e)\\\n\\\nif __name__ == '__main__':\\\n    test()\\\n\\\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/ca074bdcc9170e436dcd2f779e4a4285/error_reporting_earley.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/ca074bdcc9170e436dcd2f779e4a4285/error_reporting_earley.py",
        "status_code": 200,
        "scrape_id": "5c8f4cc6-af05-402c-9db4-8a59b0fc3284",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/222c07e0396620c7fabb1da7fda69ca9/json_parser_main.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Standalone Parser\\n\\n    This example demonstrates how to generate and use the standalone parser,\\n    using the JSON example.\\n\\n    See README.md for more details.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import sys\\n\\nfrom json_parser import Lark_StandAlone, Transformer, v_args\\n\\ninline_args = v_args(inline=True)\\n\\nclass TreeToJson(Transformer):\\n    @inline_args\\n    def string(self, s):\\n        return s[1:-1].replace('\\\\\\\\\\\"', '\\\"')\\n\\n    array = list\\n    pair = tuple\\n    object = dict\\n    number = inline_args(float)\\n\\n    null = lambda self, _: None\\n    true = lambda self, _: True\\n    false = lambda self, _: False\\n\\n\\nparser = Lark_StandAlone(transformer=TreeToJson())\\n\\nif __name__ == '__main__':\\n    with open(sys.argv[1]) as f:\\n        print(parser.parse(f.read()))\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/222c07e0396620c7fabb1da7fda69ca9/json_parser_main.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/222c07e0396620c7fabb1da7fda69ca9/json_parser_main.ipynb",
        "status_code": 200,
        "scrape_id": "e138cca4-42ba-4a00-8832-4c8ab7539925",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/4b6a9b4fb62278f5d7a70e5b2900ff58/indented_tree.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Parsing Indentation\\n\\nA demonstration of parsing indentation (\\u201cwhitespace significant\\u201d language)\\nand the usage of the Indenter class.\\n\\nSince indentation is context-sensitive, a postlex stage is introduced to\\nmanufacture INDENT/DEDENT tokens.\\n\\nIt is crucial for the indenter that the NL_type matches\\nthe spaces (and tabs) after the newline.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\nfrom lark.indenter import Indenter\\n\\ntree_grammar = r\\\"\\\"\\\"\\n    ?start: _NL* tree\\n\\n    tree: NAME _NL [_INDENT tree+ _DEDENT]\\n\\n    %import common.CNAME -> NAME\\n    %import common.WS_INLINE\\n    %declare _INDENT _DEDENT\\n    %ignore WS_INLINE\\n\\n    _NL: /(\\\\r?\\\\n[\\\\t ]*)+/\\n\\\"\\\"\\\"\\n\\nclass TreeIndenter(Indenter):\\n    NL_type = '_NL'\\n    OPEN_PAREN_types = []\\n    CLOSE_PAREN_types = []\\n    INDENT_type = '_INDENT'\\n    DEDENT_type = '_DEDENT'\\n    tab_len = 8\\n\\nparser = Lark(tree_grammar, parser='lalr', postlex=TreeIndenter())\\n\\ntest_tree = \\\"\\\"\\\"\\na\\n    b\\n    c\\n        d\\n        e\\n    f\\n        g\\n\\\"\\\"\\\"\\n\\ndef test():\\n    print(parser.parse(test_tree).pretty())\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/4b6a9b4fb62278f5d7a70e5b2900ff58/indented_tree.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/4b6a9b4fb62278f5d7a70e5b2900ff58/indented_tree.ipynb",
        "status_code": 200,
        "scrape_id": "5b053344-eda8-4eba-982c-07748649d8bd",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3c07a7adfbea6387847af2b079a58ed6/prioritizer.py",
      "markdown": "```\n\"\"\"\nCustom SPPF Prioritizer\n=======================\n\nThis example demonstrates how to subclass ``ForestVisitor`` to make a custom\nSPPF node prioritizer to be used in conjunction with ``TreeForestTransformer``.\n\nOur prioritizer will count the number of descendants of a node that are tokens.\nBy negating this count, our prioritizer will prefer nodes with fewer token\ndescendants. Thus, we choose the more specific parse.\n\"\"\"\n\nfrom lark import Lark\nfrom lark.parsers.earley_forest import ForestVisitor, TreeForestTransformer\n\nclass TokenPrioritizer(ForestVisitor):\n\n    def visit_symbol_node_in(self, node):\n        # visit the entire forest by returning node.children\n        return node.children\n\n    def visit_packed_node_in(self, node):\n        return node.children\n\n    def visit_symbol_node_out(self, node):\n        priority = 0\n        for child in node.children:\n            # Tokens do not have a priority attribute\n            # count them as -1\n            priority += getattr(child, 'priority', -1)\n        node.priority = priority\n\n    def visit_packed_node_out(self, node):\n        priority = 0\n        for child in node.children:\n            priority += getattr(child, 'priority', -1)\n        node.priority = priority\n\n    def on_cycle(self, node, path):\n        raise Exception(\"Oops, we encountered a cycle.\")\n\ngrammar = \"\"\"\nstart: hello \" \" world | hello_world\nhello: \"Hello\"\nworld: \"World\"\nhello_world: \"Hello World\"\n\"\"\"\n\nparser = Lark(grammar, parser='earley', ambiguity='forest')\nforest = parser.parse(\"Hello World\")\n\nprint(\"Default prioritizer:\")\ntree = TreeForestTransformer(resolve_ambiguity=True).transform(forest)\nprint(tree.pretty())\n\nforest = parser.parse(\"Hello World\")\n\nprint(\"Custom prioritizer:\")\ntree = TreeForestTransformer(resolve_ambiguity=True, prioritizer=TokenPrioritizer()).transform(forest)\nprint(tree.pretty())\n\n# Output:\n#\n# Default prioritizer:\n# start\n#   hello Hello\n#\n#   world World\n#\n# Custom prioritizer:\n# start\n#   hello_world   Hello World\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3c07a7adfbea6387847af2b079a58ed6/prioritizer.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3c07a7adfbea6387847af2b079a58ed6/prioritizer.py",
        "status_code": 200,
        "scrape_id": "d5d44577-baca-4197-9009-e4fe81151e03",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/philosophy.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Philosophy\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/philosophy.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/index.html \"Welcome to Lark’s documentation!\") [Next](https://lark-parser.readthedocs.io/en/stable/features.html \"Features\")\n\n* * *\n\n# Philosophy [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#philosophy \"Permalink to this heading\")\n\nParsers are innately complicated and confusing. They’re difficult to understand, difficult to write, and difficult to use. Even experts on the subject can become baffled by the nuances of these complicated state-machines.\n\nLark’s mission is to make the process of writing them as simple and abstract as possible, by following these design principles:\n\n## Design Principles [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#design-principles \"Permalink to this heading\")\n\n1. Readability matters\n\n2. Keep the grammar clean and simple\n\n3. Don’t force the user to decide on things that the parser can figure out on its own\n\n4. Usability is more important than performance\n\n5. Performance is still very important\n\n6. Follow the Zen of Python, whenever possible and applicable\n\n\nIn accordance with these principles, I arrived at the following design choices:\n\n* * *\n\n## Design Choices [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#design-choices \"Permalink to this heading\")\n\n### 1\\. Separation of code and grammar [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#separation-of-code-and-grammar \"Permalink to this heading\")\n\nGrammars are the de-facto reference for your language, and for the structure of your parse-tree. For any non-trivial language, the conflation of code and grammar always turns out convoluted and difficult to read.\n\nThe grammars in Lark are EBNF-inspired, so they are especially easy to read & work with.\n\n### 2\\. Always build a parse-tree (unless told not to) [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#always-build-a-parse-tree-unless-told-not-to \"Permalink to this heading\")\n\nTrees are always simpler to work with than state-machines.\n\n1. Trees allow you to see the “state-machine” visually\n\n2. Trees allow your computation to be aware of previous and future states\n\n3. Trees allow you to process the parse in steps, instead of forcing you to do it all at once.\n\n\nAnd anyway, every parse-tree can be replayed as a state-machine, so there is no loss of information.\n\nSee this answer in more detail [here](https://github.com/erezsh/lark/issues/4).\n\nTo improve performance, you can skip building the tree for LALR(1), by providing Lark with a transformer (see the [JSON example](https://github.com/erezsh/lark/blob/master/examples/json_parser.py)).\n\n### 3\\. Earley is the default [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#earley-is-the-default \"Permalink to this heading\")\n\nThe Earley algorithm can accept _any_ context-free grammar you throw at it (i.e. any grammar you can write in EBNF, it can parse). That makes it extremely friendly to beginners, who are not aware of the strange and arbitrary restrictions that LALR(1) places on its grammars.\n\nAs the users grow to understand the structure of their grammar, the scope of their target language, and their performance requirements, they may choose to switch over to LALR(1) to gain a huge performance boost, possibly at the cost of some language features.\n\nBoth Earley and LALR(1) can use the same grammar, as long as all constraints are satisfied.\n\nIn short, “Premature optimization is the root of all evil.”\n\n### Other design features [](https://lark-parser.readthedocs.io/en/stable/philosophy.html\\#other-design-features \"Permalink to this heading\")\n\n- Automatically resolve terminal collisions whenever possible\n\n- Automatically keep track of line & column numbers\n\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/philosophy.html)**[stable](https://lark-parser.readthedocs.io/en/stable/philosophy.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Philosophy — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/philosophy.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/philosophy.html",
        "status_code": 200,
        "scrape_id": "ff213cf9-4f1c-4000-aa03-2b111b55ce84",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- LALR’s contextual lexer\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/conf_lalr.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html \"Advanced Examples\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html \"Templates\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html#sphx-glr-download-examples-advanced-conf-lalr-py)\nto download the full example code\n\n# LALR’s contextual lexer [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html\\#lalrs-contextual-lexer \"Permalink to this heading\")\n\nThis example demonstrates the power of LALR’s contextual lexer,\nby parsing a toy configuration language.\n\nThe terminals NAME and VALUE overlap. They can match the same input.\nA basic lexer would arbitrarily choose one over the other, based on priority,\nwhich would lead to a (confusing) parse error.\nHowever, due to the unambiguous structure of the grammar, Lark’s LALR(1) algorithm knows\nwhich one of them to expect at each point during the parse.\nThe lexer then only matches the tokens that the parser expects.\nThe result is a correct parse, something that is impossible with a regular lexer.\n\nAnother approach is to use the Earley algorithm.\nIt will handle more cases than the contextual lexer, but at the cost of performance.\nSee examples/conf\\_earley.py for an example of that approach.\n\n```\nfrom lark import Lark\n\nparser = Lark(r\"\"\"\n        start: _NL? section+\n        section: \"[\" NAME \"]\" _NL item+\n        item: NAME \"=\" VALUE? _NL\n\n        NAME: /\\w/+\n        VALUE: /./+\n\n        %import common.NEWLINE -> _NL\n        %import common.WS_INLINE\n        %ignore WS_INLINE\n    \"\"\", parser=\"lalr\")\n\nsample_conf = \"\"\"\n[bla]\na=Hello\nthis=\"that\",4\nempty=\n\"\"\"\n\nprint(parser.parse(sample_conf).pretty())\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: conf_lalr.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/3ed7cc698fc366fe253eac6ecf76ee3e/conf_lalr.py)\n\n[`Download Jupyter notebook: conf_lalr.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/9e5ca2d2f34acae5a9391bd4b16a935f/conf_lalr.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/conf_lalr.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "LALR’s contextual lexer — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html",
        "status_code": 200,
        "scrape_id": "6f7de34e-3e7d-4b39-a614-d8995d531666",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Example Grammars\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/grammars/index.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html \"Grammar Composition\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html \"Standalone example\")\n\n* * *\n\n# Example Grammars [](https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html\\#example-grammars \"Permalink to this heading\")\n\nThis directory is a collection of lark grammars, taken from real world projects.\n\n- [Verilog](https://github.com/lark-parser/lark/blob/master/examples/grammars/verilog.lark) \\- Taken from [https://github.com/circuitgraph/circuitgraph/blob/main/circuitgraph/parsing/verilog.lark](https://github.com/circuitgraph/circuitgraph/blob/main/circuitgraph/parsing/verilog.lark)\n\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/grammars/)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/grammars/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Example Grammars — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html",
        "status_code": 200,
        "scrape_id": "e9cf6d4e-f735-4307-b529-f5b38200b306",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.074Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/ee39a682704904d3f08f1d957831c955/_json_parser.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Simple JSON Parser\\n\\nThe code is short and clear, and outperforms every other parser (that's written in Python).\\nFor an explanation, check out the JSON parser tutorial at /docs/json_tutorial.md\\n\\n(this is here for use by the other examples)\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark, Transformer, v_args\\n\\njson_grammar = r\\\"\\\"\\\"\\n    ?start: value\\n\\n    ?value: object\\n          | array\\n          | string\\n          | SIGNED_NUMBER      -> number\\n          | \\\"true\\\"             -> true\\n          | \\\"false\\\"            -> false\\n          | \\\"null\\\"             -> null\\n\\n    array  : \\\"[\\\" [value (\\\",\\\" value)*] \\\"]\\\"\\n    object : \\\"{\\\" [pair (\\\",\\\" pair)*] \\\"}\\\"\\n    pair   : string \\\":\\\" value\\n\\n    string : ESCAPED_STRING\\n\\n    %import common.ESCAPED_STRING\\n    %import common.SIGNED_NUMBER\\n    %import common.WS\\n\\n    %ignore WS\\n\\\"\\\"\\\"\\n\\n\\nclass TreeToJson(Transformer):\\n    @v_args(inline=True)\\n    def string(self, s):\\n        return s[1:-1].replace('\\\\\\\\\\\"', '\\\"')\\n\\n    array = list\\n    pair = tuple\\n    object = dict\\n    number = v_args(inline=True)(float)\\n\\n    null = lambda self, _: None\\n    true = lambda self, _: True\\n    false = lambda self, _: False\\n\\n\\n### Create the JSON parser with Lark, using the LALR algorithm\\njson_parser = Lark(json_grammar, parser='lalr',\\n                   # Using the basic lexer isn't required, and isn't usually recommended.\\n                   # But, it's good enough for JSON, and it's slightly faster.\\n                   lexer='basic',\\n                   # Disabling propagate_positions and placeholders slightly improves speed\\n                   propagate_positions=False,\\n                   maybe_placeholders=False,\\n                   # Using an internal transformer is faster and more memory efficient\\n                   transformer=TreeToJson())\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/ee39a682704904d3f08f1d957831c955/_json_parser.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/ee39a682704904d3f08f1d957831c955/_json_parser.ipynb",
        "status_code": 200,
        "scrape_id": "e6c0f83c-f7d5-4d41-a1b5-8bede2e68ce9",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Grammar Composition](https://lark-parser.readthedocs.io/en/stable/examples/composition/index.html)\n- <no title>\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/composition/eval_csv.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html \"<no title>\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html \"Grammar Composition\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html#sphx-glr-download-examples-composition-eval-csv-py)\nto download the full example code\n\nTransformer for evaluating csv.lark\n\n```\nfrom lark import Transformer\n\nclass CsvTreeToPandasDict(Transformer):\n    INT = int\n    FLOAT = float\n    SIGNED_FLOAT = float\n    WORD = str\n    NON_SEPARATOR_STRING = str\n\n    def row(self, children):\n        return children\n\n    def start(self, children):\n        data = {}\n\n        header = children[0].children\n        for heading in header:\n            data[heading] = []\n\n        for row in children[1:]:\n            for i, element in enumerate(row):\n                data[header[i]].append(element)\n\n        return data\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: eval_csv.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/47174f1088585b541b7296c461639c79/eval_csv.py)\n\n[`Download Jupyter notebook: eval_csv.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/de026e34f2e30342f31740044e683d7b/eval_csv.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/composition/eval_csv.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "<no title> — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html",
        "status_code": 200,
        "scrape_id": "8f44136a-7c0d-4757-b652-8ae2d5b30012",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Reconstruct a JSON\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/reconstruct_json.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html \"Error handling using an interactive parser\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html \"Custom lexer\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html#sphx-glr-download-examples-advanced-reconstruct-json-py)\nto download the full example code\n\n# Reconstruct a JSON [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html\\#reconstruct-a-json \"Permalink to this heading\")\n\nDemonstrates the experimental text-reconstruction feature\n\nThe Reconstructor takes a parse tree (already filtered from punctuation, of course),\nand reconstructs it into correct text, that can be parsed correctly.\nIt can be useful for creating “hooks” to alter data before handing it to other parsers. You can also use it to generate samples from scratch.\n\n```\nimport json\n\nfrom lark import Lark\nfrom lark.reconstruct import Reconstructor\n\nfrom _json_parser import json_grammar\n\ntest_json = '''\n    {\n        \"empty_object\" : {},\n        \"empty_array\"  : [],\n        \"booleans\"     : { \"YES\" : true, \"NO\" : false },\n        \"numbers\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\n        \"strings\"      : [ \"This\", [ \"And\" , \"That\", \"And a \\\\\"b\" ] ],\n        \"nothing\"      : null\n    }\n'''\n\ndef test_earley():\n\n    json_parser = Lark(json_grammar, maybe_placeholders=False)\n    tree = json_parser.parse(test_json)\n\n    new_json = Reconstructor(json_parser).reconstruct(tree)\n    print (new_json)\n    print (json.loads(new_json) == json.loads(test_json))\n\ndef test_lalr():\n\n    json_parser = Lark(json_grammar, parser='lalr', maybe_placeholders=False)\n    tree = json_parser.parse(test_json)\n\n    new_json = Reconstructor(json_parser).reconstruct(tree)\n    print (new_json)\n    print (json.loads(new_json) == json.loads(test_json))\n\ntest_earley()\ntest_lalr()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: reconstruct_json.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/e6911b819cf4afa1ca68b5be22630e13/reconstruct_json.py)\n\n[`Download Jupyter notebook: reconstruct_json.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/adf07a4514e9cfb278aef018e6994028/reconstruct_json.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/reconstruct_json.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Reconstruct a JSON — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html",
        "status_code": 200,
        "scrape_id": "df90c84a-40eb-4958-b816-4e6b8229e2cb",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Standalone example\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/standalone/index.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html \"Example Grammars\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html \"Standalone Parser\")\n\n* * *\n\n# Standalone example [](https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html\\#standalone-example \"Permalink to this heading\")\n\nTo initialize, cd to this folder, and run:\n\n```\n./create_standalone.sh\n\n```\n\nOr:\n\n```\npython -m lark.tools.standalone json.lark > json_parser.py\n\n```\n\nThen run using:\n\n```\npython json_parser_main.py <path-to.json>\n\n```\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_json_parser_main_thumb.png)\n\n[Standalone Parser](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html#sphx-glr-examples-standalone-json-parser-main-py)\n\nStandalone Parser\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/standalone/)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/standalone/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Standalone example — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html",
        "status_code": 200,
        "scrape_id": "4c8e8383-b5c8-48c5-9506-cc26df60a170",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.263Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/fc674523e7ef0712dfc331b1ddd10972/dynamic_complete.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Using lexer dynamic_complete\\n\\nDemonstrates how to use ``lexer='dynamic_complete'`` and ``ambiguity='explicit'``\\n\\nSometimes you have data that is highly ambiguous or 'broken' in some sense.\\nWhen using ``parser='earley'`` and ``lexer='dynamic_complete'``, Lark will be able\\nparse just about anything as long as there is a valid way to generate it from\\nthe Grammar, including looking 'into' the Regexes.\\n\\nThis examples shows how to parse a json input where the quotes have been\\nreplaced by underscores: ``{_foo_:{}, _bar_: [], _baz_: __}``\\nNotice that underscores might still appear inside strings, so a potentially\\nvalid reading of the above is:\\n``{\\\"foo_:{}, _bar\\\": [], \\\"baz\\\": \\\"\\\"}``\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from pprint import pprint\\n\\nfrom lark import Lark, Tree, Transformer, v_args\\nfrom lark.visitors import Transformer_InPlace\\n\\nGRAMMAR = r\\\"\\\"\\\"\\n%import common.SIGNED_NUMBER\\n%import common.WS_INLINE\\n%import common.NEWLINE\\n%ignore WS_INLINE\\n\\n?start: value\\n\\n?value: object\\n      | array\\n      | string\\n      | SIGNED_NUMBER      -> number\\n      | \\\"true\\\"             -> true\\n      | \\\"false\\\"            -> false\\n      | \\\"null\\\"             -> null\\n\\narray  : \\\"[\\\" (value (\\\",\\\" value)*)? \\\"]\\\"\\nobject : \\\"{\\\" (pair (\\\",\\\" pair)*)? \\\"}\\\"\\npair   : string \\\":\\\" value\\n\\nstring: STRING\\nSTRING : ESCAPED_STRING\\n\\nESCAPED_STRING: QUOTE_CHAR _STRING_ESC_INNER QUOTE_CHAR\\nQUOTE_CHAR: \\\"_\\\"\\n\\n_STRING_INNER: /.*/\\n_STRING_ESC_INNER: _STRING_INNER /(?<!\\\\\\\\)(\\\\\\\\\\\\\\\\)*?/\\n\\n\\\"\\\"\\\"\\n\\n\\ndef score(tree: Tree):\\n    \\\"\\\"\\\"\\n    Scores an option by how many children (and grand-children, and\\n    grand-grand-children, ...) it has.\\n    This means that the option with fewer large terminals gets selected\\n\\n    Between\\n        object\\n          pair\\n            string\\t_foo_\\n            object\\n          pair\\n            string\\t_bar_: [], _baz_\\n            string\\t__\\n\\n    and\\n\\n        object\\n          pair\\n            string\\t_foo_\\n            object\\n          pair\\n            string\\t_bar_\\n            array\\n          pair\\n            string\\t_baz_\\n            string\\t__\\n\\n    this will give the second a higher score. (9 vs 13)\\n    \\\"\\\"\\\"\\n    return sum(len(t.children) for t in tree.iter_subtrees())\\n\\n\\nclass RemoveAmbiguities(Transformer_InPlace):\\n    \\\"\\\"\\\"\\n    Selects an option to resolve an ambiguity using the score function above.\\n    Scores each option and selects the one with the higher score, e.g. the one\\n    with more nodes.\\n\\n    If there is a performance problem with the Tree having to many _ambig and\\n    being slow and to large, this can instead be written as a ForestVisitor.\\n    Look at the 'Custom SPPF Prioritizer' example.\\n    \\\"\\\"\\\"\\n    def _ambig(self, options):\\n        return max(options, key=score)\\n\\n\\nclass TreeToJson(Transformer):\\n    \\\"\\\"\\\"\\n    This is the same Transformer as the json_parser example.\\n    \\\"\\\"\\\"\\n    @v_args(inline=True)\\n    def string(self, s):\\n        return s[1:-1].replace('\\\\\\\\\\\"', '\\\"')\\n\\n    array = list\\n    pair = tuple\\n    object = dict\\n    number = v_args(inline=True)(float)\\n\\n    null = lambda self, _: None\\n    true = lambda self, _: True\\n    false = lambda self, _: False\\n\\n\\nparser = Lark(GRAMMAR, parser='earley', ambiguity=\\\"explicit\\\", lexer='dynamic_complete')\\n\\nEXAMPLES = [\\n    r'{_array_:[1,2,3]}',\\n\\n    r'{_abc_: _array must be of the following format [_1_, _2_, _3_]_}',\\n\\n    r'{_foo_:{}, _bar_: [], _baz_: __}',\\n\\n    r'{_error_:_invalid_client_, _error_description_:_AADSTS7000215: Invalid '\\n    r'client secret is provided.\\\\r\\\\nTrace ID: '\\n    r'a0a0aaaa-a0a0-0a00-000a-00a00aaa0a00\\\\r\\\\nCorrelation ID: '\\n    r'aa0aaa00-0aaa-0000-00a0-00000aaaa0aa\\\\r\\\\nTimestamp: 1997-10-10 00:00:00Z_, '\\n    r'_error_codes_:[7000215], _timestamp_:_1997-10-10 00:00:00Z_, '\\n    r'_trace_id_:_a0a0aaaa-a0a0-0a00-000a-00a00aaa0a00_, '\\n    r'_correlation_id_:_aa0aaa00-0aaa-0000-00a0-00000aaaa0aa_, '\\n    r'_error_uri_:_https://example.com_}',\\n\\n]\\nfor example in EXAMPLES:\\n    tree = parser.parse(example)\\n    tree = RemoveAmbiguities().transform(tree)\\n    result = TreeToJson().transform(tree)\\n    pprint(result)\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/fc674523e7ef0712dfc331b1ddd10972/dynamic_complete.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/fc674523e7ef0712dfc331b1ddd10972/dynamic_complete.ipynb",
        "status_code": 200,
        "scrape_id": "deca49f6-623d-4be2-93a7-5d8cd1c940b1",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/de026e34f2e30342f31740044e683d7b/eval_csv.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"Transformer for evaluating csv.lark\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Transformer\\n\\nclass CsvTreeToPandasDict(Transformer):\\n    INT = int\\n    FLOAT = float\\n    SIGNED_FLOAT = float\\n    WORD = str\\n    NON_SEPARATOR_STRING = str\\n\\n    def row(self, children):\\n        return children\\n\\n    def start(self, children):\\n        data = {}\\n\\n        header = children[0].children\\n        for heading in header:\\n            data[heading] = []\\n\\n        for row in children[1:]:\\n            for i, element in enumerate(row):\\n                data[header[i]].append(element)\\n\\n        return data\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/de026e34f2e30342f31740044e683d7b/eval_csv.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/de026e34f2e30342f31740044e683d7b/eval_csv.ipynb",
        "status_code": 200,
        "scrape_id": "e5f4bbaf-2ff1-4d1b-98a4-ceaf7c5734ec",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Standalone example](https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html)\n- Standalone Parser\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/standalone/json_parser_main.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/standalone/index.html \"Standalone example\") [Next](https://lark-parser.readthedocs.io/en/stable/grammar.html \"Grammar Reference\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html#sphx-glr-download-examples-standalone-json-parser-main-py)\nto download the full example code\n\n# Standalone Parser [](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html\\#standalone-parser \"Permalink to this heading\")\n\n> This example demonstrates how to generate and use the standalone parser,\n> using the JSON example.\n>\n> See README.md for more details.\n\n```\nimport sys\n\nfrom json_parser import Lark_StandAlone, Transformer, v_args\n\ninline_args = v_args(inline=True)\n\nclass TreeToJson(Transformer):\n    @inline_args\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = inline_args(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\nparser = Lark_StandAlone(transformer=TreeToJson())\n\nif __name__ == '__main__':\n    with open(sys.argv[1]) as f:\n        print(parser.parse(f.read()))\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: json_parser_main.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/55c526745700131cb7096e508b392be7/json_parser_main.py)\n\n[`Download Jupyter notebook: json_parser_main.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/222c07e0396620c7fabb1da7fda69ca9/json_parser_main.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/standalone/json_parser_main.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Standalone Parser — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html",
        "status_code": 200,
        "scrape_id": "6f3c1962-30ff-4c26-9e2c-15dd4d19a61e",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:41:59.934Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6619e43bab1bed7430fa709940e67aa2/templates.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Templates\\n\\nThis example shows how to use Lark's templates to achieve cleaner grammars\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\n\\ngrammar = r\\\"\\\"\\\"\\nstart: list | dict\\n\\nlist: \\\"[\\\" _seperated{atom, \\\",\\\"} \\\"]\\\"\\ndict: \\\"{\\\" _seperated{key_value, \\\",\\\"} \\\"}\\\"\\nkey_value: atom \\\":\\\" atom\\n\\n_seperated{x, sep}: x (sep x)*  // Define a sequence of 'x sep x sep x ...'\\n\\natom: NUMBER | ESCAPED_STRING\\n\\n%import common (NUMBER, ESCAPED_STRING, WS)\\n%ignore WS\\n\\\"\\\"\\\"\\n\\n\\nparser = Lark(grammar)\\n\\nprint(parser.parse('[1, \\\"a\\\", 2]'))\\nprint(parser.parse('{\\\"a\\\": 2, \\\"b\\\": 6}'))\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6619e43bab1bed7430fa709940e67aa2/templates.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6619e43bab1bed7430fa709940e67aa2/templates.ipynb",
        "status_code": 200,
        "scrape_id": "7fd1bf8e-7233-477e-b16e-6bf896ac4b5e",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.088Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/55c526745700131cb7096e508b392be7/json_parser_main.py",
      "markdown": "```\n\"\"\"\nStandalone Parser\n===================================\n\n    This example demonstrates how to generate and use the standalone parser,\n    using the JSON example.\n\n    See README.md for more details.\n\"\"\"\n\nimport sys\n\nfrom json_parser import Lark_StandAlone, Transformer, v_args\n\ninline_args = v_args(inline=True)\n\nclass TreeToJson(Transformer):\n    @inline_args\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = inline_args(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\nparser = Lark_StandAlone(transformer=TreeToJson())\n\nif __name__ == '__main__':\n    with open(sys.argv[1]) as f:\n        print(parser.parse(f.read()))\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/55c526745700131cb7096e508b392be7/json_parser_main.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/55c526745700131cb7096e508b392be7/json_parser_main.py",
        "status_code": 200,
        "scrape_id": "0b8de79d-7a7d-470c-8a37-6f8fd0360d9c",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/json_tutorial.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- JSON parser - Tutorial\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/json_tutorial.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/parsers.html \"Parsers\") [Next](https://lark-parser.readthedocs.io/en/stable/how_to_use.html \"How To Use Lark - Guide\")\n\n* * *\n\n# JSON parser - Tutorial [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#json-parser-tutorial \"Permalink to this heading\")\n\nLark is a parser - a program that accepts a grammar and text, and produces a structured tree that represents that text.\nIn this tutorial we will write a JSON parser in Lark, and explore Lark’s various features in the process.\n\nIt has 5 parts.\n\n1. Writing the grammar\n\n2. Creating the parser\n\n3. Shaping the tree\n\n4. Evaluating the tree\n\n5. Optimizing\n\n\nKnowledge assumed:\n\n- Using Python\n\n- A basic understanding of how to use regular expressions\n\n\n## Part 1 - The Grammar [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#part-1-the-grammar \"Permalink to this heading\")\n\nLark accepts its grammars in a format called [EBNF](https://www.wikiwand.com/en/Extended_Backus%E2%80%93Naur_form). It basically looks like this:\n\n```\nrule_name : list of rules and TERMINALS to match\n          | another possible list of items\n          | etc.\n\nTERMINAL: \"some text to match\"\n\n```\n\n( _a terminal is a string or a regular expression_)\n\nThe parser will try to match each rule (left-part) by matching its items (right-part) sequentially, trying each alternative (In practice, the parser is predictive so we don’t have to try every alternative).\n\nHow to structure those rules is beyond the scope of this tutorial, but often it’s enough to follow one’s intuition.\n\nIn the case of JSON, the structure is simple: A json document is either a list, or a dictionary, or a string/number/etc.\n\nThe dictionaries and lists are recursive, and contain other json documents (or “values”).\n\nLet’s write this structure in EBNF form:\n\n```\n    value: dict\n         | list\n         | STRING\n         | NUMBER\n         | \"true\" | \"false\" | \"null\"\n\n    list : \"[\" [value (\",\" value)*] \"]\"\n\n    dict : \"{\" [pair (\",\" pair)*] \"}\"\n    pair : STRING \":\" value\n\n```\n\nA quick explanation of the syntax:\n\n- Parenthesis let us group rules together.\n\n- rule\\* means _any amount_. That means, zero or more instances of that rule.\n\n- \\[rule\\] means _optional_. That means zero or one instance of that rule.\n\n\nLark also supports the rule+ operator, meaning one or more instances. It also supports the rule? operator which is another way to say _optional_.\n\nOf course, we still haven’t defined “STRING” and “NUMBER”. Luckily, both these literals are already defined in Lark’s common library:\n\n```\n    %import common.ESCAPED_STRING   -> STRING\n    %import common.SIGNED_NUMBER    -> NUMBER\n\n```\n\nThe arrow (->) renames the terminals. But that only adds obscurity in this case, so going forward we’ll just use their original names.\n\nWe’ll also take care of the white-space, which is part of the text, by simply matching and then throwing it away.\n\n```\n    %import common.WS\n    %ignore WS\n\n```\n\nWe tell our parser to ignore whitespace. Otherwise, we’d have to fill our grammar with WS terminals.\n\nBy the way, if you’re curious what these terminals signify, they are roughly equivalent to this:\n\n```\n    NUMBER : /-?\\d+(\\.\\d+)?([eE][+-]?\\d+)?/\n    STRING : /\".*?(?<!\\\\)\"/\n    %ignore /[ \\t\\n\\f\\r]+/\n\n```\n\nLark will accept this way of writing too, if you really want to complicate your life :)\n\nYou can find the original definitions in [common.lark](https://github.com/lark-parser/lark/blob/master/lark/grammars/common.lark).\nThey don’t strictly adhere to [json.org](https://json.org/) \\- but our purpose here is to accept json, not validate it.\n\nNotice that terminals are written in UPPER-CASE, while rules are written in lower-case.\nI’ll touch more on the differences between rules and terminals later.\n\n## Part 2 - Creating the Parser [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#part-2-creating-the-parser \"Permalink to this heading\")\n\nOnce we have our grammar, creating the parser is very simple.\n\nWe simply instantiate Lark, and tell it to accept a “value”:\n\n```\nfrom lark import Lark\njson_parser = Lark(r\"\"\"\n    value: dict\n         | list\n         | ESCAPED_STRING\n         | SIGNED_NUMBER\n         | \"true\" | \"false\" | \"null\"\n\n    list : \"[\" [value (\",\" value)*] \"]\"\n\n    dict : \"{\" [pair (\",\" pair)*] \"}\"\n    pair : ESCAPED_STRING \":\" value\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n    %ignore WS\n\n    \"\"\", start='value')\n\n```\n\nIt’s that simple! Let’s test it out:\n\n```\n>>> text = '{\"key\": [\"item0\", \"item1\", 3.14]}'\n>>> json_parser.parse(text)\nTree(value, [Tree(dict, [Tree(pair, [Token(STRING, \"key\"), Tree(value, [Tree(list, [Tree(value, [Token(STRING, \"item0\")]), Tree(value, [Token(STRING, \"item1\")]), Tree(value, [Token(NUMBER, 3.14)])])])])])])\n>>> print( _.pretty() )\nvalue\n  dict\n    pair\n      \"key\"\n      value\n        list\n          value\t\"item0\"\n          value\t\"item1\"\n          value\t3.14\n\n```\n\nAs promised, Lark automagically creates a tree that represents the parsed text.\n\nBut something is suspiciously missing from the tree. Where are the curly braces, the commas and all the other punctuation literals?\n\nLark automatically filters out literals from the tree, based on the following criteria:\n\n- Filter out string literals without a name, or with a name that starts with an underscore.\n\n- Keep regexps, even unnamed ones, unless their name starts with an underscore.\n\n\nUnfortunately, this means that it will also filter out literals like “true” and “false”, and we will lose that information. The next section, “Shaping the tree” deals with this issue, and others.\n\n## Part 3 - Shaping the Tree [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#part-3-shaping-the-tree \"Permalink to this heading\")\n\nWe now have a parser that can create a parse tree (or: AST), but the tree has some issues:\n\n1. “true”, “false” and “null” are filtered out (test it out yourself!)\n\n2. Is has useless branches, like _value_, that clutter-up our view.\n\n\nI’ll present the solution, and then explain it:\n\n```\n    ?value: dict\n          | list\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    ...\n\n    string : ESCAPED_STRING\n\n```\n\n1. Those little arrows signify _aliases_. An alias is a name for a specific part of the rule. In this case, we will name the _true/false/null_ matches, and this way we won’t lose the information. We also alias _SIGNED\\_NUMBER_ to mark it for later processing.\n\n2. The question-mark prefixing _value_ (”?value”) tells the tree-builder to inline this branch if it has only one member. In this case, _value_ will always have only one member, and will always be inlined.\n\n3. We turned the _ESCAPED\\_STRING_ terminal into a rule. This way it will appear in the tree as a branch. This is equivalent to aliasing (like we did for the number), but now _string_ can also be used elsewhere in the grammar (namely, in the _pair_ rule).\n\n\nHere is the new grammar:\n\n```\nfrom lark import Lark\njson_parser = Lark(r\"\"\"\n    ?value: dict\n          | list\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    list : \"[\" [value (\",\" value)*] \"]\"\n\n    dict : \"{\" [pair (\",\" pair)*] \"}\"\n    pair : string \":\" value\n\n    string : ESCAPED_STRING\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n    %ignore WS\n\n    \"\"\", start='value')\n\n```\n\nAnd let’s test it out:\n\n```\n>>> text = '{\"key\": [\"item0\", \"item1\", 3.14, true]}'\n>>> print( json_parser.parse(text).pretty() )\ndict\n  pair\n    string\t\"key\"\n    list\n      string\t\"item0\"\n      string\t\"item1\"\n      number\t3.14\n      true\n\n```\n\nAh! That is much much nicer.\n\n## Part 4 - Evaluating the tree [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#part-4-evaluating-the-tree \"Permalink to this heading\")\n\nIt’s nice to have a tree, but what we really want is a JSON object.\n\nThe way to do it is to evaluate the tree, using a Transformer.\n\nA transformer is a class with methods corresponding to branch names. For each branch, the appropriate method will be called with the children of the branch as its argument, and its return value will replace the branch in the tree.\n\nSo let’s write a partial transformer, that handles lists and dictionaries:\n\n```\nfrom lark import Transformer\n\nclass MyTransformer(Transformer):\n    def list(self, items):\n        return list(items)\n    def pair(self, key_value):\n        k, v = key_value\n        return k, v\n    def dict(self, items):\n        return dict(items)\n\n```\n\nAnd when we run it, we get this:\n\n```\n>>> tree = json_parser.parse(text)\n>>> MyTransformer().transform(tree)\n{Tree(string, [Token(ANONRE_1, \"key\")]): [Tree(string, [Token(ANONRE_1, \"item0\")]), Tree(string, [Token(ANONRE_1, \"item1\")]), Tree(number, [Token(ANONRE_0, 3.14)]), Tree(true, [])]}\n\n```\n\nThis is pretty close. Let’s write a full transformer that can handle the terminals too.\n\nAlso, our definitions of list and dict are a bit verbose. We can do better:\n\n```\nfrom lark import Transformer\n\nclass TreeToJson(Transformer):\n    def string(self, s):\n        (s,) = s\n        return s[1:-1]\n    def number(self, n):\n        (n,) = n\n        return float(n)\n\n    list = list\n    pair = tuple\n    dict = dict\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n```\n\nAnd when we run it:\n\n```\n>>> tree = json_parser.parse(text)\n>>> TreeToJson().transform(tree)\n{u'key': [u'item0', u'item1', 3.14, True]}\n\n```\n\nMagic!\n\n## Part 5 - Optimizing [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#part-5-optimizing \"Permalink to this heading\")\n\n### Step 1 - Benchmark [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#step-1-benchmark \"Permalink to this heading\")\n\nBy now, we have a fully working JSON parser, that can accept a string of JSON, and return its Pythonic representation.\n\nBut how fast is it?\n\nNow, of course there are JSON libraries for Python written in C, and we can never compete with them. But since this is applicable to any parser you would write in Lark, let’s see how far we can take this.\n\nThe first step for optimizing is to have a benchmark. For this benchmark I’m going to take data from [json-generator.com/](http://www.json-generator.com/). I took their default suggestion and changed it to 5000 objects. The result is a 6.6MB sparse JSON file.\n\nOur first program is going to be just a concatenation of everything we’ve done so far:\n\n```\nimport sys\nfrom lark import Lark, Transformer\n\njson_grammar = r\"\"\"\n    ?value: dict\n          | list\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    list : \"[\" [value (\",\" value)*] \"]\"\n\n    dict : \"{\" [pair (\",\" pair)*] \"}\"\n    pair : string \":\" value\n\n    string : ESCAPED_STRING\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n    %ignore WS\n    \"\"\"\n\nclass TreeToJson(Transformer):\n    def string(self, s):\n        (s,) = s\n        return s[1:-1]\n    def number(self, n):\n        (n,) = n\n        return float(n)\n\n    list = list\n    pair = tuple\n    dict = dict\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\njson_parser = Lark(json_grammar, start='value', lexer='basic')\n\nif __name__ == '__main__':\n    with open(sys.argv[1]) as f:\n        tree = json_parser.parse(f.read())\n        print(TreeToJson().transform(tree))\n\n```\n\nWe run it and get this:\n\n```\n$ time python tutorial_json.py json_data > /dev/null\n\nreal\t0m36.257s\nuser\t0m34.735s\nsys         0m1.361s\n\n```\n\nThat’s unsatisfactory time for a 6MB file. Maybe if we were parsing configuration or a small DSL, but we’re trying to handle large amount of data here.\n\nWell, turns out there’s quite a bit we can do about it!\n\n### Step 2 - LALR(1) [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#step-2-lalr-1 \"Permalink to this heading\")\n\nSo far we’ve been using the Earley algorithm, which is the default in Lark. Earley is powerful but slow. But it just so happens that our grammar is LR-compatible, and specifically LALR(1) compatible.\n\nSo let’s switch to LALR(1) and see what happens:\n\n```\njson_parser = Lark(json_grammar, start='value', parser='lalr')\n\n```\n\n```\n$ time python tutorial_json.py json_data > /dev/null\n\nreal        0m7.554s\nuser        0m7.352s\nsys         0m0.148s\n\n```\n\nAh, that’s much better. The resulting JSON is of course exactly the same. You can run it for yourself and see.\n\nIt’s important to note that not all grammars are LR-compatible, and so you can’t always switch to LALR(1). But there’s no harm in trying! If Lark lets you build the grammar, it means you’re good to go.\n\n### Step 3 - Tree-less LALR(1) [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#step-3-tree-less-lalr-1 \"Permalink to this heading\")\n\nSo far, we’ve built a full parse tree for our JSON, and then transformed it. It’s a convenient method, but it’s not the most efficient in terms of speed and memory. Luckily, Lark lets us avoid building the tree when parsing with LALR(1).\n\nHere’s the way to do it:\n\n```\njson_parser = Lark(json_grammar, start='value', parser='lalr', transformer=TreeToJson())\n\nif __name__ == '__main__':\n    with open(sys.argv[1]) as f:\n        print( json_parser.parse(f.read()) )\n\n```\n\nWe’ve used the transformer we’ve already written, but this time we plug it straight into the parser. Now it can avoid building the parse tree, and just send the data straight into our transformer. The _parse()_ method now returns the transformed JSON, instead of a tree.\n\nLet’s benchmark it:\n\n```\nreal\t0m4.866s\nuser\t0m4.722s\nsys \t0m0.121s\n\n```\n\nThat’s a measurable improvement! Also, this way is more memory efficient. Check out the benchmark table at the end to see just how much.\n\nAs a general practice, it’s recommended to work with parse trees, and only skip the tree-builder when your transformer is already working.\n\n### Step 4 - PyPy [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#step-4-pypy \"Permalink to this heading\")\n\nPyPy is a JIT engine for running Python, and it’s designed to be a drop-in replacement.\n\nLark is written purely in Python, which makes it very suitable for PyPy.\n\nLet’s get some free performance:\n\n```\n$ time pypy tutorial_json.py json_data > /dev/null\n\nreal\t0m1.397s\nuser\t0m1.296s\nsys \t0m0.083s\n\n```\n\nPyPy is awesome!\n\n### Conclusion [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#conclusion \"Permalink to this heading\")\n\nWe’ve brought the run-time down from 36 seconds to 1.1 seconds, in a series of small and simple steps.\n\nNow let’s compare the benchmarks in a nicely organized table.\n\nI measured memory consumption using a little script called [memusg](https://gist.github.com/netj/526585)\n\n| Code | CPython Time | PyPy Time | CPython Mem | PyPy Mem |\n| --- | --- | --- | --- | --- |\n| Lark - Earley _(with lexer)_ | 42s | 4s | 1167M | 608M |\n| Lark - LALR(1) | 8s | 1.53s | 453M | 266M |\n| Lark - LALR(1) tree-less | 4.76s | 1.23s | 70M | 134M |\n| PyParsing ( [Parser](https://github.com/pyparsing/pyparsing/blob/master/examples/jsonParser.py)) | 32s | 3.53s | 443M | 225M |\n| funcparserlib ( [Parser](https://github.com/vlasovskikh/funcparserlib/blob/master/tests/json.py)) | 8.5s | 1.3s | 483M | 293M |\n| Parsimonious ( [Parser](https://gist.github.com/reclosedev/5222560)) | ? | 5.7s | ? | 1545M |\n\nI added a few other parsers for comparison. PyParsing and funcparselib fair pretty well in their memory usage (they don’t build a tree), but they can’t compete with the run-time speed of LALR(1).\n\nThese benchmarks are for Lark’s alpha version. I already have several optimizations planned that will significantly improve run-time speed.\n\nOnce again, shout-out to PyPy for being so effective.\n\n## Afterword [](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html\\#afterword \"Permalink to this heading\")\n\nThis is the end of the tutorial. I hoped you liked it and learned a little about Lark.\n\nTo see what else you can do with Lark, check out the [examples](https://lark-parser.readthedocs.io/examples).\n\nRead the documentation here: https://lark-parser.readthedocs.io/en/latest/\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/json_tutorial.html)**[stable](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "JSON parser - Tutorial — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/json_tutorial.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/json_tutorial.html",
        "status_code": 200,
        "scrape_id": "7de6d34c-e876-4c12-b9da-27c1bca9421c",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6d1927842b20958cbf08c916e786d2d0/_json_parser.py",
      "markdown": "```\n\"\"\"\nSimple JSON Parser\n==================\n\nThe code is short and clear, and outperforms every other parser (that's written in Python).\nFor an explanation, check out the JSON parser tutorial at /docs/json_tutorial.md\n\n(this is here for use by the other examples)\n\"\"\"\nfrom lark import Lark, Transformer, v_args\n\njson_grammar = r\"\"\"\n    ?start: value\n\n    ?value: object\n          | array\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    array  : \"[\" [value (\",\" value)*] \"]\"\n    object : \"{\" [pair (\",\" pair)*] \"}\"\n    pair   : string \":\" value\n\n    string : ESCAPED_STRING\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n\n    %ignore WS\n\"\"\"\n\nclass TreeToJson(Transformer):\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n### Create the JSON parser with Lark, using the LALR algorithm\njson_parser = Lark(json_grammar, parser='lalr',\n                   # Using the basic lexer isn't required, and isn't usually recommended.\n                   # But, it's good enough for JSON, and it's slightly faster.\n                   lexer='basic',\n                   # Disabling propagate_positions and placeholders slightly improves speed\n                   propagate_positions=False,\n                   maybe_placeholders=False,\n                   # Using an internal transformer is faster and more memory efficient\n                   transformer=TreeToJson())\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6d1927842b20958cbf08c916e786d2d0/_json_parser.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6d1927842b20958cbf08c916e786d2d0/_json_parser.py",
        "status_code": 200,
        "scrape_id": "3d61c6c5-88cb-4ff4-b30d-15833dbcd730",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.074Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/tools.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Tools (Stand-alone, Nearley)\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/tools.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/forest.html \"Working with the SPPF\")\n\n* * *\n\n# Tools (Stand-alone, Nearley) [](https://lark-parser.readthedocs.io/en/stable/tools.html\\#tools-stand-alone-nearley \"Permalink to this heading\")\n\n## Stand-alone parser [](https://lark-parser.readthedocs.io/en/stable/tools.html\\#stand-alone-parser \"Permalink to this heading\")\n\nLark can generate a stand-alone LALR(1) parser from a grammar.\n\nThe resulting module provides the same interface as Lark, but with a fixed grammar, and reduced functionality.\n\nRun using:\n\n```\npython -m lark.tools.standalone\n\n```\n\nFor a play-by-play, read the [tutorial](http://blog.erezsh.com/create-a-stand-alone-lalr1-parser-in-python/)\n\n## Importing grammars from Nearley.js [](https://lark-parser.readthedocs.io/en/stable/tools.html\\#importing-grammars-from-nearley-js \"Permalink to this heading\")\n\nLark comes with a tool to convert grammars from [Nearley](https://github.com/Hardmath123/nearley), a popular Earley library for Javascript. It uses [Js2Py](https://github.com/PiotrDabkowski/Js2Py) to convert and run the Javascript postprocessing code segments.\n\n### Requirements [](https://lark-parser.readthedocs.io/en/stable/tools.html\\#requirements \"Permalink to this heading\")\n\n1. Install Lark with the `nearley` component:\n\n\n```\npip install lark[nearley]\n\n```\n\n1. Acquire a copy of the Nearley codebase. This can be done using:\n\n\n```\ngit clone https://github.com/Hardmath123/nearley\n\n```\n\n### Usage [](https://lark-parser.readthedocs.io/en/stable/tools.html\\#usage \"Permalink to this heading\")\n\nThe tool can be run using:\n\n```\npython -m lark.tools.nearley <grammar.ne> <start_rule> <path_to_nearley_repo>\n\n```\n\nHere’s an example of how to import nearley’s calculator example into Lark:\n\n```\ngit clone https://github.com/Hardmath123/nearley\npython -m lark.tools.nearley nearley/examples/calculator/arithmetic.ne main ./nearley > ncalc.py\n\n```\n\nYou can use the output as a regular python module:\n\n```\n>>> import ncalc\n>>> ncalc.parse('sin(pi/4) ^ e')\n0.38981434460254655\n\n```\n\nThe Nearley converter also supports an experimental converter for newer JavaScript (ES6+), using the `--es6` flag:\n\n```\ngit clone https://github.com/Hardmath123/nearley\npython -m lark.tools.nearley nearley/examples/calculator/arithmetic.ne main nearley --es6 > ncalc.py\n\n```\n\n### Notes [](https://lark-parser.readthedocs.io/en/stable/tools.html\\#notes \"Permalink to this heading\")\n\n- Lark currently cannot import templates from Nearley\n\n- Lark currently cannot export grammars to Nearley\n\n\nThese might get added in the future, if enough users ask for them.\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/tools.html)**[stable](https://lark-parser.readthedocs.io/en/stable/tools.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Tools (Stand-alone, Nearley) — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/tools.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/tools.html",
        "status_code": 200,
        "scrape_id": "7c249e54-9527-479a-bc36-c5908696f428",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.245Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Grammar Composition](https://lark-parser.readthedocs.io/en/stable/examples/composition/index.html)\n- <no title>\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/composition/eval_json.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/composition/index.html \"Grammar Composition\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html \"<no title>\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html#sphx-glr-download-examples-composition-eval-json-py)\nto download the full example code\n\nTransformer for evaluating json.lark\n\n```\nfrom lark import Transformer, v_args\n\nclass JsonTreeToJson(Transformer):\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: eval_json.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/11091a0f6990e281219479476971fa12/eval_json.py)\n\n[`Download Jupyter notebook: eval_json.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/59e28e5e93b13914beea3268d124ef92/eval_json.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/composition/eval_json.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "<no title> — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html",
        "status_code": 200,
        "scrape_id": "5277d44a-c681-4ba3-987f-01775640dcc2",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/how_to_develop.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- How to develop Lark - Guide\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/how_to_develop.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/how_to_use.html \"How To Use Lark - Guide\") [Next](https://lark-parser.readthedocs.io/en/stable/recipes.html \"Recipes\")\n\n* * *\n\n# How to develop Lark - Guide [](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html\\#how-to-develop-lark-guide \"Permalink to this heading\")\n\nThere are many ways you can help the project:\n\n- Help solve issues\n\n- Improve the documentation\n\n- Write new grammars for Lark’s library\n\n- Write a blog post introducing Lark to your audience\n\n- Port Lark to another language\n\n- Help with code development\n\n\nIf you’re interested in taking one of these on, contact us on [Gitter](https://gitter.im/lark-parser/Lobby) or [Github Discussion](https://github.com/lark-parser/lark/discussions), and we will provide more details and assist you in the process.\n\n## Code Style [](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html\\#code-style \"Permalink to this heading\")\n\nLark does not follow a predefined code style.\nWe accept any code style that makes sense, as long as it’s Pythonic and easy to read.\n\n## Unit Tests [](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html\\#unit-tests \"Permalink to this heading\")\n\nLark comes with an extensive set of tests. Many of the tests will run several times, once for each parser configuration.\n\nTo run the tests, just go to the lark project root, and run the command:\n\n```\npython -m tests\n\n```\n\nor\n\n```\npypy -m tests\n\n```\n\nFor a list of supported interpreters, you can consult the `tox.ini` file.\n\nYou can also run a single unittest using its class and method name, for example:\n\n```\n##   test_package test_class_name.test_function_name\npython -m tests TestLalrBasic.test_keep_all_tokens\n\n```\n\n### tox [](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html\\#tox \"Permalink to this heading\")\n\nTo run all Unit Tests with tox,\ninstall tox and Python 2.7 up to the latest python interpreter supported (consult the file tox.ini).\nThen,\nrun the command `tox` on the root of this project (where the main setup.py file is on).\n\nAnd, for example,\nif you would like to only run the Unit Tests for Python version 2.7,\nyou can run the command `tox -e py27`\n\n### pytest [](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html\\#pytest \"Permalink to this heading\")\n\nYou can also run the tests using pytest:\n\n```\npytest tests\n\n```\n\n### Using setup.py [](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html\\#using-setup-py \"Permalink to this heading\")\n\nAnother way to run the tests is using setup.py:\n\n```\npython setup.py test\n\n```\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/how_to_develop.html)**[stable](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "How to develop Lark - Guide — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/how_to_develop.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/how_to_develop.html",
        "status_code": 200,
        "scrape_id": "eadb8260-661c-4844-8886-1ee3761e1b35",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2d7086e8ce7628b916237820c20847e4/tree_forest_transformer.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Transform a Forest\\n\\nThis example demonstrates how to subclass ``TreeForestTransformer`` to\\ndirectly transform a SPPF.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\nfrom lark.parsers.earley_forest import TreeForestTransformer, handles_ambiguity, Discard\\n\\nclass CustomTransformer(TreeForestTransformer):\\n\\n    @handles_ambiguity\\n    def sentence(self, trees):\\n        return next(tree for tree in trees if tree.data == 'simple')\\n\\n    def simple(self, children):\\n        children.append('.')\\n        return self.tree_class('simple', children)\\n\\n    def adj(self, children):\\n        return Discard\\n\\n    def __default_token__(self, token):\\n        return token.capitalize()\\n\\ngrammar = \\\"\\\"\\\"\\n    sentence: noun verb noun        -> simple\\n            | noun verb \\\"like\\\" noun -> comparative\\n\\n    noun: adj? NOUN\\n    verb: VERB\\n    adj: ADJ\\n\\n    NOUN: \\\"flies\\\" | \\\"bananas\\\" | \\\"fruit\\\"\\n    VERB: \\\"like\\\" | \\\"flies\\\"\\n    ADJ: \\\"fruit\\\"\\n\\n    %import common.WS\\n    %ignore WS\\n\\\"\\\"\\\"\\n\\nparser = Lark(grammar, start='sentence', ambiguity='forest')\\nsentence = 'fruit flies like bananas'\\nforest = parser.parse(sentence)\\n\\ntree = CustomTransformer(resolve_ambiguity=False).transform(forest)\\nprint(tree.pretty())\\n\\n# Output:\\n#\\n# simple\\n#   noun  Flies\\n#   verb  Like\\n#   noun  Bananas\\n#   .\\n#\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2d7086e8ce7628b916237820c20847e4/tree_forest_transformer.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2d7086e8ce7628b916237820c20847e4/tree_forest_transformer.ipynb",
        "status_code": 200,
        "scrape_id": "55e23e42-9bac-4d30-8564-6c2c612a1352",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.088Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/50b59008a60a728670b293084a6fe042/calc.py",
      "markdown": "```\n\"\"\"\nBasic calculator\n================\n\nA simple example of a REPL calculator\n\nThis example shows how to write a basic calculator with variables.\n\"\"\"\nfrom lark import Lark, Transformer, v_args\n\ntry:\n    input = raw_input   # For Python2 compatibility\nexcept NameError:\n    pass\n\ncalc_grammar = \"\"\"\n    ?start: sum\n          | NAME \"=\" sum    -> assign_var\n\n    ?sum: product\n        | sum \"+\" product   -> add\n        | sum \"-\" product   -> sub\n\n    ?product: atom\n        | product \"*\" atom  -> mul\n        | product \"/\" atom  -> div\n\n    ?atom: NUMBER           -> number\n         | \"-\" atom         -> neg\n         | NAME             -> var\n         | \"(\" sum \")\"\n\n    %import common.CNAME -> NAME\n    %import common.NUMBER\n    %import common.WS_INLINE\n\n    %ignore WS_INLINE\n\"\"\"\n\n@v_args(inline=True)    # Affects the signatures of the methods\nclass CalculateTree(Transformer):\n    from operator import add, sub, mul, truediv as div, neg\n    number = float\n\n    def __init__(self):\n        self.vars = {}\n\n    def assign_var(self, name, value):\n        self.vars[name] = value\n        return value\n\n    def var(self, name):\n        try:\n            return self.vars[name]\n        except KeyError:\n            raise Exception(\"Variable not found: %s\" % name)\n\ncalc_parser = Lark(calc_grammar, parser='lalr', transformer=CalculateTree())\ncalc = calc_parser.parse\n\ndef main():\n    while True:\n        try:\n            s = input('> ')\n        except EOFError:\n            break\n        print(calc(s))\n\ndef test():\n    print(calc(\"a = 1+2\"))\n    print(calc(\"1+a*-3\"))\n\nif __name__ == '__main__':\n    # test()\n    main()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/50b59008a60a728670b293084a6fe042/calc.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/50b59008a60a728670b293084a6fe042/calc.py",
        "status_code": 200,
        "scrape_id": "aa8a7fe9-1810-4db9-96fc-adec0e4db29a",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.058Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Custom SPPF Prioritizer\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/prioritizer.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html \"Simple JSON Parser\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html \"Python 3 to Python 2 converter (tree templates)\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html#sphx-glr-download-examples-advanced-prioritizer-py)\nto download the full example code\n\n# Custom SPPF Prioritizer [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html\\#custom-sppf-prioritizer \"Permalink to this heading\")\n\nThis example demonstrates how to subclass `ForestVisitor` to make a custom\nSPPF node prioritizer to be used in conjunction with `TreeForestTransformer`.\n\nOur prioritizer will count the number of descendants of a node that are tokens.\nBy negating this count, our prioritizer will prefer nodes with fewer token\ndescendants. Thus, we choose the more specific parse.\n\n```\nfrom lark import Lark\nfrom lark.parsers.earley_forest import ForestVisitor, TreeForestTransformer\n\nclass TokenPrioritizer(ForestVisitor):\n\n    def visit_symbol_node_in(self, node):\n        # visit the entire forest by returning node.children\n        return node.children\n\n    def visit_packed_node_in(self, node):\n        return node.children\n\n    def visit_symbol_node_out(self, node):\n        priority = 0\n        for child in node.children:\n            # Tokens do not have a priority attribute\n            # count them as -1\n            priority += getattr(child, 'priority', -1)\n        node.priority = priority\n\n    def visit_packed_node_out(self, node):\n        priority = 0\n        for child in node.children:\n            priority += getattr(child, 'priority', -1)\n        node.priority = priority\n\n    def on_cycle(self, node, path):\n        raise Exception(\"Oops, we encountered a cycle.\")\n\ngrammar = \"\"\"\nstart: hello \" \" world | hello_world\nhello: \"Hello\"\nworld: \"World\"\nhello_world: \"Hello World\"\n\"\"\"\n\nparser = Lark(grammar, parser='earley', ambiguity='forest')\nforest = parser.parse(\"Hello World\")\n\nprint(\"Default prioritizer:\")\ntree = TreeForestTransformer(resolve_ambiguity=True).transform(forest)\nprint(tree.pretty())\n\nforest = parser.parse(\"Hello World\")\n\nprint(\"Custom prioritizer:\")\ntree = TreeForestTransformer(resolve_ambiguity=True, prioritizer=TokenPrioritizer()).transform(forest)\nprint(tree.pretty())\n\n# Output:\n#\n# Default prioritizer:\n# start\n#   hello Hello\n#\n#   world World\n#\n# Custom prioritizer:\n# start\n#   hello_world   Hello World\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: prioritizer.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/3c07a7adfbea6387847af2b079a58ed6/prioritizer.py)\n\n[`Download Jupyter notebook: prioritizer.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/6dea8dbfb244508aaa3b8283470f8c2d/prioritizer.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/prioritizer.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Custom SPPF Prioritizer — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html",
        "status_code": 200,
        "scrape_id": "4b7677cd-cd02-4057-9fcc-224a13e80948",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/visitors.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Transformers & Visitors\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/visitors.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/classes.html \"API Reference\") [Next](https://lark-parser.readthedocs.io/en/stable/forest.html \"Working with the SPPF\")\n\n* * *\n\n# Transformers & Visitors [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#transformers-visitors \"Permalink to this heading\")\n\nTransformers & Visitors provide a convenient interface to process the\nparse-trees that Lark returns.\n\nThey are used by inheriting from the correct class (visitor or transformer),\nand implementing methods corresponding to the rule you wish to process. Each\nmethod accepts the children as an argument. That can be modified using the\n`v_args` decorator, which allows one to inline the arguments (akin to `*args`),\nor add the tree `meta` property as an argument.\n\nSee: [visitors.py](https://github.com/lark-parser/lark/blob/master/lark/visitors.py)\n\n## Visitor [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#visitor \"Permalink to this heading\")\n\nVisitors visit each node of the tree, and run the appropriate method on it according to the node’s data.\n\nThey work bottom-up, starting with the leaves and ending at the root of the tree.\n\nThere are two classes that implement the visitor interface:\n\n- `Visitor`: Visit every node (without recursion)\n\n- `Visitor_Recursive`: Visit every node using recursion. Slightly faster.\n\n\nExample:\n\n```\nclass IncreaseAllNumbers(Visitor):\n    def number(self, tree):\n        assert tree.data == \"number\"\n        tree.children[0] += 1\n\nIncreaseAllNumbers().visit(parse_tree)\n\n```\n\n_class_ lark.visitors.Visitor( _\\*args_, _\\*\\*kwds_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor \"Permalink to this definition\")\n\nTree visitor, non-recursive (can handle huge trees).\n\nVisiting a node calls its methods (provided by the user via inheritance) according to `tree.data`\n\nvisit( _tree:[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]_)→[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\] [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor.visit \"Permalink to this definition\")\n\nVisits the tree, starting with the leaves and finally the root (bottom-up)\n\nvisit\\_topdown( _tree:[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]_)→[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\] [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor.visit_topdown \"Permalink to this definition\")\n\nVisit the tree, starting at the root, and ending at the leaves (top-down)\n\n\\_\\_default\\_\\_( _tree_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor.__default__ \"Permalink to this definition\")\n\nDefault function that is called if there is no attribute matching `tree.data`\n\nCan be overridden. Defaults to doing nothing.\n\n_class_ lark.visitors.Visitor\\_Recursive( _\\*args_, _\\*\\*kwds_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor_Recursive \"Permalink to this definition\")\n\nBottom-up visitor, recursive.\n\nVisiting a node calls its methods (provided by the user via inheritance) according to `tree.data`\n\nSlightly faster than the non-recursive version.\n\nvisit( _tree:[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]_)→[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\] [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor_Recursive.visit \"Permalink to this definition\")\n\nVisits the tree, starting with the leaves and finally the root (bottom-up)\n\nvisit\\_topdown( _tree:[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]_)→[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\] [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor_Recursive.visit_topdown \"Permalink to this definition\")\n\nVisit the tree, starting at the root, and ending at the leaves (top-down)\n\n\\_\\_default\\_\\_( _tree_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Visitor_Recursive.__default__ \"Permalink to this definition\")\n\nDefault function that is called if there is no attribute matching `tree.data`\n\nCan be overridden. Defaults to doing nothing.\n\n## Interpreter [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#interpreter \"Permalink to this heading\")\n\n_class_ lark.visitors.Interpreter( _\\*args_, _\\*\\*kwds_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Interpreter \"Permalink to this definition\")\n\nInterpreter walks the tree starting at the root.\n\nVisits the tree, starting with the root and finally the leaves (top-down)\n\nFor each tree node, it calls its methods (provided by user via inheritance) according to `tree.data`.\n\nUnlike `Transformer` and `Visitor`, the Interpreter doesn’t automatically visit its sub-branches.\nThe user has to explicitly call `visit`, `visit_children`, or use the `@visit_children_decor`.\nThis allows the user to implement branching and loops.\n\nExample:\n\n```\nclass IncreaseSomeOfTheNumbers(Interpreter):\n    def number(self, tree):\n        tree.children[0] += 1\n\n    def skip(self, tree):\n        # skip this subtree. don't change any number node inside it.\n        pass\n\n    IncreaseSomeOfTheNumbers().visit(parse_tree)\n\n```\n\n## Transformer [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#transformer \"Permalink to this heading\")\n\n_class_ lark.visitors.Transformer( _visit\\_tokens:bool=True_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer \"Permalink to this definition\")\n\nTransformers work bottom-up (or depth-first), starting with visiting the leaves and working\ntheir way up until ending at the root of the tree.\n\nFor each node visited, the transformer will call the appropriate method (callbacks), according to the\nnode’s `data`, and use the returned value to replace the node, thereby creating a new tree structure.\n\nTransformers can be used to implement map & reduce patterns. Because nodes are reduced from leaf to root,\nat any point the callbacks may assume the children have already been transformed (if applicable).\n\nIf the transformer cannot find a method with the right name, it will instead call `__default__`, which by\ndefault creates a copy of the node.\n\nTo discard a node, return Discard ( `lark.visitors.Discard`).\n\n`Transformer` can do anything `Visitor` can do, but because it reconstructs the tree,\nit is slightly less efficient.\n\nA transformer without methods essentially performs a non-memoized partial deepcopy.\n\nAll these classes implement the transformer interface:\n\n- `Transformer` \\- Recursively transforms the tree. This is the one you probably want.\n\n- `Transformer_InPlace` \\- Non-recursive. Changes the tree in-place instead of returning new instances\n\n- `Transformer_InPlaceRecursive` \\- Recursive. Changes the tree in-place instead of returning new instances\n\n\nParameters:\n\n**visit\\_tokens** ( _bool_ _,_ _optional_) – Should the transformer visit tokens in addition to rules.\nSetting this to `False` is slightly faster. Defaults to `True`.\n(For processing ignored tokens, use the `lexer_callbacks` options)\n\ntransform( _tree:[Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]_)→\\_Return\\_T [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer.transform \"Permalink to this definition\")\n\nTransform the given tree, and return the final result\n\n\\_\\_mul\\_\\_( _other:Union\\[ [Transformer](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer \"lark.visitors.Transformer\"),TransformerChain\\[\\_Leaf\\_U,\\_Return\\_V\\]\\]_)→TransformerChain\\[\\_Leaf\\_T,\\_Return\\_V\\] [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer.__mul__ \"Permalink to this definition\")\n\nChain two transformers together, returning a new transformer.\n\n\\_\\_default\\_\\_( _data_, _children_, _meta_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer.__default__ \"Permalink to this definition\")\n\nDefault function that is called if there is no attribute matching `data`\n\nCan be overridden. Defaults to creating a new copy of the tree node (i.e. `return Tree(data, children, meta)`)\n\n\\_\\_default\\_token\\_\\_( _token_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer.__default_token__ \"Permalink to this definition\")\n\nDefault function that is called if there is no attribute matching `token.type`\n\nCan be overridden. Defaults to returning the token as-is.\n\nExample:\n\n```\nfrom lark import Tree, Transformer\n\nclass EvalExpressions(Transformer):\n    def expr(self, args):\n            return eval(args[0])\n\nt = Tree('a', [Tree('expr', ['1+2'])])\nprint(EvalExpressions().transform( t ))\n\n# Prints: Tree(a, [3])\n\n```\n\nExample:\n\n```\nclass T(Transformer):\n    INT = int\n    NUMBER = float\n    def NAME(self, name):\n        return lookup_dict.get(name, name)\n\nT(visit_tokens=True).transform(tree)\n\n```\n\n_class_ lark.visitors.Transformer\\_NonRecursive( _visit\\_tokens:bool=True_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer_NonRecursive \"Permalink to this definition\")\n\nSame as Transformer but non-recursive.\n\nLike Transformer, it doesn’t change the original tree.\n\nUseful for huge trees.\n\n_class_ lark.visitors.Transformer\\_InPlace( _visit\\_tokens:bool=True_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer_InPlace \"Permalink to this definition\")\n\nSame as Transformer, but non-recursive, and changes the tree in-place instead of returning new instances\n\nUseful for huge trees. Conservative in memory.\n\n_class_ lark.visitors.Transformer\\_InPlaceRecursive( _visit\\_tokens:bool=True_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer_InPlaceRecursive \"Permalink to this definition\")\n\nSame as Transformer, recursive, but changes the tree in-place instead of returning new instances\n\n## v\\_args [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#v-args \"Permalink to this heading\")\n\nlark.visitors.v\\_args( _inline:bool=False_, _meta:bool=False_, _tree:bool=False_, _wrapper:Optional\\[Callable\\]=None_)→Callable\\[\\[Union\\[Callable\\[\\[...\\],\\_Return\\_T\\],type\\]\\],Union\\[Callable\\[\\[...\\],\\_Return\\_T\\],type\\]\\] [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.v_args \"Permalink to this definition\")\n\nA convenience decorator factory for modifying the behavior of user-supplied visitor methods.\n\nBy default, callback methods of transformers/visitors accept one argument - a list of the node’s children.\n\n`v_args` can modify this behavior. When used on a transformer/visitor class definition,\nit applies to all the callback methods inside it.\n\n`v_args` can be applied to a single method, or to an entire class. When applied to both,\nthe options given to the method take precedence.\n\nParameters:\n\n- **inline** ( _bool_ _,_ _optional_) – Children are provided as `*args` instead of a list argument (not recommended for very long lists).\n\n- **meta** ( _bool_ _,_ _optional_) – Provides two arguments: `meta` and `children` (instead of just the latter)\n\n- **tree** ( _bool_ _,_ _optional_) – Provides the entire tree as the argument, instead of the children.\n\n- **wrapper** ( _function_ _,_ _optional_) – Provide a function to decorate all methods.\n\n\nExample\n\n```\n@v_args(inline=True)\nclass SolveArith(Transformer):\n    def add(self, left, right):\n        return left + right\n\n    @v_args(meta=True)\n    def mul(self, meta, children):\n        logger.info(f'mul at line {meta.line}')\n        left, right = children\n        return left * right\n\nclass ReverseNotation(Transformer_InPlace):\n    @v_args(tree=True)\n    def tree_node(self, tree):\n        tree.children = tree.children[::-1]\n\n```\n\n## merge\\_transformers [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#merge-transformers \"Permalink to this heading\")\n\nlark.visitors.merge\\_transformers( _base\\_transformer=None_, _\\*\\*transformers\\_to\\_merge_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.merge_transformers \"Permalink to this definition\")\n\nMerge a collection of transformers into the base\\_transformer, each into its own ‘namespace’.\n\nWhen called, it will collect the methods from each transformer, and assign them to base\\_transformer,\nwith their name prefixed with the given keyword, as `prefix__methodname`.\n\nThis function is especially useful for processing grammars that import other grammars,\nthereby creating some of their rules in a ‘namespace’. (i.e with a consistent name prefix).\nIn this case, the key for the transformer should match the name of the imported grammar.\n\nParameters:\n\n- **base\\_transformer** ( [_Transformer_](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer \"lark.visitors.Transformer\") _,_ _optional_) – The transformer that all other transformers will be added to.\n\n- **\\*\\*transformers\\_to\\_merge** – Keyword arguments, in the form of `name_prefix = transformer`.\n\n\nRaises:\n\n**AttributeError** – In case of a name collision in the merged methods\n\nExample\n\n```\nclass TBase(Transformer):\n    def start(self, children):\n        return children[0] + 'bar'\n\nclass TImportedGrammar(Transformer):\n    def foo(self, children):\n        return \"foo\"\n\ncomposed_transformer = merge_transformers(TBase(), imported=TImportedGrammar())\n\nt = Tree('start', [ Tree('imported__foo', []) ])\n\nassert composed_transformer.transform(t) == 'foobar'\n\n```\n\n## Discard [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#discard \"Permalink to this heading\")\n\n`Discard` is the singleton instance of `_DiscardType`.\n\n_class_ lark.visitors.\\_DiscardType [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors._DiscardType \"Permalink to this definition\")\n\nWhen the Discard value is returned from a transformer callback,\nthat node is discarded and won’t appear in the parent.\n\nNote\n\nThis feature is disabled when the transformer is provided to Lark\nusing the `transformer` keyword (aka Tree-less LALR mode).\n\nExample\n\n```\nclass T(Transformer):\n    def ignore_tree(self, children):\n        return Discard\n\n    def IGNORE_TOKEN(self, token):\n        return Discard\n\n```\n\n## VisitError [](https://lark-parser.readthedocs.io/en/stable/visitors.html\\#visiterror \"Permalink to this heading\")\n\n_class_ lark.exceptions.VisitError( _rule_, _obj_, _orig\\_exc_) [](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.exceptions.VisitError \"Permalink to this definition\")\n\nVisitError is raised when visitors are interrupted by an exception\n\nIt provides the following attributes for inspection:\n\nParameters:\n\n- **rule** – the name of the visit rule that failed\n\n- **obj** – the tree-node or token that was being processed\n\n- **orig\\_exc** – the exception that cause it to fail\n\n\nNote: These parameters are available as attributes\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/visitors.html)**[stable](https://lark-parser.readthedocs.io/en/stable/visitors.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Transformers & Visitors — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/visitors.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/visitors.html",
        "status_code": 200,
        "scrape_id": "7616c473-6891-4702-b6cd-e4bbdc883637",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.074Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9897e3d2b4b242b1ded5769f50c0eea1/json_parser.py",
      "markdown": "```\n\"\"\"\nSimple JSON Parser\n==================\n\nThe code is short and clear, and outperforms every other parser (that's written in Python).\nFor an explanation, check out the JSON parser tutorial at /docs/json_tutorial.md\n\"\"\"\nimport sys\n\nfrom lark import Lark, Transformer, v_args\n\njson_grammar = r\"\"\"\n    ?start: value\n\n    ?value: object\n          | array\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    array  : \"[\" [value (\",\" value)*] \"]\"\n    object : \"{\" [pair (\",\" pair)*] \"}\"\n    pair   : string \":\" value\n\n    string : ESCAPED_STRING\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n\n    %ignore WS\n\"\"\"\n\nclass TreeToJson(Transformer):\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n### Create the JSON parser with Lark, using the Earley algorithm\n# json_parser = Lark(json_grammar, parser='earley', lexer='basic')\n# def parse(x):\n#     return TreeToJson().transform(json_parser.parse(x))\n\n### Create the JSON parser with Lark, using the LALR algorithm\njson_parser = Lark(json_grammar, parser='lalr',\n                   # Using the basic lexer isn't required, and isn't usually recommended.\n                   # But, it's good enough for JSON, and it's slightly faster.\n                   lexer='basic',\n                   # Disabling propagate_positions and placeholders slightly improves speed\n                   propagate_positions=False,\n                   maybe_placeholders=False,\n                   # Using an internal transformer is faster and more memory efficient\n                   transformer=TreeToJson())\nparse = json_parser.parse\n\ndef test():\n    test_json = '''\n        {\n            \"empty_object\" : {},\n            \"empty_array\"  : [],\n            \"booleans\"     : { \"YES\" : true, \"NO\" : false },\n            \"numbers\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\n            \"strings\"      : [ \"This\", [ \"And\" , \"That\", \"And a \\\\\"b\" ] ],\n            \"nothing\"      : null\n        }\n    '''\n\n    j = parse(test_json)\n    print(j)\n    import json\n    assert j == json.loads(test_json)\n\nif __name__ == '__main__':\n    # test()\n    with open(sys.argv[1]) as f:\n        print(parse(f.read()))\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9897e3d2b4b242b1ded5769f50c0eea1/json_parser.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9897e3d2b4b242b1ded5769f50c0eea1/json_parser.py",
        "status_code": 200,
        "scrape_id": "3342aa02-4d1b-46db-9884-a8a66817e7b7",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/22081051f999d4e0753796b91b344ee3/dynamic_complete.py",
      "markdown": "```\n\"\"\"\nUsing lexer dynamic_complete\n============================\n\nDemonstrates how to use ``lexer='dynamic_complete'`` and ``ambiguity='explicit'``\n\nSometimes you have data that is highly ambiguous or 'broken' in some sense.\nWhen using ``parser='earley'`` and ``lexer='dynamic_complete'``, Lark will be able\nparse just about anything as long as there is a valid way to generate it from\nthe Grammar, including looking 'into' the Regexes.\n\nThis examples shows how to parse a json input where the quotes have been\nreplaced by underscores: ``{_foo_:{}, _bar_: [], _baz_: __}``\nNotice that underscores might still appear inside strings, so a potentially\nvalid reading of the above is:\n``{\"foo_:{}, _bar\": [], \"baz\": \"\"}``\n\"\"\"\nfrom pprint import pprint\n\nfrom lark import Lark, Tree, Transformer, v_args\nfrom lark.visitors import Transformer_InPlace\n\nGRAMMAR = r\"\"\"\n%import common.SIGNED_NUMBER\n%import common.WS_INLINE\n%import common.NEWLINE\n%ignore WS_INLINE\n\n?start: value\n\n?value: object\n      | array\n      | string\n      | SIGNED_NUMBER      -> number\n      | \"true\"             -> true\n      | \"false\"            -> false\n      | \"null\"             -> null\n\narray  : \"[\" (value (\",\" value)*)? \"]\"\nobject : \"{\" (pair (\",\" pair)*)? \"}\"\npair   : string \":\" value\n\nstring: STRING\nSTRING : ESCAPED_STRING\n\nESCAPED_STRING: QUOTE_CHAR _STRING_ESC_INNER QUOTE_CHAR\nQUOTE_CHAR: \"_\"\n\n_STRING_INNER: /.*/\n_STRING_ESC_INNER: _STRING_INNER /(?<!\\\\)(\\\\\\\\)*?/\n\n\"\"\"\n\ndef score(tree: Tree):\n    \"\"\"\n    Scores an option by how many children (and grand-children, and\n    grand-grand-children, ...) it has.\n    This means that the option with fewer large terminals gets selected\n\n    Between\n        object\n          pair\n            string\t_foo_\n            object\n          pair\n            string\t_bar_: [], _baz_\n            string\t__\n\n    and\n\n        object\n          pair\n            string\t_foo_\n            object\n          pair\n            string\t_bar_\n            array\n          pair\n            string\t_baz_\n            string\t__\n\n    this will give the second a higher score. (9 vs 13)\n    \"\"\"\n    return sum(len(t.children) for t in tree.iter_subtrees())\n\nclass RemoveAmbiguities(Transformer_InPlace):\n    \"\"\"\n    Selects an option to resolve an ambiguity using the score function above.\n    Scores each option and selects the one with the higher score, e.g. the one\n    with more nodes.\n\n    If there is a performance problem with the Tree having to many _ambig and\n    being slow and to large, this can instead be written as a ForestVisitor.\n    Look at the 'Custom SPPF Prioritizer' example.\n    \"\"\"\n    def _ambig(self, options):\n        return max(options, key=score)\n\nclass TreeToJson(Transformer):\n    \"\"\"\n    This is the same Transformer as the json_parser example.\n    \"\"\"\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\nparser = Lark(GRAMMAR, parser='earley', ambiguity=\"explicit\", lexer='dynamic_complete')\n\nEXAMPLES = [\\\n    r'{_array_:[1,2,3]}',\\\n\\\n    r'{_abc_: _array must be of the following format [_1_, _2_, _3_]_}',\\\n\\\n    r'{_foo_:{}, _bar_: [], _baz_: __}',\\\n\\\n    r'{_error_:_invalid_client_, _error_description_:_AADSTS7000215: Invalid '\\\n    r'client secret is provided.\\r\\nTrace ID: '\\\n    r'a0a0aaaa-a0a0-0a00-000a-00a00aaa0a00\\r\\nCorrelation ID: '\\\n    r'aa0aaa00-0aaa-0000-00a0-00000aaaa0aa\\r\\nTimestamp: 1997-10-10 00:00:00Z_, '\\\n    r'_error_codes_:[7000215], _timestamp_:_1997-10-10 00:00:00Z_, '\\\n    r'_trace_id_:_a0a0aaaa-a0a0-0a00-000a-00a00aaa0a00_, '\\\n    r'_correlation_id_:_aa0aaa00-0aaa-0000-00a0-00000aaaa0aa_, '\\\n    r'_error_uri_:_https://example.com_}',\\\n\\\n]\nfor example in EXAMPLES:\n    tree = parser.parse(example)\n    tree = RemoveAmbiguities().transform(tree)\n    result = TreeToJson().transform(tree)\n    pprint(result)\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/22081051f999d4e0753796b91b344ee3/dynamic_complete.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/22081051f999d4e0753796b91b344ee3/dynamic_complete.py",
        "status_code": 200,
        "scrape_id": "1e1d9c38-8cad-470f-9fb4-f289380239c0",
        "content_type": "text/x-python; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Error handling using an interactive parser\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/error_handling.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html \"Earley’s dynamic lexer\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html \"Reconstruct a JSON\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html#sphx-glr-download-examples-advanced-error-handling-py)\nto download the full example code\n\n# Error handling using an interactive parser [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html\\#error-handling-using-an-interactive-parser \"Permalink to this heading\")\n\nThis example demonstrates error handling using an interactive parser in LALR\n\nWhen the parser encounters an UnexpectedToken exception, it creates a\nan interactive parser with the current parse-state, and lets you control how\nto proceed step-by-step. When you’ve achieved the correct parse-state,\nyou can resume the run by returning True.\n\n```\nfrom lark import Token\n\nfrom _json_parser import json_parser\n\ndef ignore_errors(e):\n    if e.token.type == 'COMMA':\n        # Skip comma\n        return True\n    elif e.token.type == 'SIGNED_NUMBER':\n        # Try to feed a comma and retry the number\n        e.interactive_parser.feed_token(Token('COMMA', ','))\n        e.interactive_parser.feed_token(e.token)\n        return True\n\n    # Unhandled error. Will stop parse and raise exception\n    return False\n\ndef main():\n    s = \"[0 1, 2,, 3,,, 4, 5 6 ]\"\n    res = json_parser.parse(s, on_error=ignore_errors)\n    print(res)      # prints [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n\nmain()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: error_handling.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/3a11fd47a1fb670a6759747d618a244e/error_handling.py)\n\n[`Download Jupyter notebook: error_handling.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/5a9e0a0dc353e4a9357e2204639f6c76/error_handling.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/error_handling.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Error handling using an interactive parser — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html",
        "status_code": 200,
        "scrape_id": "f0c00bda-83dd-4f0f-bcb7-9fae6150331b",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.245Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Turtle DSL\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/turtle_dsl.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/calc.html \"Basic calculator\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html \"Simple JSON Parser\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html#sphx-glr-download-examples-turtle-dsl-py)\nto download the full example code\n\n# Turtle DSL [](https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html\\#turtle-dsl \"Permalink to this heading\")\n\nImplements a LOGO-like toy language for Python’s turtle, with interpreter.\n\n```\ntry:\n    input = raw_input   # For Python2 compatibility\nexcept NameError:\n    pass\n\nimport turtle\n\nfrom lark import Lark\n\nturtle_grammar = \"\"\"\n    start: instruction+\n\n    instruction: MOVEMENT NUMBER            -> movement\n               | \"c\" COLOR [COLOR]          -> change_color\n               | \"fill\" code_block          -> fill\n               | \"repeat\" NUMBER code_block -> repeat\n\n    code_block: \"{\" instruction+ \"}\"\n\n    MOVEMENT: \"f\"|\"b\"|\"l\"|\"r\"\n    COLOR: LETTER+\n\n    %import common.LETTER\n    %import common.INT -> NUMBER\n    %import common.WS\n    %ignore WS\n\"\"\"\n\nparser = Lark(turtle_grammar)\n\ndef run_instruction(t):\n    if t.data == 'change_color':\n        turtle.color(*t.children)   # We just pass the color names as-is\n\n    elif t.data == 'movement':\n        name, number = t.children\n        { 'f': turtle.fd,\n          'b': turtle.bk,\n          'l': turtle.lt,\n          'r': turtle.rt, }[name](int(number))\n\n    elif t.data == 'repeat':\n        count, block = t.children\n        for i in range(int(count)):\n            run_instruction(block)\n\n    elif t.data == 'fill':\n        turtle.begin_fill()\n        run_instruction(t.children[0])\n        turtle.end_fill()\n\n    elif t.data == 'code_block':\n        for cmd in t.children:\n            run_instruction(cmd)\n    else:\n        raise SyntaxError('Unknown instruction: %s' % t.data)\n\ndef run_turtle(program):\n    parse_tree = parser.parse(program)\n    for inst in parse_tree.children:\n        run_instruction(inst)\n\ndef main():\n    while True:\n        code = input('> ')\n        try:\n            run_turtle(code)\n        except Exception as e:\n            print(e)\n\ndef test():\n    text = \"\"\"\n        c red yellow\n        fill { repeat 36 {\n            f200 l170\n        }}\n    \"\"\"\n    run_turtle(text)\n\nif __name__ == '__main__':\n    # test()\n    main()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: turtle_dsl.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/9cadc23f6b1e9e52f35d3cb0a28053b0/turtle_dsl.py)\n\n[`Download Jupyter notebook: turtle_dsl.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/207f80f4ec59e1e363837373665f649f/turtle_dsl.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/turtle_dsl.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Turtle DSL — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html",
        "status_code": 200,
        "scrape_id": "788def38-086c-41a2-8263-ca5e7bc28a44",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/recipes.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Recipes\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/recipes.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html \"How to develop Lark - Guide\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/index.html \"Examples for Lark\")\n\n* * *\n\n# Recipes [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#recipes \"Permalink to this heading\")\n\nA collection of recipes to use Lark and its various features\n\n## Use a transformer to parse integer tokens [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#use-a-transformer-to-parse-integer-tokens \"Permalink to this heading\")\n\nTransformers are the common interface for processing matched rules and tokens.\n\nThey can be used during parsing for better performance.\n\n```\nfrom lark import Lark, Transformer\n\nclass T(Transformer):\n    def INT(self, tok):\n        \"Convert the value of `tok` from string to int, while maintaining line number & column.\"\n        return tok.update(value=int(tok))\n\nparser = Lark(\"\"\"\nstart: INT*\n%import common.INT\n%ignore \" \"\n\"\"\", parser=\"lalr\", transformer=T())\n\nprint(parser.parse('3 14 159'))\n\n```\n\nPrints out:\n\n```\nTree(start, [Token(INT, 3), Token(INT, 14), Token(INT, 159)])\n\n```\n\n## Collect all comments with lexer\\_callbacks [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#collect-all-comments-with-lexer-callbacks \"Permalink to this heading\")\n\n`lexer_callbacks` can be used to interface with the lexer as it generates tokens.\n\nIt accepts a dictionary of the form\n\n```\n{TOKEN_TYPE: callback}\n\n```\n\nWhere callback is of type `f(Token) -> Token`\n\nIt only works with the basic and contextual lexers.\n\nThis has the same effect of using a transformer, but can also process ignored tokens.\n\n```\nfrom lark import Lark\n\ncomments = []\n\nparser = Lark(\"\"\"\n    start: INT*\n\n    COMMENT: /#.*/\n\n    %import common (INT, WS)\n    %ignore COMMENT\n    %ignore WS\n\"\"\", parser=\"lalr\", lexer_callbacks={'COMMENT': comments.append})\n\nparser.parse(\"\"\"\n1 2 3  # hello\n# world\n4 5 6\n\"\"\")\n\nprint(comments)\n\n```\n\nPrints out:\n\n```\n[Token(COMMENT, '# hello'), Token(COMMENT, '# world')]\n\n```\n\n_Note: We don’t have to return a token, because comments are ignored_\n\n## CollapseAmbiguities [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#collapseambiguities \"Permalink to this heading\")\n\nParsing ambiguous texts with earley and `ambiguity='explicit'` produces a single tree with `_ambig` nodes to mark where the ambiguity occurred.\n\nHowever, it’s sometimes more convenient instead to work with a list of all possible unambiguous trees.\n\nLark provides a utility transformer for that purpose:\n\n```\nfrom lark import Lark, Tree, Transformer\nfrom lark.visitors import CollapseAmbiguities\n\ngrammar = \"\"\"\n    !start: x y\n\n    !x: \"a\" \"b\"\n      | \"ab\"\n      | \"abc\"\n\n    !y: \"c\" \"d\"\n      | \"cd\"\n      | \"d\"\n\n\"\"\"\nparser = Lark(grammar, ambiguity='explicit')\n\nt = parser.parse('abcd')\nfor x in CollapseAmbiguities().transform(t):\n    print(x.pretty())\n\n```\n\nThis prints out:\n\n```\nstart\nx\n    a\n    b\ny\n    c\n    d\n\nstart\nx     ab\ny     cd\n\nstart\nx     abc\ny     d\n\n```\n\nWhile convenient, this should be used carefully, as highly ambiguous trees will soon create an exponential explosion of such unambiguous derivations.\n\n## Keeping track of parents when visiting [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#keeping-track-of-parents-when-visiting \"Permalink to this heading\")\n\nThe following visitor assigns a `parent` attribute for every node in the tree.\n\nIf your tree nodes aren’t unique (if there is a shared Tree instance), the assert will fail.\n\n```\nclass Parent(Visitor):\n    def __default__(self, tree):\n        for subtree in tree.children:\n            if isinstance(subtree, Tree):\n                assert not hasattr(subtree, 'parent')\n                subtree.parent = proxy(tree)\n\n```\n\n## Unwinding VisitError after a transformer/visitor exception [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#unwinding-visiterror-after-a-transformer-visitor-exception \"Permalink to this heading\")\n\nErrors that happen inside visitors and transformers get wrapped inside a `VisitError` exception.\n\nThis can often be inconvenient, if you wish the actual error to propagate upwards, or if you want to catch it.\n\nBut, it’s easy to unwrap it at the point of calling the transformer, by catching it and raising the `VisitError.orig_exc` attribute.\n\nFor example:\n\n```\nfrom lark import Lark, Transformer\nfrom lark.visitors import VisitError\n\ntree = Lark('start: \"a\"').parse('a')\n\nclass T(Transformer):\n    def start(self, x):\n        raise KeyError(\"Original Exception\")\n\nt = T()\ntry:\n    print( t.transform(tree))\nexcept VisitError as e:\n    raise e.orig_exc\n\n```\n\n## Adding a Progress Bar to Parsing with tqdm [](https://lark-parser.readthedocs.io/en/stable/recipes.html\\#adding-a-progress-bar-to-parsing-with-tqdm \"Permalink to this heading\")\n\nParsing large files can take a long time, even with the `parser='lalr'` option. To make this process more user-friendly, it’s useful to add a progress bar. One way to achieve this is to use the `InteractiveParser` to display each token as it is processed. In this example, we use [tqdm](https://github.com/tqdm/tqdm), but a similar approach should work with GUIs.\n\n```\nfrom tqdm import tqdm\n\ndef parse_with_progress(parser: Lark, text: str, start=None):\n    last = 0\n    progress = tqdm(total=len(text))\n    pi = parser.parse_interactive(text, start=start)\n    for token in pi.iter_parse():\n        if token.end_pos is not None:\n            progress.update(token.end_pos - last)\n            last = token.end_pos\n    return pi.result\n\n```\n\nNote that we don’t simply wrap the iterable because tqdm would not be able to determine the total. Additionally, keep in mind that this implementation relies on the `InteractiveParser` and, therefore, only works with the `LALR(1)` parser, not `earley`.\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/recipes.html)**[stable](https://lark-parser.readthedocs.io/en/stable/recipes.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Recipes — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/recipes.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/recipes.html",
        "status_code": 200,
        "scrape_id": "5b0a52b3-f23f-4ef2-be29-d666c8a8f3a4",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Parsing Indentation\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/indented_tree.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/index.html \"Examples for Lark\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html \"Lark Grammar\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html#sphx-glr-download-examples-indented-tree-py)\nto download the full example code\n\n# Parsing Indentation [](https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html\\#parsing-indentation \"Permalink to this heading\")\n\nA demonstration of parsing indentation (“whitespace significant” language)\nand the usage of the Indenter class.\n\nSince indentation is context-sensitive, a postlex stage is introduced to\nmanufacture INDENT/DEDENT tokens.\n\nIt is crucial for the indenter that the NL\\_type matches\nthe spaces (and tabs) after the newline.\n\n```\nfrom lark import Lark\nfrom lark.indenter import Indenter\n\ntree_grammar = r\"\"\"\n    ?start: _NL* tree\n\n    tree: NAME _NL [_INDENT tree+ _DEDENT]\n\n    %import common.CNAME -> NAME\n    %import common.WS_INLINE\n    %declare _INDENT _DEDENT\n    %ignore WS_INLINE\n\n    _NL: /(\\r?\\n[\\t ]*)+/\n\"\"\"\n\nclass TreeIndenter(Indenter):\n    NL_type = '_NL'\n    OPEN_PAREN_types = []\n    CLOSE_PAREN_types = []\n    INDENT_type = '_INDENT'\n    DEDENT_type = '_DEDENT'\n    tab_len = 8\n\nparser = Lark(tree_grammar, parser='lalr', postlex=TreeIndenter())\n\ntest_tree = \"\"\"\na\n    b\n    c\n        d\n        e\n    f\n        g\n\"\"\"\n\ndef test():\n    print(parser.parse(test_tree).pretty())\n\nif __name__ == '__main__':\n    test()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: indented_tree.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/7cc2abf4fecd3796ed4ad6d455bda349/indented_tree.py)\n\n[`Download Jupyter notebook: indented_tree.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/4b6a9b4fb62278f5d7a70e5b2900ff58/indented_tree.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/indented_tree.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Parsing Indentation — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html",
        "status_code": 200,
        "scrape_id": "c6d73059-807b-4f57-9553-ace8e26c888c",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.074Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/08132b45db8ea39c7a8efd8acc048de2/create_ast.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Creating an AST from the parse tree\\n\\n    This example demonstrates how to transform a parse-tree into an AST using `lark.ast_utils`.\\n\\n    create_transformer() collects every subclass of `Ast` subclass from the module,\\n    and creates a Lark transformer that builds the AST with no extra code.\\n\\n    This example only works with Python 3.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import sys\\nfrom typing import List\\nfrom dataclasses import dataclass\\n\\nfrom lark import Lark, ast_utils, Transformer, v_args\\nfrom lark.tree import Meta\\n\\nthis_module = sys.modules[__name__]\\n\\n\\n#\\n#   Define AST\\n#\\nclass _Ast(ast_utils.Ast):\\n    # This will be skipped by create_transformer(), because it starts with an underscore\\n    pass\\n\\nclass _Statement(_Ast):\\n    # This will be skipped by create_transformer(), because it starts with an underscore\\n    pass\\n\\n@dataclass\\nclass Value(_Ast, ast_utils.WithMeta):\\n    \\\"Uses WithMeta to include line-number metadata in the meta attribute\\\"\\n    meta: Meta\\n    value: object\\n\\n@dataclass\\nclass Name(_Ast):\\n    name: str\\n\\n@dataclass\\nclass CodeBlock(_Ast, ast_utils.AsList):\\n    # Corresponds to code_block in the grammar\\n    statements: List[_Statement]\\n\\n@dataclass\\nclass If(_Statement):\\n    cond: Value\\n    then: CodeBlock\\n\\n@dataclass\\nclass SetVar(_Statement):\\n    # Corresponds to set_var in the grammar\\n    name: str\\n    value: Value\\n\\n@dataclass\\nclass Print(_Statement):\\n    value: Value\\n\\n\\nclass ToAst(Transformer):\\n    # Define extra transformation functions, for rules that don't correspond to an AST class.\\n\\n    def STRING(self, s):\\n        # Remove quotation marks\\n        return s[1:-1]\\n\\n    def DEC_NUMBER(self, n):\\n        return int(n)\\n\\n    @v_args(inline=True)\\n    def start(self, x):\\n        return x\\n\\n#\\n#   Define Parser\\n#\\n\\nparser = Lark(\\\"\\\"\\\"\\n    start: code_block\\n\\n    code_block: statement+\\n\\n    ?statement: if | set_var | print\\n\\n    if: \\\"if\\\" value \\\"{\\\" code_block \\\"}\\\"\\n    set_var: NAME \\\"=\\\" value \\\";\\\"\\n    print: \\\"print\\\" value \\\";\\\"\\n\\n    value: name | STRING | DEC_NUMBER\\n    name: NAME\\n\\n    %import python (NAME, STRING, DEC_NUMBER)\\n    %import common.WS\\n    %ignore WS\\n    \\\"\\\"\\\",\\n    parser=\\\"lalr\\\",\\n)\\n\\ntransformer = ast_utils.create_transformer(this_module, ToAst())\\n\\ndef parse(text):\\n    tree = parser.parse(text)\\n    return transformer.transform(tree)\\n\\n#\\n#   Test\\n#\\n\\nif __name__ == '__main__':\\n    print(parse(\\\"\\\"\\\"\\n        a = 1;\\n        if a {\\n            print \\\"a is 1\\\";\\n            a = 2;\\n        }\\n    \\\"\\\"\\\"))\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/08132b45db8ea39c7a8efd8acc048de2/create_ast.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/08132b45db8ea39c7a8efd8acc048de2/create_ast.ipynb",
        "status_code": 200,
        "scrape_id": "f7072d0b-034b-40eb-8076-16d1073b46e7",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.088Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/features.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Features\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/features.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/philosophy.html \"Philosophy\") [Next](https://lark-parser.readthedocs.io/en/stable/parsers.html \"Parsers\")\n\n* * *\n\n# Features [](https://lark-parser.readthedocs.io/en/stable/features.html\\#features \"Permalink to this heading\")\n\n## Main Features [](https://lark-parser.readthedocs.io/en/stable/features.html\\#main-features \"Permalink to this heading\")\n\n- Earley parser, capable of parsing any context-free grammar\n\n  - Implements SPPF, for efficient parsing and storing of ambiguous grammars.\n- LALR(1) parser, limited in power of expression, but very efficient in space and performance (O(n)).\n\n  - Implements a parse-aware lexer that provides a better power of expression than traditional LALR implementations (such as ply).\n- EBNF-inspired grammar, with extra features (See: [Grammar Reference](https://lark-parser.readthedocs.io/en/stable/grammar.html))\n\n- Builds a parse-tree (AST) automagically based on the grammar\n\n- Stand-alone parser generator - create a small independent parser to embed in your project. ( [read more](https://lark-parser.readthedocs.io/en/stable/tools.html#stand-alone-parser))\n\n- Flexible error handling by using an interactive parser interface (LALR only)\n\n- Automatic line & column tracking (for both tokens and matched rules)\n\n- Automatic terminal collision resolution\n\n- Warns on regex collisions using the optional `interegular` library. ( [read more](https://lark-parser.readthedocs.io/en/stable/how_to_use.html#regex-collisions))\n\n- Grammar composition - Import terminals and rules from other grammars (see [example](https://github.com/lark-parser/lark/tree/master/examples/composition)).\n\n- Standard library of terminals (strings, numbers, names, etc.)\n\n- Unicode fully supported\n\n- Extensive test suite\n\n- Type annotations (MyPy support)\n\n- Pure-Python implementation\n\n\n[Read more about the parsers](https://lark-parser.readthedocs.io/en/stable/parsers.html)\n\n## Extra features [](https://lark-parser.readthedocs.io/en/stable/features.html\\#extra-features \"Permalink to this heading\")\n\n- Support for external regex module ( [see here](https://lark-parser.readthedocs.io/en/stable/classes.html#using-unicode-character-classes-with-regex))\n\n- Import grammars from Nearley.js ( [read more](https://lark-parser.readthedocs.io/en/stable/tools.html#importing-grammars-from-nearleyjs))\n\n- CYK parser\n\n- Visualize your parse trees as dot or png files ( [see\\_example](https://github.com/lark-parser/lark/blob/master/examples/fruitflies.py))\n\n- Automatic reconstruction of input from parse-tree (see [example](https://github.com/lark-parser/lark/blob/master/examples/advanced/reconstruct_json.py) and [another example](https://github.com/lark-parser/lark/blob/master/examples/advanced/reconstruct_python.py))\n\n- Use Lark grammars in [Julia](https://github.com/jamesrhester/Lerche.jl) and [Javascript](https://github.com/lark-parser/Lark.js).\n\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/features.html)**[stable](https://lark-parser.readthedocs.io/en/stable/features.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Features — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/features.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/features.html",
        "status_code": 200,
        "scrape_id": "fdfd8a0a-f953-49dc-b602-486f1337c158",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/tree_construction.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Tree Construction Reference\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/tree_construction.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/grammar.html \"Grammar Reference\") [Next](https://lark-parser.readthedocs.io/en/stable/classes.html \"API Reference\")\n\n* * *\n\n# Tree Construction Reference [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#tree-construction-reference \"Permalink to this heading\")\n\nLark builds a tree automatically based on the structure of the grammar, where each rule that is matched becomes a branch (node) in the tree, and its children are its matches, in the order of matching.\n\nFor example, the rule `node: child1 child2` will create a tree node with two children. If it is matched as part of another rule (i.e. if it isn’t the root), the new rule’s tree node will become its parent.\n\nUsing `item+` or `item*` will result in a list of items, equivalent to writing `item item item ..`.\n\nUsing `item?` will return the item if it matched, or nothing.\n\nIf `maybe_placeholders=True` (the default), then using `[item]` will return the item if it matched, or the value `None`, if it didn’t.\n\nIf `maybe_placeholders=False`, then `[]` behaves like `()?`.\n\n## Terminals [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#terminals \"Permalink to this heading\")\n\nTerminals are always values in the tree, never branches.\n\nLark filters out certain types of terminals by default, considering them punctuation:\n\n- Terminals that won’t appear in the tree are:\n\n  - Unnamed literals (like `\"keyword\"` or `\"+\"`)\n\n  - Terminals whose name starts with an underscore (like `_DIGIT`)\n- Terminals that _will_ appear in the tree are:\n\n  - Unnamed regular expressions (like `/[0-9]/`)\n\n  - Named terminals whose name starts with a letter (like `DIGIT`)\n\nNote: Terminals composed of literals and other terminals always include the entire match without filtering any part.\n\n**Example:**\n\n```\nstart:  PNAME pname\n\nPNAME:  \"(\" NAME \")\"\npname:  \"(\" NAME \")\"\n\nNAME:   /\\w+/\n%ignore /\\s+/\n\n```\n\nLark will parse “(Hello) (World)” as:\n\n```\nstart\n    (Hello)\n    pname World\n\n```\n\nRules prefixed with `!` will retain all their literals regardless.\n\n**Example:**\n\n```\n    expr: \"(\" expr \")\"\n        | NAME+\n\n    NAME: /\\w+/\n\n    %ignore \" \"\n\n```\n\nLark will parse “((hello world))” as:\n\n```\nexpr\n    expr\n        expr\n            \"hello\"\n            \"world\"\n\n```\n\nThe brackets do not appear in the tree by design. The words appear because they are matched by a named terminal.\n\n## Shaping the tree [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#shaping-the-tree \"Permalink to this heading\")\n\nUsers can alter the automatic construction of the tree using a collection of grammar features.\n\n### Inlining rules with `_` [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#inlining-rules-with \"Permalink to this heading\")\n\nRules whose name begins with an underscore will be inlined into their containing rule.\n\n**Example:**\n\n```\n    start: \"(\" _greet \")\"\n    _greet: /\\w+/ /\\w+/\n\n```\n\nLark will parse “(hello world)” as:\n\n```\nstart\n    \"hello\"\n    \"world\"\n\n```\n\n### Conditionally inlining rules with `?` [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#conditionally-inlining-rules-with \"Permalink to this heading\")\n\nRules that receive a question mark (?) at the beginning of their definition, will be inlined if they have a single child, after filtering.\n\n**Example:**\n\n```\n    start: greet greet\n    ?greet: \"(\" /\\w+/ \")\"\n          | /\\w+/ /\\w+/\n\n```\n\nLark will parse “hello world (planet)” as:\n\n```\nstart\n    greet\n        \"hello\"\n        \"world\"\n    \"planet\"\n\n```\n\n### Pinning rule terminals with `!` [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#pinning-rule-terminals-with \"Permalink to this heading\")\n\nRules that begin with an exclamation mark will keep all their terminals (they won’t get filtered).\n\n```\n    !expr: \"(\" expr \")\"\n         | NAME+\n    NAME: /\\w+/\n    %ignore \" \"\n\n```\n\nWill parse “((hello world))” as:\n\n```\nexpr\n  (\n  expr\n    (\n    expr\n      hello\n      world\n    )\n  )\n\n```\n\nUsing the `!` prefix is usually a “code smell”, and may point to a flaw in your grammar design.\n\n### Aliasing rules [](https://lark-parser.readthedocs.io/en/stable/tree_construction.html\\#aliasing-rules \"Permalink to this heading\")\n\nAliases - options in a rule can receive an alias. It will be then used as the branch name for the option, instead of the rule name.\n\n**Example:**\n\n```\n    start: greet greet\n    greet: \"hello\"\n         | \"world\" -> planet\n\n```\n\nLark will parse “hello world” as:\n\n```\nstart\n    greet\n    planet\n\n```\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/tree_construction.html)**[stable](https://lark-parser.readthedocs.io/en/stable/tree_construction.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Tree Construction Reference — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/tree_construction.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/tree_construction.html",
        "status_code": 200,
        "scrape_id": "fa016d5e-7355-45c9-8e8a-8a36e61c22ab",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Example-Driven Error Reporting\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/error_reporting_lalr.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html \"Example-Driven Error Reporting\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html \"Reconstruct Python\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html#sphx-glr-download-examples-advanced-error-reporting-lalr-py)\nto download the full example code\n\n# Example-Driven Error Reporting [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html\\#example-driven-error-reporting \"Permalink to this heading\")\n\nA demonstration of example-driven error reporting with the LALR parser\n(See also: error\\_reporting\\_earley.py)\n\n```\nfrom lark import Lark, UnexpectedInput\n\nfrom _json_parser import json_grammar   # Using the grammar from the json_parser example\n\njson_parser = Lark(json_grammar, parser='lalr')\n\nclass JsonSyntaxError(SyntaxError):\n    def __str__(self):\n        context, line, column = self.args\n        return '%s at line %s, column %s.\\n\\n%s' % (self.label, line, column, context)\n\nclass JsonMissingValue(JsonSyntaxError):\n    label = 'Missing Value'\n\nclass JsonMissingOpening(JsonSyntaxError):\n    label = 'Missing Opening'\n\nclass JsonMissingClosing(JsonSyntaxError):\n    label = 'Missing Closing'\n\nclass JsonMissingComma(JsonSyntaxError):\n    label = 'Missing Comma'\n\nclass JsonTrailingComma(JsonSyntaxError):\n    label = 'Trailing Comma'\n\ndef parse(json_text):\n    try:\n        j = json_parser.parse(json_text)\n    except UnexpectedInput as u:\n        exc_class = u.match_examples(json_parser.parse, {\n            JsonMissingOpening: ['{\"foo\": ]}',\n                                 '{\"foor\": }}',\n                                 '{\"foo\": }'],\n            JsonMissingClosing: ['{\"foo\": [}',\\\n                                 '{',\\\n                                 '{\"a\": 1',\\\n                                 '[1'],\\\n            JsonMissingComma: ['[1 2]',\\\n                               '[false 1]',\\\n                               '[\"b\" 1]',\\\n                               '{\"a\":true 1:4}',\\\n                               '{\"a\":1 1:4}',\\\n                               '{\"a\":\"b\" 1:4}'],\\\n            JsonTrailingComma: ['[,]',\\\n                                '[1,]',\\\n                                '[1,2,]',\\\n                                '{\"foo\":1,}',\\\n                                '{\"foo\":false,\"bar\":true,}']\\\n        }, use_accepts=True)\\\n        if not exc_class:\\\n            raise\\\n        raise exc_class(u.get_context(json_text), u.line, u.column)\\\n\\\ndef test():\\\n    try:\\\n        parse('{\"example1\": \"value\"')\\\n    except JsonMissingClosing as e:\\\n        print(e)\\\n\\\n    try:\\\n        parse('{\"example2\": ] ')\\\n    except JsonMissingOpening as e:\\\n        print(e)\\\n\\\nif __name__ == '__main__':\\\n    test()\\\n\\\n```\\\n\\\n**Total running time of the script:** (0 minutes 0.000 seconds)\\\n\\\n[`Download Python source code: error_reporting_lalr.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/2cc75b757e7515472722c8c02d4fe4e4/error_reporting_lalr.py)\\\n\\\n[`Download Jupyter notebook: error_reporting_lalr.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/7279f5d640bfe9814468a2adf38516d5/error_reporting_lalr.ipynb)\\\n\\\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\\\n\\\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/error_reporting_lalr.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\\\n\\\n* * *\\\n\\\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\\\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Example-Driven Error Reporting — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html",
        "status_code": 200,
        "scrape_id": "0aec9db1-f903-43a1-b211-2e1abe3e73ca",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/d3b43c711b7f9a6aeee99f79cf861539/templates.py",
      "markdown": "```\n\"\"\"\nTemplates\n=========\n\nThis example shows how to use Lark's templates to achieve cleaner grammars\n\n\"\"\"\nfrom lark import Lark\n\ngrammar = r\"\"\"\nstart: list | dict\n\nlist: \"[\" _seperated{atom, \",\"} \"]\"\ndict: \"{\" _seperated{key_value, \",\"} \"}\"\nkey_value: atom \":\" atom\n\n_seperated{x, sep}: x (sep x)*  // Define a sequence of 'x sep x sep x ...'\n\natom: NUMBER | ESCAPED_STRING\n\n%import common (NUMBER, ESCAPED_STRING, WS)\n%ignore WS\n\"\"\"\n\nparser = Lark(grammar)\n\nprint(parser.parse('[1, \"a\", 2]'))\nprint(parser.parse('{\"a\": 2, \"b\": 6}'))\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/d3b43c711b7f9a6aeee99f79cf861539/templates.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/d3b43c711b7f9a6aeee99f79cf861539/templates.py",
        "status_code": 200,
        "scrape_id": "fa9ac2fb-07b5-43bb-8789-245c2c41ec6a",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/bdb62f1189ee436f5378982a91ecc1cf/error_reporting_earley.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Example-Driven Error Reporting\\n\\nA demonstration of example-driven error reporting with the Earley parser\\n(See also: error_reporting_lalr.py)\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark, UnexpectedInput\\n\\nfrom _json_parser import json_grammar   # Using the grammar from the json_parser example\\n\\njson_parser = Lark(json_grammar)\\n\\nclass JsonSyntaxError(SyntaxError):\\n    def __str__(self):\\n        context, line, column = self.args\\n        return '%s at line %s, column %s.\\\\n\\\\n%s' % (self.label, line, column, context)\\n\\nclass JsonMissingValue(JsonSyntaxError):\\n    label = 'Missing Value'\\n\\nclass JsonMissingOpening(JsonSyntaxError):\\n    label = 'Missing Opening'\\n\\nclass JsonMissingClosing(JsonSyntaxError):\\n    label = 'Missing Closing'\\n\\nclass JsonMissingComma(JsonSyntaxError):\\n    label = 'Missing Comma'\\n\\nclass JsonTrailingComma(JsonSyntaxError):\\n    label = 'Trailing Comma'\\n\\n\\ndef parse(json_text):\\n    try:\\n        j = json_parser.parse(json_text)\\n    except UnexpectedInput as u:\\n        exc_class = u.match_examples(json_parser.parse, {\\n            JsonMissingOpening: ['{\\\"foo\\\": ]}',\\n                                 '{\\\"foor\\\": }}',\\n                                 '{\\\"foo\\\": }'],\\n            JsonMissingClosing: ['{\\\"foo\\\": [}',\\n                                 '{',\\n                                 '{\\\"a\\\": 1',\\n                                 '[1'],\\n            JsonMissingComma: ['[1 2]',\\n                               '[false 1]',\\n                               '[\\\"b\\\" 1]',\\n                               '{\\\"a\\\":true 1:4}',\\n                               '{\\\"a\\\":1 1:4}',\\n                               '{\\\"a\\\":\\\"b\\\" 1:4}'],\\n            JsonTrailingComma: ['[,]',\\n                                '[1,]',\\n                                '[1,2,]',\\n                                '{\\\"foo\\\":1,}',\\n                                '{\\\"foo\\\":false,\\\"bar\\\":true,}']\\n        }, use_accepts=True)\\n        if not exc_class:\\n            raise\\n        raise exc_class(u.get_context(json_text), u.line, u.column)\\n\\n\\ndef test():\\n    try:\\n        parse('{\\\"example1\\\": \\\"value\\\"')\\n    except JsonMissingClosing as e:\\n        print(e)\\n\\n    try:\\n        parse('{\\\"example2\\\": ] ')\\n    except JsonMissingOpening as e:\\n        print(e)\\n\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/bdb62f1189ee436f5378982a91ecc1cf/error_reporting_earley.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/bdb62f1189ee436f5378982a91ecc1cf/error_reporting_earley.ipynb",
        "status_code": 200,
        "scrape_id": "3cbda0e7-dbd3-4fc7-a772-05489426f23c",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Handling Ambiguity\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/fruitflies.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html \"Lark Grammar\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/calc.html \"Basic calculator\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html#sphx-glr-download-examples-fruitflies-py)\nto download the full example code\n\n# Handling Ambiguity [](https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html\\#handling-ambiguity \"Permalink to this heading\")\n\nA demonstration of ambiguity\n\nThis example shows how to use get explicit ambiguity from Lark’s Earley parser.\n\n```\nimport sys\nfrom lark import Lark, tree\n\ngrammar = \"\"\"\n    sentence: noun verb noun        -> simple\n            | noun verb \"like\" noun -> comparative\n\n    noun: adj? NOUN\n    verb: VERB\n    adj: ADJ\n\n    NOUN: \"flies\" | \"bananas\" | \"fruit\"\n    VERB: \"like\" | \"flies\"\n    ADJ: \"fruit\"\n\n    %import common.WS\n    %ignore WS\n\"\"\"\n\nparser = Lark(grammar, start='sentence', ambiguity='explicit')\n\nsentence = 'fruit flies like bananas'\n\ndef make_png(filename):\n    tree.pydot__tree_to_png( parser.parse(sentence), filename)\n\ndef make_dot(filename):\n    tree.pydot__tree_to_dot( parser.parse(sentence), filename)\n\nif __name__ == '__main__':\n    print(parser.parse(sentence).pretty())\n    # make_png(sys.argv[1])\n    # make_dot(sys.argv[1])\n\n# Output:\n#\n# _ambig\n#   comparative\n#     noun  fruit\n#     verb  flies\n#     noun  bananas\n#   simple\n#     noun\n#       fruit\n#       flies\n#     verb  like\n#     noun  bananas\n#\n# (or view a nicer version at \"./fruitflies.png\")\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: fruitflies.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/b0239cee17ba033b2ccfffe66491b86e/fruitflies.py)\n\n[`Download Jupyter notebook: fruitflies.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/9ebc86868010e2fc400ecf1ef8a5aa4a/fruitflies.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/fruitflies.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Handling Ambiguity — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html",
        "status_code": 200,
        "scrape_id": "6bae78b4-247e-4f0a-80f6-b782e5adfc21",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.157Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/f034a71a096a9049dcf409ec85c36943/conf_earley.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Earley\\u2019s dynamic lexer\\n\\nDemonstrates the power of Earley\\u2019s dynamic lexer on a toy configuration language\\n\\nUsing a lexer for configuration files is tricky, because values don't\\nhave to be surrounded by delimiters. Using a basic lexer for this just won't work.\\n\\nIn this example we use a dynamic lexer and let the Earley parser resolve the ambiguity.\\n\\nAnother approach is to use the contextual lexer with LALR. It is less powerful than Earley,\\nbut it can handle some ambiguity when lexing and it's much faster.\\nSee examples/conf_lalr.py for an example of that approach.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\n\\nparser = Lark(r\\\"\\\"\\\"\\n        start: _NL? section+\\n        section: \\\"[\\\" NAME \\\"]\\\" _NL item+\\n        item: NAME \\\"=\\\" VALUE? _NL\\n\\n        NAME: /\\\\w/+\\n        VALUE: /./+\\n\\n        %import common.NEWLINE -> _NL\\n        %import common.WS_INLINE\\n        %ignore WS_INLINE\\n    \\\"\\\"\\\", parser=\\\"earley\\\")\\n\\ndef test():\\n    sample_conf = \\\"\\\"\\\"\\n[bla]\\n\\na=Hello\\nthis=\\\"that\\\",4\\nempty=\\n\\\"\\\"\\\"\\n\\n    r = parser.parse(sample_conf)\\n    print (r.pretty())\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/f034a71a096a9049dcf409ec85c36943/conf_earley.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/f034a71a096a9049dcf409ec85c36943/conf_earley.ipynb",
        "status_code": 200,
        "scrape_id": "45ad12ee-19d5-4cbc-afbf-1dc00192b8ce",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/179842700c93c6cca88ed33e1b99eb9c/json_parser.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Simple JSON Parser\\n\\nThe code is short and clear, and outperforms every other parser (that's written in Python).\\nFor an explanation, check out the JSON parser tutorial at /docs/json_tutorial.md\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import sys\\n\\nfrom lark import Lark, Transformer, v_args\\n\\njson_grammar = r\\\"\\\"\\\"\\n    ?start: value\\n\\n    ?value: object\\n          | array\\n          | string\\n          | SIGNED_NUMBER      -> number\\n          | \\\"true\\\"             -> true\\n          | \\\"false\\\"            -> false\\n          | \\\"null\\\"             -> null\\n\\n    array  : \\\"[\\\" [value (\\\",\\\" value)*] \\\"]\\\"\\n    object : \\\"{\\\" [pair (\\\",\\\" pair)*] \\\"}\\\"\\n    pair   : string \\\":\\\" value\\n\\n    string : ESCAPED_STRING\\n\\n    %import common.ESCAPED_STRING\\n    %import common.SIGNED_NUMBER\\n    %import common.WS\\n\\n    %ignore WS\\n\\\"\\\"\\\"\\n\\n\\nclass TreeToJson(Transformer):\\n    @v_args(inline=True)\\n    def string(self, s):\\n        return s[1:-1].replace('\\\\\\\\\\\"', '\\\"')\\n\\n    array = list\\n    pair = tuple\\n    object = dict\\n    number = v_args(inline=True)(float)\\n\\n    null = lambda self, _: None\\n    true = lambda self, _: True\\n    false = lambda self, _: False\\n\\n\\n### Create the JSON parser with Lark, using the Earley algorithm\\n# json_parser = Lark(json_grammar, parser='earley', lexer='basic')\\n# def parse(x):\\n#     return TreeToJson().transform(json_parser.parse(x))\\n\\n### Create the JSON parser with Lark, using the LALR algorithm\\njson_parser = Lark(json_grammar, parser='lalr',\\n                   # Using the basic lexer isn't required, and isn't usually recommended.\\n                   # But, it's good enough for JSON, and it's slightly faster.\\n                   lexer='basic',\\n                   # Disabling propagate_positions and placeholders slightly improves speed\\n                   propagate_positions=False,\\n                   maybe_placeholders=False,\\n                   # Using an internal transformer is faster and more memory efficient\\n                   transformer=TreeToJson())\\nparse = json_parser.parse\\n\\n\\ndef test():\\n    test_json = '''\\n        {\\n            \\\"empty_object\\\" : {},\\n            \\\"empty_array\\\"  : [],\\n            \\\"booleans\\\"     : { \\\"YES\\\" : true, \\\"NO\\\" : false },\\n            \\\"numbers\\\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\\n            \\\"strings\\\"      : [ \\\"This\\\", [ \\\"And\\\" , \\\"That\\\", \\\"And a \\\\\\\\\\\"b\\\" ] ],\\n            \\\"nothing\\\"      : null\\n        }\\n    '''\\n\\n    j = parse(test_json)\\n    print(j)\\n    import json\\n    assert j == json.loads(test_json)\\n\\n\\nif __name__ == '__main__':\\n    # test()\\n    with open(sys.argv[1]) as f:\\n        print(parse(f.read()))\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/179842700c93c6cca88ed33e1b99eb9c/json_parser.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/179842700c93c6cca88ed33e1b99eb9c/json_parser.ipynb",
        "status_code": 200,
        "scrape_id": "c6dba8fe-6061-4eb9-a16e-1c0b7df741f3",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.738Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Grammar-complete Python Parser\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/python_parser.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html \"Python 3 to Python 2 converter (tree templates)\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html \"Creating an AST from the parse tree\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html#sphx-glr-download-examples-advanced-python-parser-py)\nto download the full example code\n\n# Grammar-complete Python Parser [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html\\#grammar-complete-python-parser \"Permalink to this heading\")\n\nA fully-working Python 2 & 3 parser (but not production ready yet!)\n\nThis example demonstrates usage of the included Python grammars\n\n```\nimport sys\nimport os, os.path\nfrom io import open\nimport glob, time\n\nfrom lark import Lark\nfrom lark.indenter import PythonIndenter\n\nkwargs = dict(postlex=PythonIndenter(), start='file_input')\n\n# Official Python grammar by Lark\npython_parser3 = Lark.open_from_package('lark', 'python.lark', ['grammars'], parser='lalr', **kwargs)\n\n# Local Python2 grammar\npython_parser2 = Lark.open('python2.lark', rel_to=__file__, parser='lalr', **kwargs)\npython_parser2_earley = Lark.open('python2.lark', rel_to=__file__, parser='earley', lexer='basic', **kwargs)\n\ntry:\n    xrange\nexcept NameError:\n    chosen_parser = python_parser3\nelse:\n    chosen_parser = python_parser2\n\ndef _read(fn, *args):\n    kwargs = {'encoding': 'iso-8859-1'}\n    with open(fn, *args, **kwargs) as f:\n        return f.read()\n\ndef _get_lib_path():\n    if os.name == 'nt':\n        if 'PyPy' in sys.version:\n            return os.path.join(sys.base_prefix, 'lib-python', sys.winver)\n        else:\n            return os.path.join(sys.base_prefix, 'Lib')\n    else:\n        return [x for x in sys.path if x.endswith('%s.%s' % sys.version_info[:2])][0]\n\ndef test_python_lib():\n    path = _get_lib_path()\n\n    start = time.time()\n    files = glob.glob(path+'/*.py')\n    total_kb = 0\n    for f in files:\n        r = _read(os.path.join(path, f))\n        kb = len(r) / 1024\n        print( '%s -\\t%.1f kb' % (f, kb))\n        chosen_parser.parse(r + '\\n')\n        total_kb += kb\n\n    end = time.time()\n    print( \"test_python_lib (%d files, %.1f kb), time: %.2f secs\"%(len(files), total_kb, end-start) )\n\ndef test_earley_equals_lalr():\n    path = _get_lib_path()\n\n    files = glob.glob(path+'/*.py')\n    for f in files:\n        print( f )\n        tree1 = python_parser2.parse(_read(os.path.join(path, f)) + '\\n')\n        tree2 = python_parser2_earley.parse(_read(os.path.join(path, f)) + '\\n')\n        assert tree1 == tree2\n\nif __name__ == '__main__':\n    test_python_lib()\n    # test_earley_equals_lalr()\n    # python_parser3.parse(_read(sys.argv[1]) + '\\n')\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: python_parser.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/3933bf173c425fd28a9c4d7c72b8eca1/python_parser.py)\n\n[`Download Jupyter notebook: python_parser.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/60290154124d6b16926446036bb711d6/python_parser.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/python_parser.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Grammar-complete Python Parser — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html",
        "status_code": 200,
        "scrape_id": "25ba3179-6bfe-4a8f-9efe-95f4b2d04cc3",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9d7d9d95319f4514ab7247f8eb86ddf0/tree_forest_transformer.py",
      "markdown": "```\n\"\"\"\nTransform a Forest\n==================\n\nThis example demonstrates how to subclass ``TreeForestTransformer`` to\ndirectly transform a SPPF.\n\"\"\"\n\nfrom lark import Lark\nfrom lark.parsers.earley_forest import TreeForestTransformer, handles_ambiguity, Discard\n\nclass CustomTransformer(TreeForestTransformer):\n\n    @handles_ambiguity\n    def sentence(self, trees):\n        return next(tree for tree in trees if tree.data == 'simple')\n\n    def simple(self, children):\n        children.append('.')\n        return self.tree_class('simple', children)\n\n    def adj(self, children):\n        return Discard\n\n    def __default_token__(self, token):\n        return token.capitalize()\n\ngrammar = \"\"\"\n    sentence: noun verb noun        -> simple\n            | noun verb \"like\" noun -> comparative\n\n    noun: adj? NOUN\n    verb: VERB\n    adj: ADJ\n\n    NOUN: \"flies\" | \"bananas\" | \"fruit\"\n    VERB: \"like\" | \"flies\"\n    ADJ: \"fruit\"\n\n    %import common.WS\n    %ignore WS\n\"\"\"\n\nparser = Lark(grammar, start='sentence', ambiguity='forest')\nsentence = 'fruit flies like bananas'\nforest = parser.parse(sentence)\n\ntree = CustomTransformer(resolve_ambiguity=False).transform(forest)\nprint(tree.pretty())\n\n# Output:\n#\n# simple\n#   noun  Flies\n#   verb  Like\n#   noun  Bananas\n#   .\n#\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9d7d9d95319f4514ab7247f8eb86ddf0/tree_forest_transformer.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9d7d9d95319f4514ab7247f8eb86ddf0/tree_forest_transformer.py",
        "status_code": 200,
        "scrape_id": "215f5dc4-8909-4f7c-8a9a-6d5f569d7ca3",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.694Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/98afe2f1c3b9485fcb8bdeebbbf0234f/main.py",
      "markdown": "```\n\"\"\"\nGrammar Composition\n===================\n\nThis example shows how to do grammar composition in Lark, by creating a new\nfile format that allows both CSV and JSON to co-exist.\n\n1) We define ``storage.lark``, which imports both ``csv.lark`` and ``json.lark``,\n  and allows them to be used one after the other.\n\n  In the generated tree, each imported rule/terminal is automatically prefixed (with ``json__`` or ``csv__),\n  which creates an implicit namespace and allows them to coexist without collisions.\n\n2) We merge their respective transformers (unaware of each other) into a new base transformer.\n   The resulting transformer can evaluate both JSON and CSV in the parse tree.\n\n  The methods of each transformer are renamed into their appropriate namespace, using the given prefix.\n  This approach allows full re-use: the transformers don't need to care if their grammar is used directly,\n  or being imported, or who is doing the importing.\n\n\"\"\"\nfrom pathlib import Path\nfrom lark import Lark\nfrom json import dumps\nfrom lark.visitors import Transformer, merge_transformers\n\nfrom eval_csv import CsvTreeToPandasDict\nfrom eval_json import JsonTreeToJson\n\n__dir__ = Path(__file__).parent\n\nclass Storage(Transformer):\n    def start(self, children):\n        return children\n\nstorage_transformer = merge_transformers(Storage(), csv=CsvTreeToPandasDict(), json=JsonTreeToJson())\n\nparser = Lark.open(\"storage.lark\", rel_to=__file__)\n\ndef main():\n    json_tree = parser.parse(dumps({\"test\": \"a\", \"dict\": { \"list\": [1, 1.2] }}))\n    res = storage_transformer.transform(json_tree)\n    print(\"Just JSON: \", res)\n\n    csv_json_tree = parser.parse(open(__dir__ / 'combined_csv_and_json.txt').read())\n    res = storage_transformer.transform(csv_json_tree)\n    print(\"JSON + CSV: \", dumps(res, indent=2))\n\nif __name__ == \"__main__\":\n    main()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/98afe2f1c3b9485fcb8bdeebbbf0234f/main.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/98afe2f1c3b9485fcb8bdeebbbf0234f/main.py",
        "status_code": 200,
        "scrape_id": "a174ea1d-26eb-4c65-afab-dcc7f4139f0d",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Using lexer dynamic\\_complete\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/dynamic_complete.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html \"Reconstruct Python\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html \"Syntax Highlighting\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html#sphx-glr-download-examples-advanced-dynamic-complete-py)\nto download the full example code\n\n# Using lexer dynamic\\_complete [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html\\#using-lexer-dynamic-complete \"Permalink to this heading\")\n\nDemonstrates how to use `lexer='dynamic_complete'` and `ambiguity='explicit'`\n\nSometimes you have data that is highly ambiguous or ‘broken’ in some sense.\nWhen using `parser='earley'` and `lexer='dynamic_complete'`, Lark will be able\nparse just about anything as long as there is a valid way to generate it from\nthe Grammar, including looking ‘into’ the Regexes.\n\nThis examples shows how to parse a json input where the quotes have been\nreplaced by underscores: `{_foo_:{}, _bar_: [], _baz_: __}`\nNotice that underscores might still appear inside strings, so a potentially\nvalid reading of the above is:\n`{\"foo_:{}, _bar\": [], \"baz\": \"\"}`\n\n```\nfrom pprint import pprint\n\nfrom lark import Lark, Tree, Transformer, v_args\nfrom lark.visitors import Transformer_InPlace\n\nGRAMMAR = r\"\"\"\n%import common.SIGNED_NUMBER\n%import common.WS_INLINE\n%import common.NEWLINE\n%ignore WS_INLINE\n\n?start: value\n\n?value: object\n      | array\n      | string\n      | SIGNED_NUMBER      -> number\n      | \"true\"             -> true\n      | \"false\"            -> false\n      | \"null\"             -> null\n\narray  : \"[\" (value (\",\" value)*)? \"]\"\nobject : \"{\" (pair (\",\" pair)*)? \"}\"\npair   : string \":\" value\n\nstring: STRING\nSTRING : ESCAPED_STRING\n\nESCAPED_STRING: QUOTE_CHAR _STRING_ESC_INNER QUOTE_CHAR\nQUOTE_CHAR: \"_\"\n\n_STRING_INNER: /.*/\n_STRING_ESC_INNER: _STRING_INNER /(?<!\\\\)(\\\\\\\\)*?/\n\n\"\"\"\n\ndef score(tree: Tree):\n    \"\"\"\n    Scores an option by how many children (and grand-children, and\n    grand-grand-children, ...) it has.\n    This means that the option with fewer large terminals gets selected\n\n    Between\n        object\n          pair\n            string  _foo_\n            object\n          pair\n            string  _bar_: [], _baz_\n            string  __\n\n    and\n\n        object\n          pair\n            string  _foo_\n            object\n          pair\n            string  _bar_\n            array\n          pair\n            string  _baz_\n            string  __\n\n    this will give the second a higher score. (9 vs 13)\n    \"\"\"\n    return sum(len(t.children) for t in tree.iter_subtrees())\n\nclass RemoveAmbiguities(Transformer_InPlace):\n    \"\"\"\n    Selects an option to resolve an ambiguity using the score function above.\n    Scores each option and selects the one with the higher score, e.g. the one\n    with more nodes.\n\n    If there is a performance problem with the Tree having to many _ambig and\n    being slow and to large, this can instead be written as a ForestVisitor.\n    Look at the 'Custom SPPF Prioritizer' example.\n    \"\"\"\n    def _ambig(self, options):\n        return max(options, key=score)\n\nclass TreeToJson(Transformer):\n    \"\"\"\n    This is the same Transformer as the json_parser example.\n    \"\"\"\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\nparser = Lark(GRAMMAR, parser='earley', ambiguity=\"explicit\", lexer='dynamic_complete')\n\nEXAMPLES = [\\\n    r'{_array_:[1,2,3]}',\\\n\\\n    r'{_abc_: _array must be of the following format [_1_, _2_, _3_]_}',\\\n\\\n    r'{_foo_:{}, _bar_: [], _baz_: __}',\\\n\\\n    r'{_error_:_invalid_client_, _error_description_:_AADSTS7000215: Invalid '\\\n    r'client secret is provided.\\r\\nTrace ID: '\\\n    r'a0a0aaaa-a0a0-0a00-000a-00a00aaa0a00\\r\\nCorrelation ID: '\\\n    r'aa0aaa00-0aaa-0000-00a0-00000aaaa0aa\\r\\nTimestamp: 1997-10-10 00:00:00Z_, '\\\n    r'_error_codes_:[7000215], _timestamp_:_1997-10-10 00:00:00Z_, '\\\n    r'_trace_id_:_a0a0aaaa-a0a0-0a00-000a-00a00aaa0a00_, '\\\n    r'_correlation_id_:_aa0aaa00-0aaa-0000-00a0-00000aaaa0aa_, '\\\n    r'_error_uri_:_https://example.com_}',\\\n\\\n]\nfor example in EXAMPLES:\n    tree = parser.parse(example)\n    tree = RemoveAmbiguities().transform(tree)\n    result = TreeToJson().transform(tree)\n    pprint(result)\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: dynamic_complete.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/22081051f999d4e0753796b91b344ee3/dynamic_complete.py)\n\n[`Download Jupyter notebook: dynamic_complete.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/fc674523e7ef0712dfc331b1ddd10972/dynamic_complete.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/dynamic_complete.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Using lexer dynamic_complete — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html",
        "status_code": 200,
        "scrape_id": "d3af88bb-e147-42ab-9ab2-13627a4ad110",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Creating an AST from the parse tree\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/create_ast.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html \"Grammar-complete Python Parser\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html \"Example-Driven Error Reporting\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html#sphx-glr-download-examples-advanced-create-ast-py)\nto download the full example code\n\n# Creating an AST from the parse tree [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html\\#creating-an-ast-from-the-parse-tree \"Permalink to this heading\")\n\n> This example demonstrates how to transform a parse-tree into an AST using lark.ast\\_utils.\n>\n> create\\_transformer() collects every subclass of Ast subclass from the module,\n> and creates a Lark transformer that builds the AST with no extra code.\n>\n> This example only works with Python 3.\n\n```\nimport sys\nfrom typing import List\nfrom dataclasses import dataclass\n\nfrom lark import Lark, ast_utils, Transformer, v_args\nfrom lark.tree import Meta\n\nthis_module = sys.modules[__name__]\n\n#\n#   Define AST\n#\nclass _Ast(ast_utils.Ast):\n    # This will be skipped by create_transformer(), because it starts with an underscore\n    pass\n\nclass _Statement(_Ast):\n    # This will be skipped by create_transformer(), because it starts with an underscore\n    pass\n\n@dataclass\nclass Value(_Ast, ast_utils.WithMeta):\n    \"Uses WithMeta to include line-number metadata in the meta attribute\"\n    meta: Meta\n    value: object\n\n@dataclass\nclass Name(_Ast):\n    name: str\n\n@dataclass\nclass CodeBlock(_Ast, ast_utils.AsList):\n    # Corresponds to code_block in the grammar\n    statements: List[_Statement]\n\n@dataclass\nclass If(_Statement):\n    cond: Value\n    then: CodeBlock\n\n@dataclass\nclass SetVar(_Statement):\n    # Corresponds to set_var in the grammar\n    name: str\n    value: Value\n\n@dataclass\nclass Print(_Statement):\n    value: Value\n\nclass ToAst(Transformer):\n    # Define extra transformation functions, for rules that don't correspond to an AST class.\n\n    def STRING(self, s):\n        # Remove quotation marks\n        return s[1:-1]\n\n    def DEC_NUMBER(self, n):\n        return int(n)\n\n    @v_args(inline=True)\n    def start(self, x):\n        return x\n\n#\n#   Define Parser\n#\n\nparser = Lark(\"\"\"\n    start: code_block\n\n    code_block: statement+\n\n    ?statement: if | set_var | print\n\n    if: \"if\" value \"{\" code_block \"}\"\n    set_var: NAME \"=\" value \";\"\n    print: \"print\" value \";\"\n\n    value: name | STRING | DEC_NUMBER\n    name: NAME\n\n    %import python (NAME, STRING, DEC_NUMBER)\n    %import common.WS\n    %ignore WS\n    \"\"\",\n    parser=\"lalr\",\n)\n\ntransformer = ast_utils.create_transformer(this_module, ToAst())\n\ndef parse(text):\n    tree = parser.parse(text)\n    return transformer.transform(tree)\n\n#\n#   Test\n#\n\nif __name__ == '__main__':\n    print(parse(\"\"\"\n        a = 1;\n        if a {\n            print \"a is 1\";\n            a = 2;\n        }\n    \"\"\"))\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: create_ast.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/bfeb22cff3ae6c24841aad8c5a95d047/create_ast.py)\n\n[`Download Jupyter notebook: create_ast.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/08132b45db8ea39c7a8efd8acc048de2/create_ast.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/create_ast.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Creating an AST from the parse tree — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html",
        "status_code": 200,
        "scrape_id": "d73b3f76-1a52-4836-a1d1-eb41bbb831cf",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/347194332333371dddab71778db00fd5/py3to2.py",
      "markdown": "```\n\"\"\"\nPython 3 to Python 2 converter (tree templates)\n===============================================\n\nThis example demonstrates how to translate between two trees using tree templates.\nIt parses Python 3, translates it to a Python 2 AST, and then outputs the result as Python 2 code.\n\nUses reconstruct_python.py for generating the final Python 2 code.\n\"\"\"\n\nfrom lark import Lark\nfrom lark.tree_templates import TemplateConf, TemplateTranslator\n\nfrom lark.indenter import PythonIndenter\nfrom reconstruct_python import PythonReconstructor\n\n#\n# 1. Define a Python parser that also accepts template vars in the code (in the form of $var)\n#\nTEMPLATED_PYTHON = r\"\"\"\n%import python (single_input, file_input, eval_input, atom, var, stmt, expr, testlist_star_expr, _NEWLINE, _INDENT, _DEDENT, COMMENT, NAME)\n\n%extend atom: TEMPLATE_NAME -> var\n\nTEMPLATE_NAME: \"$\" NAME\n\n?template_start: (stmt | testlist_star_expr _NEWLINE)\n\n%ignore /[\\t \\f]+/          // WS\n%ignore /\\\\[\\t \\f]*\\r?\\n/   // LINE_CONT\n%ignore COMMENT\n\"\"\"\n\nparser = Lark(TEMPLATED_PYTHON, parser='lalr', start=['single_input', 'file_input', 'eval_input', 'template_start'], postlex=PythonIndenter(), maybe_placeholders=False)\n\ndef parse_template(s):\n    return parser.parse(s + '\\n', start='template_start')\n\ndef parse_code(s):\n    return parser.parse(s + '\\n', start='file_input')\n\n#\n# 2. Define translations using templates (each template code is parsed to a template tree)\n#\n\npytemplate = TemplateConf(parse=parse_template)\n\ntranslations_3to2 = {\n    'yield from $a':\n\t    'for _tmp in $a: yield _tmp',\n\n    'raise $e from $x':\n    \t'raise $e',\n\n    '$a / $b':\n\t    'float($a) / $b',\n}\ntranslations_3to2 = {pytemplate(k): pytemplate(v) for k, v in translations_3to2.items()}\n\n#\n# 3. Translate and reconstruct Python 3 code into valid Python 2 code\n#\n\npython_reconstruct = PythonReconstructor(parser)\n\ndef translate_py3to2(code):\n\ttree = parse_code(code)\n\ttree = TemplateTranslator(translations_3to2).translate(tree)\n\treturn python_reconstruct.reconstruct(tree)\n\n#\n# Test Code\n#\n\n_TEST_CODE = '''\nif a / 2 > 1:\n    yield from [1,2,3]\nelse:\n    raise ValueError(a) from e\n\n'''\n\ndef test():\n\tprint(_TEST_CODE)\n\tprint('   ----->    ')\n\tprint(translate_py3to2(_TEST_CODE))\n\nif __name__ == '__main__':\n\ttest()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/347194332333371dddab71778db00fd5/py3to2.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/347194332333371dddab71778db00fd5/py3to2.py",
        "status_code": 200,
        "scrape_id": "4d874224-efc8-4a6d-8181-c7d96959db5e",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/bfeb22cff3ae6c24841aad8c5a95d047/create_ast.py",
      "markdown": "```\n\"\"\"\nCreating an AST from the parse tree\n===================================\n\n    This example demonstrates how to transform a parse-tree into an AST using `lark.ast_utils`.\n\n    create_transformer() collects every subclass of `Ast` subclass from the module,\n    and creates a Lark transformer that builds the AST with no extra code.\n\n    This example only works with Python 3.\n\"\"\"\n\nimport sys\nfrom typing import List\nfrom dataclasses import dataclass\n\nfrom lark import Lark, ast_utils, Transformer, v_args\nfrom lark.tree import Meta\n\nthis_module = sys.modules[__name__]\n\n#\n#   Define AST\n#\nclass _Ast(ast_utils.Ast):\n    # This will be skipped by create_transformer(), because it starts with an underscore\n    pass\n\nclass _Statement(_Ast):\n    # This will be skipped by create_transformer(), because it starts with an underscore\n    pass\n\n@dataclass\nclass Value(_Ast, ast_utils.WithMeta):\n    \"Uses WithMeta to include line-number metadata in the meta attribute\"\n    meta: Meta\n    value: object\n\n@dataclass\nclass Name(_Ast):\n    name: str\n\n@dataclass\nclass CodeBlock(_Ast, ast_utils.AsList):\n    # Corresponds to code_block in the grammar\n    statements: List[_Statement]\n\n@dataclass\nclass If(_Statement):\n    cond: Value\n    then: CodeBlock\n\n@dataclass\nclass SetVar(_Statement):\n    # Corresponds to set_var in the grammar\n    name: str\n    value: Value\n\n@dataclass\nclass Print(_Statement):\n    value: Value\n\nclass ToAst(Transformer):\n    # Define extra transformation functions, for rules that don't correspond to an AST class.\n\n    def STRING(self, s):\n        # Remove quotation marks\n        return s[1:-1]\n\n    def DEC_NUMBER(self, n):\n        return int(n)\n\n    @v_args(inline=True)\n    def start(self, x):\n        return x\n\n#\n#   Define Parser\n#\n\nparser = Lark(\"\"\"\n    start: code_block\n\n    code_block: statement+\n\n    ?statement: if | set_var | print\n\n    if: \"if\" value \"{\" code_block \"}\"\n    set_var: NAME \"=\" value \";\"\n    print: \"print\" value \";\"\n\n    value: name | STRING | DEC_NUMBER\n    name: NAME\n\n    %import python (NAME, STRING, DEC_NUMBER)\n    %import common.WS\n    %ignore WS\n    \"\"\",\n    parser=\"lalr\",\n)\n\ntransformer = ast_utils.create_transformer(this_module, ToAst())\n\ndef parse(text):\n    tree = parser.parse(text)\n    return transformer.transform(tree)\n\n#\n#   Test\n#\n\nif __name__ == '__main__':\n    print(parse(\"\"\"\n        a = 1;\n        if a {\n            print \"a is 1\";\n            a = 2;\n        }\n    \"\"\"))\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/bfeb22cff3ae6c24841aad8c5a95d047/create_ast.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/bfeb22cff3ae6c24841aad8c5a95d047/create_ast.py",
        "status_code": 200,
        "scrape_id": "3ed6943d-7004-4e18-a8dc-ea974687d6b1",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3ed7cc698fc366fe253eac6ecf76ee3e/conf_lalr.py",
      "markdown": "```\n\"\"\"\nLALR’s contextual lexer\n=======================\n\nThis example demonstrates the power of LALR's contextual lexer,\nby parsing a toy configuration language.\n\nThe terminals `NAME` and `VALUE` overlap. They can match the same input.\nA basic lexer would arbitrarily choose one over the other, based on priority,\nwhich would lead to a (confusing) parse error.\nHowever, due to the unambiguous structure of the grammar, Lark's LALR(1) algorithm knows\nwhich one of them to expect at each point during the parse.\nThe lexer then only matches the tokens that the parser expects.\nThe result is a correct parse, something that is impossible with a regular lexer.\n\nAnother approach is to use the Earley algorithm.\nIt will handle more cases than the contextual lexer, but at the cost of performance.\nSee examples/conf_earley.py for an example of that approach.\n\"\"\"\nfrom lark import Lark\n\nparser = Lark(r\"\"\"\n        start: _NL? section+\n        section: \"[\" NAME \"]\" _NL item+\n        item: NAME \"=\" VALUE? _NL\n\n        NAME: /\\w/+\n        VALUE: /./+\n\n        %import common.NEWLINE -> _NL\n        %import common.WS_INLINE\n        %ignore WS_INLINE\n    \"\"\", parser=\"lalr\")\n\nsample_conf = \"\"\"\n[bla]\na=Hello\nthis=\"that\",4\nempty=\n\"\"\"\n\nprint(parser.parse(sample_conf).pretty())\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3ed7cc698fc366fe253eac6ecf76ee3e/conf_lalr.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3ed7cc698fc366fe253eac6ecf76ee3e/conf_lalr.py",
        "status_code": 200,
        "scrape_id": "47f1b995-c7d7-4d28-b1e3-af32f64d8223",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/how_to_use.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- How To Use Lark - Guide\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/how_to_use.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html \"JSON parser - Tutorial\") [Next](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html \"How to develop Lark - Guide\")\n\n* * *\n\n# How To Use Lark - Guide [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#how-to-use-lark-guide \"Permalink to this heading\")\n\n## Work process [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#work-process \"Permalink to this heading\")\n\nThis is the recommended process for working with Lark:\n\n1. Collect or create input samples, that demonstrate key features or behaviors in the language you’re trying to parse.\n\n2. Write a grammar. Try to aim for a structure that is intuitive, and in a way that imitates how you would explain your language to a fellow human.\n\n3. Try your grammar in Lark against each input sample. Make sure the resulting parse-trees make sense.\n\n4. Use Lark’s grammar features to [shape the tree](https://lark-parser.readthedocs.io/en/stable/tree_construction.html): Get rid of superfluous rules by inlining them, and use aliases when specific cases need clarification.\n\nYou can perform steps 1-4 repeatedly, gradually growing your grammar to include more sentences.\n\n5. Create a transformer to evaluate the parse-tree into a structure you’ll be comfortable to work with. This may include evaluating literals, merging branches, or even converting the entire tree into your own set of AST classes.\n\n\nOf course, some specific use-cases may deviate from this process. Feel free to suggest these cases, and I’ll add them to this page.\n\n## Getting started [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#getting-started \"Permalink to this heading\")\n\nBrowse the [Examples](https://github.com/lark-parser/lark/tree/master/examples) to find a template that suits your purposes.\n\nRead the tutorials to get a better understanding of how everything works. (links in the [main page](https://lark-parser.readthedocs.io/en/stable/index.html))\n\nUse the [Cheatsheet (PDF)](https://lark-parser.readthedocs.io/en/latest/_static/lark_cheatsheet.pdf) for quick reference.\n\nUse the reference pages for more in-depth explanations. (links in the [main page](https://lark-parser.readthedocs.io/en/stable/index.html))\n\n## Debug [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#debug \"Permalink to this heading\")\n\nGrammars may contain non-obvious bugs, usually caused by rules or terminals interfering with each other in subtle ways.\n\nWhen trying to debug a misbehaving grammar, the following methodology is recommended:\n\n1. Create a copy of the grammar, so you can change the parser/grammar without any worries\n\n2. Find the minimal input that creates the error\n\n3. Slowly remove rules from the grammar, while making sure the error still occurs.\n\n\nUsually, by the time you get to a minimal grammar, the problem becomes clear.\n\nBut if it doesn’t, feel free to ask us on gitter, or even open an issue. Post a reproducing code, with the minimal grammar and input, and we’ll do our best to help.\n\n### Regex collisions [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#regex-collisions \"Permalink to this heading\")\n\nA likely source of bugs occurs when two regexes in a grammar can match the same input. If both terminals have the same priority, most lexers would arbitrarily choose the first one that matches, which isn’t always the desired one. (a notable exception is the `dynamic_complete` lexer, which always tries all variations. But its users pay for that with performance.)\n\nThese collisions can be hard to notice, and their effects can be difficult to debug, as they are subtle and sometimes hard to reproduce.\n\nTo help with these situations, Lark can utilize a new external library called `interegular`. If it is installed, Lark uses it to check for collisions, and warn about any conflicts that it can find:\n\n```\nimport logging\nfrom lark import Lark, logger\n\nlogger.setLevel(logging.WARN)\n\ncollision_grammar = '''\nstart: A | B\nA: /a+/\nB: /[ab]+/\n'''\np = Lark(collision_grammar, parser='lalr')\n\n# Output:\n# Collision between Terminals B and A. The lexer will choose between them arbitrarily\n# Example Collision: a\n\n```\n\nYou can install interegular for Lark using `pip install 'lark[interegular]'`.\n\nNote 1: Interegular currently only runs when the lexer is `basic` or `contextual`.\n\nNote 2: Some advanced regex features, such as lookahead and lookbehind, may prevent interegular from detecting existing collisions.\n\n### Shift/Reduce collisions [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#shift-reduce-collisions \"Permalink to this heading\")\n\nBy default Lark automatically resolves Shift/Reduce conflicts as Shift. It produces notifications as debug messages.\n\nwhen users pass `debug=True`, those notifications are written as warnings.\n\nEither way, to get the messages printed you have to configure the `logger` beforehand. For example:\n\n```\nimport logging\nfrom lark import Lark, logger\n\nlogger.setLevel(logging.DEBUG)\n\ncollision_grammar = '''\nstart: as as\nas: a*\na: \"a\"\n'''\np = Lark(collision_grammar, parser='lalr', debug=True)\n# Shift/Reduce conflict for terminal A: (resolving as shift)\n#  * <as : >\n# Shift/Reduce conflict for terminal A: (resolving as shift)\n#  * <as : __as_star_0>\n\n```\n\n### Strict-Mode [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#strict-mode \"Permalink to this heading\")\n\nLark, by default, accepts grammars with unresolved Shift/Reduce collisions (which it always resolves to shift), and regex collisions.\n\nStrict-mode allows users to validate that their grammars don’t contain these collisions.\n\nWhen Lark is initialized with `strict=True`, it raises an exception on any Shift/Reduce or regex collision.\n\nIf `interegular` isn’t installed, an exception is thrown.\n\nWhen using strict-mode, users will be expected to resolve their collisions manually:\n\n- To resolve Shift/Reduce collisions, adjust the priority weights of the rules involved, until there are no more collisions.\n\n- To resolve regex collisions, change the involved regexes so that they can no longer both match the same input (Lark provides an example).\n\n\nStrict-mode only applies to LALR for now.\n\n```\nfrom lark import Lark\n\ncollision_grammar = '''\nstart: as as\nas: a*\na: \"a\"\n'''\np = Lark(collision_grammar, parser='lalr', strict=True)\n\n# Traceback (most recent call last):\n#   ...\n# lark.exceptions.GrammarError: Shift/Reduce conflict for terminal A. [strict-mode]\n\n```\n\n## Tools [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#tools \"Permalink to this heading\")\n\n### Stand-alone parser [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#stand-alone-parser \"Permalink to this heading\")\n\nLark can generate a stand-alone LALR(1) parser from a grammar.\n\nThe resulting module provides the same interface as Lark, but with a fixed grammar, and reduced functionality.\n\nRun using:\n\n```\npython -m lark.tools.standalone\n\n```\n\nFor a play-by-play, read the [tutorial](http://blog.erezsh.com/create-a-stand-alone-lalr1-parser-in-python/)\n\n### Import Nearley.js grammars [](https://lark-parser.readthedocs.io/en/stable/how_to_use.html\\#import-nearley-js-grammars \"Permalink to this heading\")\n\nIt is possible to import Nearley grammars into Lark. The Javascript code is translated using Js2Py.\n\nSee the [tools page](https://lark-parser.readthedocs.io/en/stable/tools.html) for more information.\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/how_to_use.html)**[stable](https://lark-parser.readthedocs.io/en/stable/how_to_use.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "How To Use Lark - Guide — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/how_to_use.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/how_to_use.html",
        "status_code": 200,
        "scrape_id": "ed6ab8f1-3e98-4276-a43c-df337f36b2db",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/1e229dcdb521be752d4349e61ead59d1/qscintilla_json.py",
      "markdown": "```\n\"\"\"\nSyntax Highlighting\n===================\n\nThis example shows how to write a syntax-highlighted editor with Qt and Lark\n\nRequirements:\n\n  PyQt5==5.15.8\n  QScintilla==2.13.4\n\"\"\"\n\nimport sys\nimport textwrap\n\nfrom PyQt5.QtWidgets import QApplication\nfrom PyQt5.QtGui import QColor, QFont, QFontMetrics\n\nfrom PyQt5.Qsci import QsciScintilla\nfrom PyQt5.Qsci import QsciLexerCustom\n\nfrom lark import Lark\n\nclass LexerJson(QsciLexerCustom):\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self.create_parser()\n        self.create_styles()\n\n    def create_styles(self):\n        deeppink = QColor(249, 38, 114)\n        khaki = QColor(230, 219, 116)\n        mediumpurple = QColor(174, 129, 255)\n        mediumturquoise = QColor(81, 217, 205)\n        yellowgreen = QColor(166, 226, 46)\n        lightcyan = QColor(213, 248, 232)\n        darkslategrey = QColor(39, 40, 34)\n\n        styles = {\n            0: mediumturquoise,\n            1: mediumpurple,\n            2: yellowgreen,\n            3: deeppink,\n            4: khaki,\n            5: lightcyan\n        }\n\n        for style, color in styles.items():\n            self.setColor(color, style)\n            self.setPaper(darkslategrey, style)\n            self.setFont(self.parent().font(), style)\n\n        self.token_styles = {\n            \"COLON\": 5,\n            \"COMMA\": 5,\n            \"LBRACE\": 5,\n            \"LSQB\": 5,\n            \"RBRACE\": 5,\n            \"RSQB\": 5,\n            \"FALSE\": 0,\n            \"NULL\": 0,\n            \"TRUE\": 0,\n            \"STRING\": 4,\n            \"NUMBER\": 1,\n        }\n\n    def create_parser(self):\n        grammar = '''\n            anons: \":\" \"{\" \"}\" \",\" \"[\" \"]\"\n            TRUE: \"true\"\n            FALSE: \"false\"\n            NULL: \"NULL\"\n            %import common.ESCAPED_STRING -> STRING\n            %import common.SIGNED_NUMBER  -> NUMBER\n            %import common.WS\n            %ignore WS\n        '''\n\n        self.lark = Lark(grammar, parser=None, lexer='basic')\n        # All tokens: print([t.name for t in self.lark.parser.lexer.tokens])\n\n    def defaultPaper(self, style):\n        return QColor(39, 40, 34)\n\n    def language(self):\n        return \"Json\"\n\n    def description(self, style):\n        return {v: k for k, v in self.token_styles.items()}.get(style, \"\")\n\n    def styleText(self, start, end):\n        self.startStyling(start)\n        text = self.parent().text()[start:end]\n        last_pos = 0\n\n        try:\n            for token in self.lark.lex(text):\n                ws_len = token.start_pos - last_pos\n                if ws_len:\n                    self.setStyling(ws_len, 0)    # whitespace\n\n                token_len = len(bytearray(token, \"utf-8\"))\n                self.setStyling(\n                    token_len, self.token_styles.get(token.type, 0))\n\n                last_pos = token.start_pos + token_len\n        except Exception as e:\n            print(e)\n\nclass EditorAll(QsciScintilla):\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n\n        # Set font defaults\n        font = QFont()\n        font.setFamily('Consolas')\n        font.setFixedPitch(True)\n        font.setPointSize(8)\n        font.setBold(True)\n        self.setFont(font)\n\n        # Set margin defaults\n        fontmetrics = QFontMetrics(font)\n        self.setMarginsFont(font)\n        self.setMarginWidth(0, fontmetrics.width(\"000\") + 6)\n        self.setMarginLineNumbers(0, True)\n        self.setMarginsForegroundColor(QColor(128, 128, 128))\n        self.setMarginsBackgroundColor(QColor(39, 40, 34))\n        self.setMarginType(1, self.SymbolMargin)\n        self.setMarginWidth(1, 12)\n\n        # Set indentation defaults\n        self.setIndentationsUseTabs(False)\n        self.setIndentationWidth(4)\n        self.setBackspaceUnindents(True)\n        self.setIndentationGuides(True)\n\n        # self.setFolding(QsciScintilla.CircledFoldStyle)\n\n        # Set caret defaults\n        self.setCaretForegroundColor(QColor(247, 247, 241))\n        self.setCaretWidth(2)\n\n        # Set selection color defaults\n        self.setSelectionBackgroundColor(QColor(61, 61, 52))\n        self.resetSelectionForegroundColor()\n\n        # Set multiselection defaults\n        self.SendScintilla(QsciScintilla.SCI_SETMULTIPLESELECTION, True)\n        self.SendScintilla(QsciScintilla.SCI_SETMULTIPASTE, 1)\n        self.SendScintilla(\n            QsciScintilla.SCI_SETADDITIONALSELECTIONTYPING, True)\n\n        lexer = LexerJson(self)\n        self.setLexer(lexer)\n\nEXAMPLE_TEXT = textwrap.dedent(\"\"\"\\\n        {\n            \"_id\": \"5b05ffcbcf8e597939b3f5ca\",\n            \"about\": \"Excepteur consequat commodo esse voluptate aute aliquip ad sint deserunt commodo eiusmod irure. Sint aliquip sit magna duis eu est culpa aliqua excepteur ut tempor nulla. Aliqua ex pariatur id labore sit. Quis sit ex aliqua veniam exercitation laboris anim adipisicing. Lorem nisi reprehenderit ullamco labore qui sit ut aliqua tempor consequat pariatur proident.\",\n            \"address\": \"665 Malbone Street, Thornport, Louisiana, 243\",\n            \"age\": 23,\n            \"balance\": \"$3,216.91\",\n            \"company\": \"BULLJUICE\",\n            \"email\": \"elisekelley@bulljuice.com\",\n            \"eyeColor\": \"brown\",\n            \"gender\": \"female\",\n            \"guid\": \"d3a6d865-0f64-4042-8a78-4f53de9b0707\",\n            \"index\": 0,\n            \"isActive\": false,\n            \"isActive2\": true,\n            \"latitude\": -18.660714,\n            \"longitude\": -85.378048,\n            \"name\": \"Elise Kelley\",\n            \"phone\": \"+1 (808) 543-3966\",\n            \"picture\": \"http://placehold.it/32x32\",\n            \"registered\": \"2017-09-30T03:47:40 -02:00\",\n            \"tags\": [\\\n                \"et\",\\\n                \"nostrud\",\\\n                \"in\",\\\n                \"fugiat\",\\\n                \"incididunt\",\\\n                \"labore\",\\\n                \"nostrud\"\\\n            ]\n        }\\\n    \"\"\")\n\ndef main():\n    app = QApplication(sys.argv)\n    ex = EditorAll()\n    ex.setWindowTitle(__file__)\n    ex.setText(EXAMPLE_TEXT)\n    ex.resize(800, 600)\n    ex.show()\n    sys.exit(app.exec_())\n\nif __name__ == \"__main__\":\n    main()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/1e229dcdb521be752d4349e61ead59d1/qscintilla_json.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/1e229dcdb521be752d4349e61ead59d1/qscintilla_json.py",
        "status_code": 200,
        "scrape_id": "738efb58-45a5-4a31-af11-35af5e116394",
        "content_type": "text/x-python; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/grammar.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Grammar Reference\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/grammar.md)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html \"Standalone Parser\") [Next](https://lark-parser.readthedocs.io/en/stable/tree_construction.html \"Tree Construction Reference\")\n\n* * *\n\n# Grammar Reference [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#grammar-reference \"Permalink to this heading\")\n\n## Definitions [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#definitions \"Permalink to this heading\")\n\nA **grammar** is a list of rules and terminals, that together define a language.\n\nTerminals define the alphabet of the language, while rules define its structure.\n\nIn Lark, a terminal may be a string, a regular expression, or a concatenation of these and other terminals.\n\nEach rule is a list of terminals and rules, whose location and nesting define the structure of the resulting parse-tree.\n\nA **parsing algorithm** is an algorithm that takes a grammar definition and a sequence of symbols (members of the alphabet), and matches the entirety of the sequence by searching for a structure that is allowed by the grammar.\n\n### General Syntax and notes [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#general-syntax-and-notes \"Permalink to this heading\")\n\nGrammars in Lark are based on [EBNF](https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_form) syntax, with several enhancements.\n\nEBNF is basically a short-hand for common BNF patterns.\n\nOptionals are expanded:\n\n```\n  a b? c    ->    (a c | a b c)\n\n```\n\nRepetition is extracted into a recursion:\n\n```\n  a: b*    ->    a: _b_tag\n                 _b_tag: (_b_tag b)?\n\n```\n\nAnd so on.\n\nLark grammars are composed of a list of definitions and directives, each on its own line. A definition is either a named rule, or a named terminal, with the following syntax, respectively:\n\n```\n  rule: <EBNF EXPRESSION>\n      | etc.\n\n  TERM: <EBNF EXPRESSION>   // Rules aren't allowed\n\n```\n\n**Comments** start with\neither `//` (C++ style) or `#` (Python style, since version 1.1.6)\nand last to the end of the line.\n\nLark begins the parse with the rule ‘start’, unless specified otherwise in the options.\n\nNames of rules are always in lowercase, while names of terminals are always in uppercase. This distinction has practical effects, for the shape of the generated parse-tree, and the automatic construction of the lexer (aka tokenizer, or scanner).\n\n## Terminals [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#terminals \"Permalink to this heading\")\n\nTerminals are used to match text into symbols. They can be defined as a combination of literals and other terminals.\n\n**Syntax:**\n\n```\n<NAME> [. <priority>] : <literals-and-or-terminals>\n\n```\n\nTerminal names must be uppercase.\n\nLiterals can be one of:\n\n- `\"string\"`\n\n- `/regular expression+/`\n\n- `\"case-insensitive string\"i`\n\n- `/re with flags/imulx`\n\n- Literal range: `\"a\"..\"z\"`, `\"1\"..\"9\"`, etc.\n\n\nTerminals also support grammar operators, such as `|`, `+`, `*` and `?`.\n\nTerminals are a linear construct, and therefore may not contain themselves (recursion isn’t allowed).\n\n### Templates [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#templates \"Permalink to this heading\")\n\nTemplates are expanded when preprocessing the grammar.\n\nDefinition syntax:\n\n```\n  my_template{param1, param2, ...}: <EBNF EXPRESSION>\n\n```\n\nUse syntax:\n\n```\nsome_rule: my_template{arg1, arg2, ...}\n\n```\n\nExample:\n\n```\n_separated{x, sep}: x (sep x)*  // Define a sequence of 'x sep x sep x ...'\n\nnum_list: \"[\" _separated{NUMBER, \",\"} \"]\"   // Will match \"[1, 2, 3]\" etc.\n\n```\n\n### Priority [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#priority \"Permalink to this heading\")\n\nTerminals can be assigned a priority to influence lexing. Terminal priorities\nare signed integers with a default value of 0.\n\nWhen using a lexer, the highest priority terminals are always matched first.\n\nWhen using Earley’s dynamic lexing, terminal priorities are used to prefer\ncertain lexings and resolve ambiguity.\n\n### Regexp Flags [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#regexp-flags \"Permalink to this heading\")\n\nYou can use flags on regexps and strings. For example:\n\n```\nSELECT: \"select\"i     //# Will ignore case, and match SELECT or Select, etc.\nMULTILINE_TEXT: /.+/s\nSIGNED_INTEGER: /\n    [+-]?  # the sign\n    (0|[1-9][0-9]*)  # the digits\n /x\n\n```\n\nSupported flags are one of: `imslux`. See Python’s regex documentation for more details on each one.\n\nRegexps/strings of different flags can only be concatenated in Python 3.6+\n\n#### Notes for when using a lexer: [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#notes-for-when-using-a-lexer \"Permalink to this heading\")\n\nWhen using a lexer (basic or contextual), it is the grammar-author’s responsibility to make sure the literals don’t collide, or that if they do, they are matched in the desired order. Literals are matched according to the following precedence:\n\n1. Highest priority first (priority is specified as: TERM.number: …)\n\n2. Length of match (for regexps, the longest theoretical match is used)\n\n3. Length of literal / pattern definition\n\n4. Name\n\n\n**Examples:**\n\n```\nIF: \"if\"\nINTEGER : /[0-9]+/\nINTEGER2 : (\"0\"..\"9\")+          //# Same as INTEGER\nDECIMAL.2: INTEGER? \".\" INTEGER  //# Will be matched before INTEGER\nWHITESPACE: (\" \" | /\\t/ )+\nSQL_SELECT: \"select\"i\n\n```\n\n### Regular expressions & Ambiguity [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#regular-expressions-ambiguity \"Permalink to this heading\")\n\nEach terminal is eventually compiled to a regular expression. All the operators and references inside it are mapped to their respective expressions.\n\nFor example, in the following grammar, `A1` and `A2`, are equivalent:\n\n```\nA1: \"a\" | \"b\"\nA2: /a|b/\n\n```\n\nThis means that inside terminals, Lark cannot detect or resolve ambiguity, even when using Earley.\n\nFor example, for this grammar:\n\n```\nstart           : (A | B)+\nA               : \"a\" | \"ab\"\nB               : \"b\"\n\n```\n\nWe get only one possible derivation, instead of two:\n\n```\n>>> p = Lark(g, ambiguity=\"explicit\")\n>>> p.parse(\"ab\")\nTree('start', [Token('A', 'ab')])\n\n```\n\nThis is happening because Python’s regex engine always returns the best matching option. There is no way to access the alternatives.\n\nIf you find yourself in this situation, the recommended solution is to use rules instead.\n\nExample:\n\n```\n>>> p = Lark(\"\"\"start: (a | b)+\n...             !a: \"a\" | \"ab\"\n...             !b: \"b\"\n...             \"\"\", ambiguity=\"explicit\")\n>>> print(p.parse(\"ab\").pretty())\n_ambig\n  start\n    a   ab\n  start\n    a   a\n    b   b\n\n```\n\n## Rules [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#rules \"Permalink to this heading\")\n\n**Syntax:**\n\n```\n<name> : <items-to-match>  [-> <alias> ]\n       | ...\n\n```\n\nNames of rules and aliases are always in lowercase.\n\nRule definitions can be extended to the next line by using the OR operator (signified by a pipe: `|` ).\n\nAn alias is a name for the specific rule alternative. It affects tree construction.\n\nEach item is one of:\n\n- `rule`\n\n- `TERMINAL`\n\n- `\"string literal\"` or `/regexp literal/`\n\n- `(item item ..)` \\- Group items\n\n- `[item item ..]` \\- Maybe. Same as `(item item ..)?`, but when `maybe_placeholders=True`, generates `None` if there is no match.\n\n- `item?` \\- Zero or one instances of item (”maybe”)\n\n- `item*` \\- Zero or more instances of item\n\n- `item+` \\- One or more instances of item\n\n- `item ~ n` \\- Exactly _n_ instances of item\n\n- `item ~ n..m` \\- Between _n_ to _m_ instances of item (not recommended for wide ranges, due to performance issues)\n\n\n**Examples:**\n\n```\nhello_world: \"hello\" \"world\"\nmul: (mul \"*\")? number     //# Left-recursion is allowed and encouraged!\nexpr: expr operator expr\n    | value               //# Multi-line, belongs to expr\n\nfour_words: word ~ 4\n\n```\n\n### Priority [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#id1 \"Permalink to this heading\")\n\nLike terminals, rules can be assigned a priority. Rule priorities are signed\nintegers with a default value of 0.\n\nWhen using LALR, the highest priority rules are used to resolve collision errors.\n\nWhen using Earley, rule priorities are used to resolve ambiguity.\n\n## Directives [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#directives \"Permalink to this heading\")\n\n### %ignore [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#ignore \"Permalink to this heading\")\n\nAll occurrences of the terminal will be ignored, and won’t be part of the parse.\n\nUsing the `%ignore` directive results in a cleaner grammar.\n\nIt’s especially important for the LALR(1) algorithm, because adding whitespace (or comments, or other extraneous elements) explicitly in the grammar, harms its predictive abilities, which are based on a lookahead of 1.\n\n**Syntax:**\n\n```\n%ignore <TERMINAL>\n\n```\n\n**Examples:**\n\n```\n%ignore \" \"\n\nCOMMENT: \"#\" /[^\\n]/*\n%ignore COMMENT\n\n```\n\n### %import [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#import \"Permalink to this heading\")\n\nAllows one to import terminals and rules from lark grammars.\n\nWhen importing rules, all their dependencies will be imported into a namespace, to avoid collisions. It’s not possible to override their dependencies (e.g. like you would when inheriting a class).\n\n**Syntax:**\n\n```\n%import <module>.<TERMINAL>\n%import <module>.<rule>\n%import <module>.<TERMINAL> -> <NEWTERMINAL>\n%import <module>.<rule> -> <newrule>\n%import <module> (<TERM1>, <TERM2>, <rule1>, <rule2>)\n\n```\n\nIf the module path is absolute, Lark will attempt to load it from the built-in directory (which currently contains `common.lark`, `python.lark`, and `unicode.lark`).\n\nIf the module path is relative, such as `.path.to.file`, Lark will attempt to load it from the current working directory. Grammars must have the `.lark` extension.\n\nThe rule or terminal can be imported under another name with the `->` syntax.\n\n**Example:**\n\n```\n%import common.NUMBER\n\n%import .terminals_file (A, B, C)\n\n%import .rules_file.rulea -> ruleb\n\n```\n\nNote that `%ignore` directives cannot be imported. Imported rules will abide by the `%ignore` directives declared in the main grammar.\n\n### %declare [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#declare \"Permalink to this heading\")\n\nDeclare a terminal without defining it. Useful for plugins.\n\n### %override [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#override \"Permalink to this heading\")\n\nOverride a rule or terminals, affecting all references to it, even in imported grammars.\n\nUseful for implementing an inheritance pattern when importing grammars.\n\n**Example:**\n\n```\n%import my_grammar (start, number, NUMBER)\n\n// Add hex support to my_grammar\n%override number: NUMBER | /0x\\w+/\n\n```\n\n### %extend [](https://lark-parser.readthedocs.io/en/stable/grammar.html\\#extend \"Permalink to this heading\")\n\nExtend the definition of a rule or terminal, e.g. add a new option on what it can match, like when separated with `|`.\n\nUseful for splitting up a definition of a complex rule with many different options over multiple files.\n\nCan also be used to implement a plugin system where a core grammar is extended by others.\n\n**Example:**\n\n```\n%import my_grammar (start, NUMBER)\n\n// Add hex support to my_grammar\n%extend NUMBER: /0x\\w+/\n\n```\n\nFor both `%extend` and `%override`, there is not requirement for a rule/terminal to come from another file, but that is probably the most common usecase\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/grammar.html)**[stable](https://lark-parser.readthedocs.io/en/stable/grammar.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Grammar Reference — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/grammar.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/grammar.html",
        "status_code": 200,
        "scrape_id": "387cc875-01be-45b4-90ce-9f8573ca72d9",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/59e28e5e93b13914beea3268d124ef92/eval_json.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"Transformer for evaluating json.lark\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Transformer, v_args\\n\\nclass JsonTreeToJson(Transformer):\\n    @v_args(inline=True)\\n    def string(self, s):\\n        return s[1:-1].replace('\\\\\\\\\\\"', '\\\"')\\n\\n    array = list\\n    pair = tuple\\n    object = dict\\n    number = v_args(inline=True)(float)\\n\\n    null = lambda self, _: None\\n    true = lambda self, _: True\\n    false = lambda self, _: False\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/59e28e5e93b13914beea3268d124ef92/eval_json.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/59e28e5e93b13914beea3268d124ef92/eval_json.ipynb",
        "status_code": 200,
        "scrape_id": "43c939be-f5c9-42a2-a9d9-0dd32edd2432",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3933bf173c425fd28a9c4d7c72b8eca1/python_parser.py",
      "markdown": "```\n\"\"\"\nGrammar-complete Python Parser\n==============================\n\nA fully-working Python 2 & 3 parser (but not production ready yet!)\n\nThis example demonstrates usage of the included Python grammars\n\"\"\"\nimport sys\nimport os, os.path\nfrom io import open\nimport glob, time\n\nfrom lark import Lark\nfrom lark.indenter import PythonIndenter\n\nkwargs = dict(postlex=PythonIndenter(), start='file_input')\n\n# Official Python grammar by Lark\npython_parser3 = Lark.open_from_package('lark', 'python.lark', ['grammars'], parser='lalr', **kwargs)\n\n# Local Python2 grammar\npython_parser2 = Lark.open('python2.lark', rel_to=__file__, parser='lalr', **kwargs)\npython_parser2_earley = Lark.open('python2.lark', rel_to=__file__, parser='earley', lexer='basic', **kwargs)\n\ntry:\n    xrange\nexcept NameError:\n    chosen_parser = python_parser3\nelse:\n    chosen_parser = python_parser2\n\ndef _read(fn, *args):\n    kwargs = {'encoding': 'iso-8859-1'}\n    with open(fn, *args, **kwargs) as f:\n        return f.read()\n\ndef _get_lib_path():\n    if os.name == 'nt':\n        if 'PyPy' in sys.version:\n            return os.path.join(sys.base_prefix, 'lib-python', sys.winver)\n        else:\n            return os.path.join(sys.base_prefix, 'Lib')\n    else:\n        return [x for x in sys.path if x.endswith('%s.%s' % sys.version_info[:2])][0]\n\ndef test_python_lib():\n    path = _get_lib_path()\n\n    start = time.time()\n    files = glob.glob(path+'/*.py')\n    total_kb = 0\n    for f in files:\n        r = _read(os.path.join(path, f))\n        kb = len(r) / 1024\n        print( '%s -\\t%.1f kb' % (f, kb))\n        chosen_parser.parse(r + '\\n')\n        total_kb += kb\n\n    end = time.time()\n    print( \"test_python_lib (%d files, %.1f kb), time: %.2f secs\"%(len(files), total_kb, end-start) )\n\ndef test_earley_equals_lalr():\n    path = _get_lib_path()\n\n    files = glob.glob(path+'/*.py')\n    for f in files:\n        print( f )\n        tree1 = python_parser2.parse(_read(os.path.join(path, f)) + '\\n')\n        tree2 = python_parser2_earley.parse(_read(os.path.join(path, f)) + '\\n')\n        assert tree1 == tree2\n\nif __name__ == '__main__':\n    test_python_lib()\n    # test_earley_equals_lalr()\n    # python_parser3.parse(_read(sys.argv[1]) + '\\n')\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3933bf173c425fd28a9c4d7c72b8eca1/python_parser.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3933bf173c425fd28a9c4d7c72b8eca1/python_parser.py",
        "status_code": 200,
        "scrape_id": "c006aa5f-b231-4506-99ae-d1539f08cd38",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_static/lark_cheatsheet.pdf",
      "markdown": "# Lark Cheat Sheet\n\n|     |     |\n| --- | --- |\n| Tree Shaping |\n| rule: \"foo\" BAR | \"foo\" will be filtered out |\n| !rule: \"foo\" BAR | \"foo\" will be kept |\n| rule: /foo/ BAR | /foo/ will be kept |\n| \\_TERM | Filterout this terminal |\n| \\_rule | Always inline this rule |\n| ?rule: | Inline if matched 1 child |\n| foo bar -> alias | Createalias |\n\nRules are a branch (node) in the resulting tree, and its children are its matches, in the order of matching.\n\nTerm​inals (tokens) are always values in the tree, never branches.\n\nInlining rules means removing their branch and replacing it with their children.\n\n|     |     |     |     |\n| --- | --- | --- | --- |\n| leatograpny byerezsh via cheatography.com/61630/cs/15 |\n| Lark Options | Grammar Definitions |  |\n| parser=\"earley\" | Use the Earley parser (default) | rule: ... | Define a rule |\n| Use the LALR(1) | TERM:... | Define a terminal |\n| parser=\"lalr\" | parser | rule.n: | Rule with priority n |\n| Use the CYK | TERM.n:.. | Terminal with priority n |\n| lexer=\"standard\" | parser | // text | Comment |\n| Use the standard lexer | %ignore ... | Ignore terminal in input |\n| ambiguity='explicit' | Return all | %import ... | Import terminal from file |\n| derivations for Earley | %declare TERM | Declare a terminal without a pattern (used for postlex) |\n| start=\"foo\" | Use \"foo\" as starting rule | Rules consist of values, other rules and terminals. Terminals only consist of values and other |\n| transformer=... | Apply transformer to tree (for LALR) | terminals. |\n| propagate\\_positions | Fill tre instances with line number | Grammar Patterns |  |\n| information | foo bar | Match sequence |\n| keep\\_all\\_tokens | Don't remove | (foo bar) | Group together (for operations) |\n| unnamed | foo 丨 bar | Match one or the other |\n| postlex | terminals | foo？ | Match Oor 1 instances |\n| Provide a wrapper for the | \\[foo bar\\] | Match O or 1 instances |\n|  | lexer | foo\\* | Match O or more instances |\n| Provide an | foo+ | Match 1 or more instances |\n|  | alternative for Tree |  |  |\n|  | foo~3 | Match exactly3 instances |\n| Token Reference |  |  |\n| token.type | Returns name of terminal | Terminal Atoms |  |\n|  | \"string\" | String to match |\n| token.value | Return matched string | \"string\"i | Case-insensitive string |\n| token.line | Line of match | /regexp/ | Regular Expression |\n| token.column | Column of match | /re/imslux | Regular Expression with flags |\n| token.end\\_line | Line where match ends | \"a\"..\"z\" | Literal range |\n| token.end\\_colu ends | Column where match |  |  |\n| mn len(token) Length of match |  |  |\n| Tokens inherit from str, so all string operations are valid |  |  |\n\nTree Reference\n\n|     |     |\n| --- | --- |\n| tree.data | Get rule name |\n| tree.children | Get rule matches |\n| print(tree.pretty()) | Pretty-print tree |\n| tree.iter\\_subtrees() | Iterate on all |\n|  | nodes |\n| tree.find\\_data(\"foo\") | Findnodeswith |\n| rule foo |\n| tree.find\\_pred(...) | Find nodes by |\n| predicate |\n| tree1 == tree2 | Compare trees |",
      "metadata": {
        "title": "Lark Cheat Sheet by erezsh - Cheatography.com",
        "url": "https://lark-parser.readthedocs.io/en/stable/_static/lark_cheatsheet.pdf",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_static/lark_cheatsheet.pdf",
        "status_code": 200,
        "scrape_id": "620a8ff7-afa4-4d37-8e61-a881d451b677",
        "num_pages": 1,
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Reconstruct Python\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/reconstruct_python.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html \"Example-Driven Error Reporting\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html \"Using lexer dynamic_complete\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html#sphx-glr-download-examples-advanced-reconstruct-python-py)\nto download the full example code\n\n# Reconstruct Python [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html\\#reconstruct-python \"Permalink to this heading\")\n\nDemonstrates how Lark’s experimental text-reconstruction feature can recreate\nfunctional Python code from its parse-tree, using just the correct grammar and\na small formatter.\n\n```\nfrom lark import Token, Lark\nfrom lark.reconstruct import Reconstructor\nfrom lark.indenter import PythonIndenter\n\n# Official Python grammar by Lark\npython_parser3 = Lark.open_from_package('lark', 'python.lark', ['grammars'],\n                                        parser='lalr', postlex=PythonIndenter(), start='file_input',\n                                        maybe_placeholders=False    # Necessary for reconstructor\n                                        )\n\nSPACE_AFTER = set(',+-*/~@<>=\"|:')\nSPACE_BEFORE = (SPACE_AFTER - set(',:')) | set('\\'')\n\ndef special(sym):\n    return Token('SPECIAL', sym.name)\n\ndef postproc(items):\n    stack = ['\\n']\n    actions = []\n    last_was_whitespace = True\n    for item in items:\n        if isinstance(item, Token) and item.type == 'SPECIAL':\n            actions.append(item.value)\n        else:\n            if actions:\n                assert actions[0] == '_NEWLINE' and '_NEWLINE' not in actions[1:], actions\n\n                for a in actions[1:]:\n                    if a == '_INDENT':\n                        stack.append(stack[-1] + ' ' * 4)\n                    else:\n                        assert a == '_DEDENT'\n                        stack.pop()\n                actions.clear()\n                yield stack[-1]\n                last_was_whitespace = True\n            if not last_was_whitespace:\n                if item[0] in SPACE_BEFORE:\n                    yield ' '\n            yield item\n            last_was_whitespace = item[-1].isspace()\n            if not last_was_whitespace:\n                if item[-1] in SPACE_AFTER:\n                    yield ' '\n                    last_was_whitespace = True\n    yield \"\\n\"\n\nclass PythonReconstructor:\n    def __init__(self, parser):\n        self._recons = Reconstructor(parser, {'_NEWLINE': special, '_DEDENT': special, '_INDENT': special})\n\n    def reconstruct(self, tree):\n        return self._recons.reconstruct(tree, postproc)\n\ndef test():\n    python_reconstructor = PythonReconstructor(python_parser3)\n\n    self_contents = open(__file__).read()\n\n    tree = python_parser3.parse(self_contents+'\\n')\n    output = python_reconstructor.reconstruct(tree)\n\n    tree_new = python_parser3.parse(output)\n    print(tree.pretty())\n    print(tree_new.pretty())\n    # assert tree.pretty() == tree_new.pretty()\n    assert tree == tree_new\n\n    print(output)\n\nif __name__ == '__main__':\n    test()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: reconstruct_python.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/3b0766c1f76ff2904339853615cf4943/reconstruct_python.py)\n\n[`Download Jupyter notebook: reconstruct_python.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/57b38708c982e98764460c3e288a1ff5/reconstruct_python.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/reconstruct_python.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Reconstruct Python — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html",
        "status_code": 200,
        "scrape_id": "72ecb45e-612f-4d13-8c19-73225a6242e5",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/#)\n- Welcome to Lark’s documentation!\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/index.rst)\n\n[Next](https://lark-parser.readthedocs.io/en/stable/philosophy.html \"Philosophy\")\n\n* * *\n\n# Welcome to Lark’s documentation! [](https://lark-parser.readthedocs.io/en/stable/\\#welcome-to-lark-s-documentation \"Permalink to this heading\")\n\nLark is a modern parsing library for Python. Lark can parse any context-free grammar.\n\nLark provides:\n\n- Advanced grammar language, based on EBNF\n\n- Three parsing algorithms to choose from: Earley, LALR(1) and CYK\n\n- Automatic tree construction, inferred from your grammar\n\n- Fast unicode lexer with regexp support, and automatic line-counting\n\n\n## Install Lark [](https://lark-parser.readthedocs.io/en/stable/\\#install-lark \"Permalink to this heading\")\n\n```\n$ pip install lark\n\n```\n\n## Syntax Highlighting [](https://lark-parser.readthedocs.io/en/stable/\\#syntax-highlighting \"Permalink to this heading\")\n\n- [Sublime Text & TextMate](https://github.com/lark-parser/lark_syntax)\n\n- [Visual Studio Code](https://github.com/lark-parser/vscode-lark) (Or install through the vscode plugin system)\n\n- [Intellij & PyCharm](https://github.com/lark-parser/intellij-syntax-highlighting)\n\n- [Vim](https://github.com/lark-parser/vim-lark-syntax)\n\n- [Atom](https://github.com/Alhadis/language-grammars)\n\n\n## Resources [](https://lark-parser.readthedocs.io/en/stable/\\#resources \"Permalink to this heading\")\n\n- [Philosophy](https://lark-parser.readthedocs.io/en/stable/philosophy.html)\n\n- [Features](https://lark-parser.readthedocs.io/en/stable/features.html)\n\n- [Examples](https://github.com/lark-parser/lark/tree/master/examples)\n\n- [Third-party examples](https://github.com/ligurio/lark-grammars)\n\n- [Online IDE](https://lark-parser.org/ide)\n\n- Tutorials\n\n  - [How to write a DSL](http://blog.erezsh.com/how-to-write-a-dsl-in-python-with-lark/) \\- Implements a toy LOGO-like language with\n    an interpreter\n\n  - [JSON parser - Tutorial](https://lark-parser.readthedocs.io/en/stable/json_tutorial.html) \\- Teaches you how to use Lark\n\n  - Unofficial\n\n    - [Program Synthesis is Possible](https://www.cs.cornell.edu/~asampson/blog/minisynth.html) \\- Creates a DSL for Z3\n\n    - [Using Lark to Parse Text - Robin Reynolds-Haertle (PyCascades 2023)](https://www.youtube.com/watch?v=CeOtqlh0UuQ) (video presentation)\n- Guides\n\n  - [How To Use Lark - Guide](https://lark-parser.readthedocs.io/en/stable/how_to_use.html)\n\n  - [How to develop Lark - Guide](https://lark-parser.readthedocs.io/en/stable/how_to_develop.html)\n- Reference\n\n  - [Grammar Reference](https://lark-parser.readthedocs.io/en/stable/grammar.html)\n\n  - [Tree Construction Reference](https://lark-parser.readthedocs.io/en/stable/tree_construction.html)\n\n  - [Transformers & Visitors](https://lark-parser.readthedocs.io/en/stable/visitors.html)\n\n  - [Working with the SPPF](https://lark-parser.readthedocs.io/en/stable/forest.html)\n\n  - [API Reference](https://lark-parser.readthedocs.io/en/stable/classes.html)\n\n  - [Tools (Stand-alone, Nearley)](https://lark-parser.readthedocs.io/en/stable/tools.html)\n\n  - [Cheatsheet (PDF)](https://lark-parser.readthedocs.io/en/stable/_static/lark_cheatsheet.pdf)\n- Discussion\n\n  - [Gitter](https://gitter.im/lark-parser/Lobby)\n\n  - [Forum (Google Groups)](https://groups.google.com/forum/#!forum/lark-parser)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/)**[stable](https://lark-parser.readthedocs.io/en/stable/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Welcome to Lark’s documentation! — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable",
        "status_code": 200,
        "scrape_id": "69287ed1-f49b-4b07-90b1-fd9914e0afe5",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9056f9d3440746d8fe151c31173e18e6/qscintilla_json.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Syntax Highlighting\\n\\nThis example shows how to write a syntax-highlighted editor with Qt and Lark\\n\\nRequirements:\\n\\n  PyQt5==5.15.8\\n  QScintilla==2.13.4\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import sys\\nimport textwrap\\n\\nfrom PyQt5.QtWidgets import QApplication\\nfrom PyQt5.QtGui import QColor, QFont, QFontMetrics\\n\\nfrom PyQt5.Qsci import QsciScintilla\\nfrom PyQt5.Qsci import QsciLexerCustom\\n\\nfrom lark import Lark\\n\\n\\nclass LexerJson(QsciLexerCustom):\\n\\n    def __init__(self, parent=None):\\n        super().__init__(parent)\\n        self.create_parser()\\n        self.create_styles()\\n\\n    def create_styles(self):\\n        deeppink = QColor(249, 38, 114)\\n        khaki = QColor(230, 219, 116)\\n        mediumpurple = QColor(174, 129, 255)\\n        mediumturquoise = QColor(81, 217, 205)\\n        yellowgreen = QColor(166, 226, 46)\\n        lightcyan = QColor(213, 248, 232)\\n        darkslategrey = QColor(39, 40, 34)\\n\\n        styles = {\\n            0: mediumturquoise,\\n            1: mediumpurple,\\n            2: yellowgreen,\\n            3: deeppink,\\n            4: khaki,\\n            5: lightcyan\\n        }\\n\\n        for style, color in styles.items():\\n            self.setColor(color, style)\\n            self.setPaper(darkslategrey, style)\\n            self.setFont(self.parent().font(), style)\\n\\n        self.token_styles = {\\n            \\\"COLON\\\": 5,\\n            \\\"COMMA\\\": 5,\\n            \\\"LBRACE\\\": 5,\\n            \\\"LSQB\\\": 5,\\n            \\\"RBRACE\\\": 5,\\n            \\\"RSQB\\\": 5,\\n            \\\"FALSE\\\": 0,\\n            \\\"NULL\\\": 0,\\n            \\\"TRUE\\\": 0,\\n            \\\"STRING\\\": 4,\\n            \\\"NUMBER\\\": 1,\\n        }\\n\\n    def create_parser(self):\\n        grammar = '''\\n            anons: \\\":\\\" \\\"{\\\" \\\"}\\\" \\\",\\\" \\\"[\\\" \\\"]\\\"\\n            TRUE: \\\"true\\\"\\n            FALSE: \\\"false\\\"\\n            NULL: \\\"NULL\\\"\\n            %import common.ESCAPED_STRING -> STRING\\n            %import common.SIGNED_NUMBER  -> NUMBER\\n            %import common.WS\\n            %ignore WS\\n        '''\\n\\n        self.lark = Lark(grammar, parser=None, lexer='basic')\\n        # All tokens: print([t.name for t in self.lark.parser.lexer.tokens])\\n\\n    def defaultPaper(self, style):\\n        return QColor(39, 40, 34)\\n\\n    def language(self):\\n        return \\\"Json\\\"\\n\\n    def description(self, style):\\n        return {v: k for k, v in self.token_styles.items()}.get(style, \\\"\\\")\\n\\n    def styleText(self, start, end):\\n        self.startStyling(start)\\n        text = self.parent().text()[start:end]\\n        last_pos = 0\\n\\n        try:\\n            for token in self.lark.lex(text):\\n                ws_len = token.start_pos - last_pos\\n                if ws_len:\\n                    self.setStyling(ws_len, 0)    # whitespace\\n\\n                token_len = len(bytearray(token, \\\"utf-8\\\"))\\n                self.setStyling(\\n                    token_len, self.token_styles.get(token.type, 0))\\n\\n                last_pos = token.start_pos + token_len\\n        except Exception as e:\\n            print(e)\\n\\n\\nclass EditorAll(QsciScintilla):\\n\\n    def __init__(self, parent=None):\\n        super().__init__(parent)\\n\\n        # Set font defaults\\n        font = QFont()\\n        font.setFamily('Consolas')\\n        font.setFixedPitch(True)\\n        font.setPointSize(8)\\n        font.setBold(True)\\n        self.setFont(font)\\n\\n        # Set margin defaults\\n        fontmetrics = QFontMetrics(font)\\n        self.setMarginsFont(font)\\n        self.setMarginWidth(0, fontmetrics.width(\\\"000\\\") + 6)\\n        self.setMarginLineNumbers(0, True)\\n        self.setMarginsForegroundColor(QColor(128, 128, 128))\\n        self.setMarginsBackgroundColor(QColor(39, 40, 34))\\n        self.setMarginType(1, self.SymbolMargin)\\n        self.setMarginWidth(1, 12)\\n\\n        # Set indentation defaults\\n        self.setIndentationsUseTabs(False)\\n        self.setIndentationWidth(4)\\n        self.setBackspaceUnindents(True)\\n        self.setIndentationGuides(True)\\n\\n        # self.setFolding(QsciScintilla.CircledFoldStyle)\\n\\n        # Set caret defaults\\n        self.setCaretForegroundColor(QColor(247, 247, 241))\\n        self.setCaretWidth(2)\\n\\n        # Set selection color defaults\\n        self.setSelectionBackgroundColor(QColor(61, 61, 52))\\n        self.resetSelectionForegroundColor()\\n\\n        # Set multiselection defaults\\n        self.SendScintilla(QsciScintilla.SCI_SETMULTIPLESELECTION, True)\\n        self.SendScintilla(QsciScintilla.SCI_SETMULTIPASTE, 1)\\n        self.SendScintilla(\\n            QsciScintilla.SCI_SETADDITIONALSELECTIONTYPING, True)\\n\\n        lexer = LexerJson(self)\\n        self.setLexer(lexer)\\n\\n\\nEXAMPLE_TEXT = textwrap.dedent(\\\"\\\"\\\"\\\\\\n        {\\n            \\\"_id\\\": \\\"5b05ffcbcf8e597939b3f5ca\\\",\\n            \\\"about\\\": \\\"Excepteur consequat commodo esse voluptate aute aliquip ad sint deserunt commodo eiusmod irure. Sint aliquip sit magna duis eu est culpa aliqua excepteur ut tempor nulla. Aliqua ex pariatur id labore sit. Quis sit ex aliqua veniam exercitation laboris anim adipisicing. Lorem nisi reprehenderit ullamco labore qui sit ut aliqua tempor consequat pariatur proident.\\\",\\n            \\\"address\\\": \\\"665 Malbone Street, Thornport, Louisiana, 243\\\",\\n            \\\"age\\\": 23,\\n            \\\"balance\\\": \\\"$3,216.91\\\",\\n            \\\"company\\\": \\\"BULLJUICE\\\",\\n            \\\"email\\\": \\\"elisekelley@bulljuice.com\\\",\\n            \\\"eyeColor\\\": \\\"brown\\\",\\n            \\\"gender\\\": \\\"female\\\",\\n            \\\"guid\\\": \\\"d3a6d865-0f64-4042-8a78-4f53de9b0707\\\",\\n            \\\"index\\\": 0,\\n            \\\"isActive\\\": false,\\n            \\\"isActive2\\\": true,\\n            \\\"latitude\\\": -18.660714,\\n            \\\"longitude\\\": -85.378048,\\n            \\\"name\\\": \\\"Elise Kelley\\\",\\n            \\\"phone\\\": \\\"+1 (808) 543-3966\\\",\\n            \\\"picture\\\": \\\"http://placehold.it/32x32\\\",\\n            \\\"registered\\\": \\\"2017-09-30T03:47:40 -02:00\\\",\\n            \\\"tags\\\": [\\n                \\\"et\\\",\\n                \\\"nostrud\\\",\\n                \\\"in\\\",\\n                \\\"fugiat\\\",\\n                \\\"incididunt\\\",\\n                \\\"labore\\\",\\n                \\\"nostrud\\\"\\n            ]\\n        }\\\\\\n    \\\"\\\"\\\")\\n\\ndef main():\\n    app = QApplication(sys.argv)\\n    ex = EditorAll()\\n    ex.setWindowTitle(__file__)\\n    ex.setText(EXAMPLE_TEXT)\\n    ex.resize(800, 600)\\n    ex.show()\\n    sys.exit(app.exec_())\\n\\n\\nif __name__ == \\\"__main__\\\":\\n    main()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9056f9d3440746d8fe151c31173e18e6/qscintilla_json.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9056f9d3440746d8fe151c31173e18e6/qscintilla_json.ipynb",
        "status_code": 200,
        "scrape_id": "24f85eeb-4447-4547-9271-c27b43a71bb3",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9e5ca2d2f34acae5a9391bd4b16a935f/conf_lalr.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# LALR\\u2019s contextual lexer\\n\\nThis example demonstrates the power of LALR's contextual lexer,\\nby parsing a toy configuration language.\\n\\nThe terminals `NAME` and `VALUE` overlap. They can match the same input.\\nA basic lexer would arbitrarily choose one over the other, based on priority,\\nwhich would lead to a (confusing) parse error.\\nHowever, due to the unambiguous structure of the grammar, Lark's LALR(1) algorithm knows\\nwhich one of them to expect at each point during the parse.\\nThe lexer then only matches the tokens that the parser expects.\\nThe result is a correct parse, something that is impossible with a regular lexer.\\n\\nAnother approach is to use the Earley algorithm.\\nIt will handle more cases than the contextual lexer, but at the cost of performance.\\nSee examples/conf_earley.py for an example of that approach.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\n\\nparser = Lark(r\\\"\\\"\\\"\\n        start: _NL? section+\\n        section: \\\"[\\\" NAME \\\"]\\\" _NL item+\\n        item: NAME \\\"=\\\" VALUE? _NL\\n\\n        NAME: /\\\\w/+\\n        VALUE: /./+\\n\\n        %import common.NEWLINE -> _NL\\n        %import common.WS_INLINE\\n        %ignore WS_INLINE\\n    \\\"\\\"\\\", parser=\\\"lalr\\\")\\n\\n\\nsample_conf = \\\"\\\"\\\"\\n[bla]\\na=Hello\\nthis=\\\"that\\\",4\\nempty=\\n\\\"\\\"\\\"\\n\\nprint(parser.parse(sample_conf).pretty())\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9e5ca2d2f34acae5a9391bd4b16a935f/conf_lalr.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/9e5ca2d2f34acae5a9391bd4b16a935f/conf_lalr.ipynb",
        "status_code": 200,
        "scrape_id": "322e7514-75c1-490c-81fe-88f36de89192",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/7cc2abf4fecd3796ed4ad6d455bda349/indented_tree.py",
      "markdown": "```\n\"\"\"\nParsing Indentation\n===================\n\nA demonstration of parsing indentation (“whitespace significant” language)\nand the usage of the Indenter class.\n\nSince indentation is context-sensitive, a postlex stage is introduced to\nmanufacture INDENT/DEDENT tokens.\n\nIt is crucial for the indenter that the NL_type matches\nthe spaces (and tabs) after the newline.\n\"\"\"\nfrom lark import Lark\nfrom lark.indenter import Indenter\n\ntree_grammar = r\"\"\"\n    ?start: _NL* tree\n\n    tree: NAME _NL [_INDENT tree+ _DEDENT]\n\n    %import common.CNAME -> NAME\n    %import common.WS_INLINE\n    %declare _INDENT _DEDENT\n    %ignore WS_INLINE\n\n    _NL: /(\\r?\\n[\\t ]*)+/\n\"\"\"\n\nclass TreeIndenter(Indenter):\n    NL_type = '_NL'\n    OPEN_PAREN_types = []\n    CLOSE_PAREN_types = []\n    INDENT_type = '_INDENT'\n    DEDENT_type = '_DEDENT'\n    tab_len = 8\n\nparser = Lark(tree_grammar, parser='lalr', postlex=TreeIndenter())\n\ntest_tree = \"\"\"\na\n    b\n    c\n        d\n        e\n    f\n        g\n\"\"\"\n\ndef test():\n    print(parser.parse(test_tree).pretty())\n\nif __name__ == '__main__':\n    test()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/7cc2abf4fecd3796ed4ad6d455bda349/indented_tree.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/7cc2abf4fecd3796ed4ad6d455bda349/indented_tree.py",
        "status_code": 200,
        "scrape_id": "bc981889-866b-4199-9e7c-79f81596a060",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Simple JSON Parser\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/_json_parser.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html \"Transform a Forest\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html \"Custom SPPF Prioritizer\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html#sphx-glr-download-examples-advanced-json-parser-py)\nto download the full example code\n\n# Simple JSON Parser [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html\\#simple-json-parser \"Permalink to this heading\")\n\nThe code is short and clear, and outperforms every other parser (that’s written in Python).\nFor an explanation, check out the JSON parser tutorial at /docs/json\\_tutorial.md\n\n(this is here for use by the other examples)\n\n```\nfrom lark import Lark, Transformer, v_args\n\njson_grammar = r\"\"\"\n    ?start: value\n\n    ?value: object\n          | array\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    array  : \"[\" [value (\",\" value)*] \"]\"\n    object : \"{\" [pair (\",\" pair)*] \"}\"\n    pair   : string \":\" value\n\n    string : ESCAPED_STRING\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n\n    %ignore WS\n\"\"\"\n\nclass TreeToJson(Transformer):\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n### Create the JSON parser with Lark, using the LALR algorithm\njson_parser = Lark(json_grammar, parser='lalr',\n                   # Using the basic lexer isn't required, and isn't usually recommended.\n                   # But, it's good enough for JSON, and it's slightly faster.\n                   lexer='basic',\n                   # Disabling propagate_positions and placeholders slightly improves speed\n                   propagate_positions=False,\n                   maybe_placeholders=False,\n                   # Using an internal transformer is faster and more memory efficient\n                   transformer=TreeToJson())\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: _json_parser.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/6d1927842b20958cbf08c916e786d2d0/_json_parser.py)\n\n[`Download Jupyter notebook: _json_parser.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/ee39a682704904d3f08f1d957831c955/_json_parser.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/_json_parser.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Simple JSON Parser — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html",
        "status_code": 200,
        "scrape_id": "60a45357-1f13-4ec8-8370-094cf80ce20b",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.738Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Simple JSON Parser\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/json_parser.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html \"Turtle DSL\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html \"Advanced Examples\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html#sphx-glr-download-examples-json-parser-py)\nto download the full example code\n\n# Simple JSON Parser [](https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html\\#simple-json-parser \"Permalink to this heading\")\n\nThe code is short and clear, and outperforms every other parser (that’s written in Python).\nFor an explanation, check out the JSON parser tutorial at /docs/json\\_tutorial.md\n\n```\nimport sys\n\nfrom lark import Lark, Transformer, v_args\n\njson_grammar = r\"\"\"\n    ?start: value\n\n    ?value: object\n          | array\n          | string\n          | SIGNED_NUMBER      -> number\n          | \"true\"             -> true\n          | \"false\"            -> false\n          | \"null\"             -> null\n\n    array  : \"[\" [value (\",\" value)*] \"]\"\n    object : \"{\" [pair (\",\" pair)*] \"}\"\n    pair   : string \":\" value\n\n    string : ESCAPED_STRING\n\n    %import common.ESCAPED_STRING\n    %import common.SIGNED_NUMBER\n    %import common.WS\n\n    %ignore WS\n\"\"\"\n\nclass TreeToJson(Transformer):\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n### Create the JSON parser with Lark, using the Earley algorithm\n# json_parser = Lark(json_grammar, parser='earley', lexer='basic')\n# def parse(x):\n#     return TreeToJson().transform(json_parser.parse(x))\n\n### Create the JSON parser with Lark, using the LALR algorithm\njson_parser = Lark(json_grammar, parser='lalr',\n                   # Using the basic lexer isn't required, and isn't usually recommended.\n                   # But, it's good enough for JSON, and it's slightly faster.\n                   lexer='basic',\n                   # Disabling propagate_positions and placeholders slightly improves speed\n                   propagate_positions=False,\n                   maybe_placeholders=False,\n                   # Using an internal transformer is faster and more memory efficient\n                   transformer=TreeToJson())\nparse = json_parser.parse\n\ndef test():\n    test_json = '''\n        {\n            \"empty_object\" : {},\n            \"empty_array\"  : [],\n            \"booleans\"     : { \"YES\" : true, \"NO\" : false },\n            \"numbers\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\n            \"strings\"      : [ \"This\", [ \"And\" , \"That\", \"And a \\\\\"b\" ] ],\n            \"nothing\"      : null\n        }\n    '''\n\n    j = parse(test_json)\n    print(j)\n    import json\n    assert j == json.loads(test_json)\n\nif __name__ == '__main__':\n    # test()\n    with open(sys.argv[1]) as f:\n        print(parse(f.read()))\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: json_parser.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/9897e3d2b4b242b1ded5769f50c0eea1/json_parser.py)\n\n[`Download Jupyter notebook: json_parser.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/179842700c93c6cca88ed33e1b99eb9c/json_parser.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/json_parser.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Simple JSON Parser — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html",
        "status_code": 200,
        "scrape_id": "32d94a73-3bd7-42ba-b4bd-414fa75aab62",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Transform a Forest\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/tree_forest_transformer.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html \"Custom lexer\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html \"Simple JSON Parser\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html#sphx-glr-download-examples-advanced-tree-forest-transformer-py)\nto download the full example code\n\n# Transform a Forest [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html\\#transform-a-forest \"Permalink to this heading\")\n\nThis example demonstrates how to subclass `TreeForestTransformer` to\ndirectly transform a SPPF.\n\n```\nfrom lark import Lark\nfrom lark.parsers.earley_forest import TreeForestTransformer, handles_ambiguity, Discard\n\nclass CustomTransformer(TreeForestTransformer):\n\n    @handles_ambiguity\n    def sentence(self, trees):\n        return next(tree for tree in trees if tree.data == 'simple')\n\n    def simple(self, children):\n        children.append('.')\n        return self.tree_class('simple', children)\n\n    def adj(self, children):\n        return Discard\n\n    def __default_token__(self, token):\n        return token.capitalize()\n\ngrammar = \"\"\"\n    sentence: noun verb noun        -> simple\n            | noun verb \"like\" noun -> comparative\n\n    noun: adj? NOUN\n    verb: VERB\n    adj: ADJ\n\n    NOUN: \"flies\" | \"bananas\" | \"fruit\"\n    VERB: \"like\" | \"flies\"\n    ADJ: \"fruit\"\n\n    %import common.WS\n    %ignore WS\n\"\"\"\n\nparser = Lark(grammar, start='sentence', ambiguity='forest')\nsentence = 'fruit flies like bananas'\nforest = parser.parse(sentence)\n\ntree = CustomTransformer(resolve_ambiguity=False).transform(forest)\nprint(tree.pretty())\n\n# Output:\n#\n# simple\n#   noun  Flies\n#   verb  Like\n#   noun  Bananas\n#   .\n#\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: tree_forest_transformer.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/9d7d9d95319f4514ab7247f8eb86ddf0/tree_forest_transformer.py)\n\n[`Download Jupyter notebook: tree_forest_transformer.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/2d7086e8ce7628b916237820c20847e4/tree_forest_transformer.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/tree_forest_transformer.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Transform a Forest — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html",
        "status_code": 200,
        "scrape_id": "74ec6333-3d10-4ce3-b4d8-d9c91aa6cd47",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/b0239cee17ba033b2ccfffe66491b86e/fruitflies.py",
      "markdown": "```\n\"\"\"\nHandling Ambiguity\n==================\n\nA demonstration of ambiguity\n\nThis example shows how to use get explicit ambiguity from Lark's Earley parser.\n\n\"\"\"\nimport sys\nfrom lark import Lark, tree\n\ngrammar = \"\"\"\n    sentence: noun verb noun        -> simple\n            | noun verb \"like\" noun -> comparative\n\n    noun: adj? NOUN\n    verb: VERB\n    adj: ADJ\n\n    NOUN: \"flies\" | \"bananas\" | \"fruit\"\n    VERB: \"like\" | \"flies\"\n    ADJ: \"fruit\"\n\n    %import common.WS\n    %ignore WS\n\"\"\"\n\nparser = Lark(grammar, start='sentence', ambiguity='explicit')\n\nsentence = 'fruit flies like bananas'\n\ndef make_png(filename):\n    tree.pydot__tree_to_png( parser.parse(sentence), filename)\n\ndef make_dot(filename):\n    tree.pydot__tree_to_dot( parser.parse(sentence), filename)\n\nif __name__ == '__main__':\n    print(parser.parse(sentence).pretty())\n    # make_png(sys.argv[1])\n    # make_dot(sys.argv[1])\n\n# Output:\n#\n# _ambig\n#   comparative\n#     noun\tfruit\n#     verb\tflies\n#     noun\tbananas\n#   simple\n#     noun\n#       fruit\n#       flies\n#     verb\tlike\n#     noun\tbananas\n#\n# (or view a nicer version at \"./fruitflies.png\")\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/b0239cee17ba033b2ccfffe66491b86e/fruitflies.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/b0239cee17ba033b2ccfffe66491b86e/fruitflies.py",
        "status_code": 200,
        "scrape_id": "b01d753c-93e4-4c1f-8631-2faf1bf909e6",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/index.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Examples for Lark\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/index.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/recipes.html \"Recipes\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html \"Parsing Indentation\")\n\n* * *\n\n# Examples for Lark [](https://lark-parser.readthedocs.io/en/stable/examples/index.html\\#examples-for-lark \"Permalink to this heading\")\n\n**How to run the examples**:\n\nAfter cloning the repo, open the terminal into the root directory of the\nproject, and run the following:\n\n```\n[lark]$ python -m examples.<name_of_example>\n\n```\n\nFor example, the following will parse all the Python files in the\nstandard library of your local installation:\n\n```\n[lark]$ python -m examples.advanced.python_parser\n\n```\n\n## Beginner Examples [](https://lark-parser.readthedocs.io/en/stable/examples/index.html\\#beginner-examples \"Permalink to this heading\")\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_indented_tree_thumb.png)\n\n[Parsing Indentation](https://lark-parser.readthedocs.io/en/stable/examples/indented_tree.html#sphx-glr-examples-indented-tree-py)\n\nParsing Indentation\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_lark_grammar_thumb.png)\n\n[Lark Grammar](https://lark-parser.readthedocs.io/en/stable/examples/lark_grammar.html#sphx-glr-examples-lark-grammar-py)\n\nLark Grammar\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_fruitflies_thumb.png)\n\n[Handling Ambiguity](https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html#sphx-glr-examples-fruitflies-py)\n\nHandling Ambiguity\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_calc_thumb.png)\n\n[Basic calculator](https://lark-parser.readthedocs.io/en/stable/examples/calc.html#sphx-glr-examples-calc-py)\n\nBasic calculator\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_turtle_dsl_thumb.png)\n\n[Turtle DSL](https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html#sphx-glr-examples-turtle-dsl-py)\n\nTurtle DSL\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_json_parser_thumb.png)\n\n[Simple JSON Parser](https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html#sphx-glr-examples-json-parser-py)\n\nSimple JSON Parser\n\n## Advanced Examples [](https://lark-parser.readthedocs.io/en/stable/examples/index.html\\#advanced-examples \"Permalink to this heading\")\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_conf_lalr_thumb.png)\n\n[LALR’s contextual lexer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html#sphx-glr-examples-advanced-conf-lalr-py)\n\nLALR’s contextual lexer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_templates_thumb.png)\n\n[Templates](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html#sphx-glr-examples-advanced-templates-py)\n\nTemplates\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_conf_earley_thumb.png)\n\n[Earley’s dynamic lexer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html#sphx-glr-examples-advanced-conf-earley-py)\n\nEarley’s dynamic lexer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_error_handling_thumb.png)\n\n[Error handling using an interactive parser](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html#sphx-glr-examples-advanced-error-handling-py)\n\nError handling using an interactive parser\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_reconstruct_json_thumb.png)\n\n[Reconstruct a JSON](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html#sphx-glr-examples-advanced-reconstruct-json-py)\n\nReconstruct a JSON\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_custom_lexer_thumb.png)\n\n[Custom lexer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html#sphx-glr-examples-advanced-custom-lexer-py)\n\nCustom lexer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_tree_forest_transformer_thumb.png)\n\n[Transform a Forest](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html#sphx-glr-examples-advanced-tree-forest-transformer-py)\n\nTransform a Forest\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr__json_parser_thumb.png)\n\n[Simple JSON Parser](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html#sphx-glr-examples-advanced-json-parser-py)\n\nSimple JSON Parser\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_prioritizer_thumb.png)\n\n[Custom SPPF Prioritizer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html#sphx-glr-examples-advanced-prioritizer-py)\n\nCustom SPPF Prioritizer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_py3to2_thumb.png)\n\n[Python 3 to Python 2 converter (tree templates)](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html#sphx-glr-examples-advanced-py3to2-py)\n\nPython 3 to Python 2 converter (tree templates)\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_python_parser_thumb.png)\n\n[Grammar-complete Python Parser](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html#sphx-glr-examples-advanced-python-parser-py)\n\nGrammar-complete Python Parser\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_create_ast_thumb.png)\n\n[Creating an AST from the parse tree](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html#sphx-glr-examples-advanced-create-ast-py)\n\nCreating an AST from the parse tree\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_error_reporting_earley_thumb.png)\n\n[Example-Driven Error Reporting](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html#sphx-glr-examples-advanced-error-reporting-earley-py)\n\nExample-Driven Error Reporting\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_error_reporting_lalr_thumb.png)\n\n[Example-Driven Error Reporting](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html#sphx-glr-examples-advanced-error-reporting-lalr-py)\n\nExample-Driven Error Reporting\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_reconstruct_python_thumb.png)\n\n[Reconstruct Python](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html#sphx-glr-examples-advanced-reconstruct-python-py)\n\nReconstruct Python\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_dynamic_complete_thumb.png)\n\n[Using lexer dynamic\\_complete](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html#sphx-glr-examples-advanced-dynamic-complete-py)\n\nUsing lexer dynamic\\_complete\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_qscintilla_json_thumb.png)\n\n[Syntax Highlighting](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html#sphx-glr-examples-advanced-qscintilla-json-py)\n\nSyntax Highlighting\n\n# Grammar Composition [](https://lark-parser.readthedocs.io/en/stable/examples/index.html\\#grammar-composition \"Permalink to this heading\")\n\nThis example shows how to do grammar composition in Lark, by creating a new\nfile format that allows both CSV and JSON to co-exist.\n\nWe show how, by using namespaces, Lark grammars and their transformers can be fully reused -\nthey don’t need to care if their grammar is used directly, or being imported, or who is doing the importing.\n\nSee [main.py](https://github.com/lark-parser/lark/blob/master/examples/composition/main.py) for more details.\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_eval_json_thumb.png)\n\nsphx\\_glr\\_examples\\_composition\\_eval\\_json.py\n\nTransformer for evaluating json.lark\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_eval_csv_thumb.png)\n\nsphx\\_glr\\_examples\\_composition\\_eval\\_csv.py\n\nTransformer for evaluating csv.lark\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_main_thumb.png)\n\n[Grammar Composition](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html#sphx-glr-examples-composition-main-py)\n\nGrammar Composition\n\n# Example Grammars [](https://lark-parser.readthedocs.io/en/stable/examples/index.html\\#example-grammars \"Permalink to this heading\")\n\nThis directory is a collection of lark grammars, taken from real world projects.\n\n- [Verilog](https://github.com/lark-parser/lark/blob/master/examples/grammars/verilog.lark) \\- Taken from [https://github.com/circuitgraph/circuitgraph/blob/main/circuitgraph/parsing/verilog.lark](https://github.com/circuitgraph/circuitgraph/blob/main/circuitgraph/parsing/verilog.lark)\n\n\n# Standalone example [](https://lark-parser.readthedocs.io/en/stable/examples/index.html\\#standalone-example \"Permalink to this heading\")\n\nTo initialize, cd to this folder, and run:\n\n```\n./create_standalone.sh\n\n```\n\nOr:\n\n```\npython -m lark.tools.standalone json.lark > json_parser.py\n\n```\n\nThen run using:\n\n```\npython json_parser_main.py <path-to.json>\n\n```\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_json_parser_main_thumb.png)\n\n[Standalone Parser](https://lark-parser.readthedocs.io/en/stable/examples/standalone/json_parser_main.html#sphx-glr-examples-standalone-json-parser-main-py)\n\nStandalone Parser\n\n[`Download all examples in Python source code: examples_python.zip`](https://lark-parser.readthedocs.io/en/stable/_downloads/bc82bea3a5dd7bdba60b65220891d9e5/examples_python.zip)\n\n[`Download all examples in Jupyter notebooks: examples_jupyter.zip`](https://lark-parser.readthedocs.io/en/stable/_downloads/fb625db3c50d423b1b7881136ffdeec8/examples_jupyter.zip)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Examples for Lark — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/index.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/index.html",
        "status_code": 200,
        "scrape_id": "cdd8d848-604d-4fc4-9b94-1aca78939f89",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Example-Driven Error Reporting\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/error_reporting_earley.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html \"Creating an AST from the parse tree\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html \"Example-Driven Error Reporting\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html#sphx-glr-download-examples-advanced-error-reporting-earley-py)\nto download the full example code\n\n# Example-Driven Error Reporting [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html\\#example-driven-error-reporting \"Permalink to this heading\")\n\nA demonstration of example-driven error reporting with the Earley parser\n(See also: error\\_reporting\\_lalr.py)\n\n```\nfrom lark import Lark, UnexpectedInput\n\nfrom _json_parser import json_grammar   # Using the grammar from the json_parser example\n\njson_parser = Lark(json_grammar)\n\nclass JsonSyntaxError(SyntaxError):\n    def __str__(self):\n        context, line, column = self.args\n        return '%s at line %s, column %s.\\n\\n%s' % (self.label, line, column, context)\n\nclass JsonMissingValue(JsonSyntaxError):\n    label = 'Missing Value'\n\nclass JsonMissingOpening(JsonSyntaxError):\n    label = 'Missing Opening'\n\nclass JsonMissingClosing(JsonSyntaxError):\n    label = 'Missing Closing'\n\nclass JsonMissingComma(JsonSyntaxError):\n    label = 'Missing Comma'\n\nclass JsonTrailingComma(JsonSyntaxError):\n    label = 'Trailing Comma'\n\ndef parse(json_text):\n    try:\n        j = json_parser.parse(json_text)\n    except UnexpectedInput as u:\n        exc_class = u.match_examples(json_parser.parse, {\n            JsonMissingOpening: ['{\"foo\": ]}',\n                                 '{\"foor\": }}',\n                                 '{\"foo\": }'],\n            JsonMissingClosing: ['{\"foo\": [}',\\\n                                 '{',\\\n                                 '{\"a\": 1',\\\n                                 '[1'],\\\n            JsonMissingComma: ['[1 2]',\\\n                               '[false 1]',\\\n                               '[\"b\" 1]',\\\n                               '{\"a\":true 1:4}',\\\n                               '{\"a\":1 1:4}',\\\n                               '{\"a\":\"b\" 1:4}'],\\\n            JsonTrailingComma: ['[,]',\\\n                                '[1,]',\\\n                                '[1,2,]',\\\n                                '{\"foo\":1,}',\\\n                                '{\"foo\":false,\"bar\":true,}']\\\n        }, use_accepts=True)\\\n        if not exc_class:\\\n            raise\\\n        raise exc_class(u.get_context(json_text), u.line, u.column)\\\n\\\ndef test():\\\n    try:\\\n        parse('{\"example1\": \"value\"')\\\n    except JsonMissingClosing as e:\\\n        print(e)\\\n\\\n    try:\\\n        parse('{\"example2\": ] ')\\\n    except JsonMissingOpening as e:\\\n        print(e)\\\n\\\nif __name__ == '__main__':\\\n    test()\\\n\\\n```\\\n\\\n**Total running time of the script:** (0 minutes 0.000 seconds)\\\n\\\n[`Download Python source code: error_reporting_earley.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/ca074bdcc9170e436dcd2f779e4a4285/error_reporting_earley.py)\\\n\\\n[`Download Jupyter notebook: error_reporting_earley.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/bdb62f1189ee436f5378982a91ecc1cf/error_reporting_earley.ipynb)\\\n\\\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\\\n\\\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/error_reporting_earley.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\\\n\\\n* * *\\\n\\\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\\\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Example-Driven Error Reporting — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html",
        "status_code": 200,
        "scrape_id": "0148d170-b36c-4c6b-9e1a-376a2a62811b",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/classes.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- API Reference\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/classes.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/tree_construction.html \"Tree Construction Reference\") [Next](https://lark-parser.readthedocs.io/en/stable/visitors.html \"Transformers & Visitors\")\n\n* * *\n\n# API Reference [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#api-reference \"Permalink to this heading\")\n\n## Lark [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#lark \"Permalink to this heading\")\n\n_class_ lark.Lark( _grammar:Union\\[Grammar,str,IO\\[str\\]\\]_, _\\*\\*options_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark \"Permalink to this definition\")\n\nMain interface for the library.\n\nIt’s mostly a thin wrapper for the many different parsers, and for the tree constructor.\n\nParameters:\n\n- **grammar** – a string or file-object containing the grammar spec (using Lark’s ebnf syntax)\n\n- **options** – a dictionary controlling various aspects of Lark.\n\n\nExample\n\n```\n>>> Lark(r'''start: \"foo\" ''')\nLark(...)\n\n```\n\n**=== General Options ===**\n\nstart\n\nThe start symbol. Either a string, or a list of strings for multiple possible starts (Default: “start”)\n\ndebug\n\nDisplay debug information and extra warnings. Use only when debugging (Default: `False`)\nWhen used with Earley, it generates a forest graph as “sppf.png”, if ‘dot’ is installed.\n\nstrict\n\nThrow an exception on any potential ambiguity, including shift/reduce conflicts, and regex collisions.\n\ntransformer\n\nApplies the transformer to every parse tree (equivalent to applying it after the parse, but faster)\n\npropagate\\_positions\n\nPropagates positional attributes into the ‘meta’ attribute of all tree branches.\nSets attributes: (line, column, end\\_line, end\\_column, start\\_pos, end\\_pos,\n\n> container\\_line, container\\_column, container\\_end\\_line, container\\_end\\_column)\n\nAccepts `False`, `True`, or a callable, which will filter which nodes to ignore when propagating.\n\nmaybe\\_placeholders\n\nWhen `True`, the `[]` operator returns `None` when not matched.\nWhen `False`, `[]` behaves like the `?` operator, and returns no value at all.\n(default= `True`)\n\ncache\n\nCache the results of the Lark grammar analysis, for x2 to x3 faster loading. LALR only for now.\n\n- When `False`, does nothing (default)\n\n- When `True`, caches to a temporary file in the local directory\n\n- When given a string, caches to the path pointed by the string\n\n\nregex\n\nWhen True, uses the `regex` module instead of the stdlib `re`.\n\ng\\_regex\\_flags\n\nFlags that are applied to all terminals (both regex and strings)\n\nkeep\\_all\\_tokens\n\nPrevent the tree builder from automagically removing “punctuation” tokens (Default: `False`)\n\ntree\\_class\n\nLark will produce trees comprised of instances of this class instead of the default `lark.Tree`.\n\n**=== Algorithm Options ===**\n\nparser\n\nDecides which parser engine to use. Accepts “earley” or “lalr”. (Default: “earley”).\n(there is also a “cyk” option for legacy)\n\nlexer\n\nDecides whether or not to use a lexer stage\n\n- “auto” (default): Choose for me based on the parser\n\n- “basic”: Use a basic lexer\n\n- “contextual”: Stronger lexer (only works with parser=”lalr”)\n\n- “dynamic”: Flexible and powerful (only with parser=”earley”)\n\n- “dynamic\\_complete”: Same as dynamic, but tries _every_ variation of tokenizing possible.\n\n\nambiguity\n\nDecides how to handle ambiguity in the parse. Only relevant if parser=”earley”\n\n- “resolve”: The parser will automatically choose the simplest derivation\n(it chooses consistently: greedy for tokens, non-greedy for rules)\n\n- “explicit”: The parser will return all derivations wrapped in “\\_ambig” tree nodes (i.e. a forest).\n\n- “forest”: The parser will return the root of the shared packed parse forest.\n\n\n**=== Misc. / Domain Specific Options ===**\n\npostlex\n\nLexer post-processing (Default: `None`) Only works with the basic and contextual lexers.\n\npriority\n\nHow priorities should be evaluated - “auto”, `None`, “normal”, “invert” (Default: “auto”)\n\nlexer\\_callbacks\n\nDictionary of callbacks for the lexer. May alter tokens during lexing. Use with caution.\n\nuse\\_bytes\n\nAccept an input of type `bytes` instead of `str`.\n\nordered\\_sets\n\nShould Earley use ordered-sets to achieve stable output (~10% slower than regular sets. Default: True)\n\nedit\\_terminals\n\nA callback for editing the terminals before parse.\n\nimport\\_paths\n\nA List of either paths or loader functions to specify from where grammars are imported\n\nsource\\_path\n\nOverride the source of from where the grammar was loaded. Useful for relative imports and unconventional grammar loading\n\n**=== End of Options ===**\n\nsave( _f_, _exclude\\_options:Collection\\[str\\]=()_)→None [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.save \"Permalink to this definition\")\n\nSaves the instance into the given file object\n\nUseful for caching and multiprocessing.\n\n_classmethod_ load( _f_)→\\_T [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.load \"Permalink to this definition\")\n\nLoads an instance from the given file object\n\nUseful for caching and multiprocessing.\n\n_classmethod_ open( _grammar\\_filename:str_, _rel\\_to:Optional\\[str\\]=None_, _\\*\\*options_)→\\_T [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.open \"Permalink to this definition\")\n\nCreate an instance of Lark with the grammar given by its filename\n\nIf `rel_to` is provided, the function will find the grammar filename in relation to it.\n\nExample\n\n```\n>>> Lark.open(\"grammar_file.lark\", rel_to=__file__, parser=\"lalr\")\nLark(...)\n\n```\n\n_classmethod_ open\\_from\\_package( _package:str_, _grammar\\_path:str_, _search\\_paths:Sequence\\[str\\]=\\[''\\]_, _\\*\\*options_)→\\_T [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.open_from_package \"Permalink to this definition\")\n\nCreate an instance of Lark with the grammar loaded from within the package package.\nThis allows grammar loading from zipapps.\n\nImports in the grammar will use the package and search\\_paths provided, through FromPackageLoader\n\nExample\n\nLark.open\\_from\\_package(\\_\\_name\\_\\_, “example.lark”, (“grammars”,), parser=…)\n\nlex( _text:str_, _dont\\_ignore:bool=False_)→Iterator\\[ [Token](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token \"lark.lexer.Token\")\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.lex \"Permalink to this definition\")\n\nOnly lex (and postlex) the text, without parsing it. Only relevant when lexer=’basic’\n\nWhen dont\\_ignore=True, the lexer will return all tokens, even those marked for %ignore.\n\nRaises:\n\n[**UnexpectedCharacters**](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedCharacters \"lark.exceptions.UnexpectedCharacters\") – In case the lexer cannot find a suitable match.\n\nget\\_terminal( _name:str_)→TerminalDef [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.get_terminal \"Permalink to this definition\")\n\nGet information about a terminal\n\nparse\\_interactive( _text:Optional\\[str\\]=None_, _start:Optional\\[str\\]=None_)→[InteractiveParser](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser \"lark.parsers.lalr_interactive_parser.InteractiveParser\") [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.parse_interactive \"Permalink to this definition\")\n\nStart an interactive parsing session.\n\nParameters:\n\n- **text** ( _str_ _,_ _optional_) – Text to be parsed. Required for `resume_parse()`.\n\n- **start** ( _str_ _,_ _optional_) – Start symbol\n\n\nReturns:\n\nA new InteractiveParser instance.\n\nSee Also: `Lark.parse()`\n\nparse( _text:str_, _start:Optional\\[str\\]=None_, _on\\_error:Optional\\[Callable\\[\\[ [UnexpectedInput](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedInput \"lark.exceptions.UnexpectedInput\")\\],bool\\]\\]=None_)→ParseTree [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Lark.parse \"Permalink to this definition\")\n\nParse the given text, according to the options provided.\n\nParameters:\n\n- **text** ( _str_) – Text to be parsed.\n\n- **start** ( _str_ _,_ _optional_) – Required if Lark was given multiple possible start symbols (using the start option).\n\n- **on\\_error** ( _function_ _,_ _optional_) – if provided, will be called on UnexpectedToken error. Return true to resume parsing.\nLALR only. See examples/advanced/error\\_handling.py for an example of how to use on\\_error.\n\n\nReturns:\n\nIf a transformer is supplied to `__init__`, returns whatever is the\nresult of the transformation. Otherwise, returns a Tree instance.\n\nRaises:\n\n[**UnexpectedInput**](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedInput \"lark.exceptions.UnexpectedInput\") – On a parse error, one of these sub-exceptions will rise:\n`UnexpectedCharacters`, `UnexpectedToken`, or `UnexpectedEOF`.\nFor convenience, these sub-exceptions also inherit from `ParserError` and `LexerError`.\n\n### Using Unicode character classes with `regex` [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#using-unicode-character-classes-with-regex \"Permalink to this heading\")\n\nPython’s builtin `re` module has a few persistent known bugs and also won’t parse\nadvanced regex features such as character classes.\nWith `pip install lark[regex]`, the `regex` module will be\ninstalled alongside lark and can act as a drop-in replacement to `re`.\n\nAny instance of Lark instantiated with `regex=True` will use the `regex` module instead of `re`.\n\nFor example, we can use character classes to match PEP-3131 compliant Python identifiers:\n\n```\nfrom lark import Lark\n>>> g = Lark(r\"\"\"\n                    ?start: NAME\n                    NAME: ID_START ID_CONTINUE*\n                    ID_START: /[\\p{Lu}\\p{Ll}\\p{Lt}\\p{Lm}\\p{Lo}\\p{Nl}_]+/\n                    ID_CONTINUE: ID_START | /[\\p{Mn}\\p{Mc}\\p{Nd}\\p{Pc}·]+/\n                \"\"\", regex=True)\n\n>>> g.parse('வணக்கம்')\n'வணக்கம்'\n\n```\n\n## Tree [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#tree \"Permalink to this heading\")\n\n_class_ lark.Tree( _data:str_, _children:List\\[Union\\[\\_Leaf\\_T, [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.Tree\")\\[\\_Leaf\\_T\\]\\]\\]_, _meta:Optional\\[Meta\\]=None_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"Permalink to this definition\")\n\nThe main tree class.\n\nCreates a new tree, and stores “data” and “children” in attributes of the same name.\nTrees can be hashed and compared.\n\nParameters:\n\n- **data** – The name of the rule or alias\n\n- **children** – List of matched sub-rules and terminals\n\n- **meta** –\n\nLine & Column numbers (if `propagate_positions` is enabled).\nmeta attributes: (line, column, end\\_line, end\\_column, start\\_pos, end\\_pos,\n\n\n> container\\_line, container\\_column, container\\_end\\_line, container\\_end\\_column)\n\n\ncontainer\\_\\* attributes consider all symbols, including those that have been inlined in the tree.\nFor example, in the rule ‘a: \\_A B \\_C’, the regular attributes will mark the start and end of B,\nbut the container\\_\\* attributes will also include \\_A and \\_C in the range. However, rules that\ncontain ‘a’ will consider it in full, including \\_A and \\_C for all attributes.\n\n\npretty( _indent\\_str:str=''_)→str [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.pretty \"Permalink to this definition\")\n\nReturns an indented string representation of the tree.\n\nGreat for debugging.\n\n\\_\\_rich\\_\\_( _parent:Optional\\[rich.tree.Tree\\]=None_)→rich.tree.Tree [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.__rich__ \"Permalink to this definition\")\n\nReturns a tree widget for the ‘rich’ library.\n\nExample\n\n::\n\nfrom rich import print\nfrom lark import Tree\n\ntree = Tree(‘root’, \\[‘node1’, ‘node2’\\])\nprint(tree)\n\niter\\_subtrees()→Iterator\\[ [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.iter_subtrees \"Permalink to this definition\")\n\nDepth-first iteration.\n\nIterates over all the subtrees, never returning to the same node twice (Lark’s parse-tree is actually a DAG).\n\niter\\_subtrees\\_topdown() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.iter_subtrees_topdown \"Permalink to this definition\")\n\nBreadth-first iteration.\n\nIterates over all the subtrees, return nodes in order like pretty() does.\n\nfind\\_pred( _pred:Callable\\[\\[ [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]\\],bool\\]_)→Iterator\\[ [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.find_pred \"Permalink to this definition\")\n\nReturns all nodes of the tree that evaluate pred(node) as true.\n\nfind\\_data( _data:str_)→Iterator\\[ [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.tree.Tree\")\\[\\_Leaf\\_T\\]\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.find_data \"Permalink to this definition\")\n\nReturns all nodes of the tree whose data equals the given data.\n\nscan\\_values( _pred:Callable\\[\\[Union\\[\\_Leaf\\_T, [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.Tree\")\\[\\_Leaf\\_T\\]\\]\\],bool\\]_)→Iterator\\[\\_Leaf\\_T\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree.scan_values \"Permalink to this definition\")\n\nReturn all values in the tree that evaluate pred(value) as true.\n\nThis can be used to find all the tokens in the tree.\n\nExample\n\n```\n>>> all_tokens = tree.scan_values(lambda v: isinstance(v, Token))\n\n```\n\n## Token [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#token \"Permalink to this heading\")\n\n_class_ lark.Token( _type:str_, _value:Any_, _start\\_pos:Optional\\[int\\]=None_, _line:Optional\\[int\\]=None_, _column:Optional\\[int\\]=None_, _end\\_line:Optional\\[int\\]=None_, _end\\_column:Optional\\[int\\]=None_, _end\\_pos:Optional\\[int\\]=None_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token \"Permalink to this definition\")_class_ lark.Token( _type\\_:str_, _value:Any_, _start\\_pos:Optional\\[int\\]=None_, _line:Optional\\[int\\]=None_, _column:Optional\\[int\\]=None_, _end\\_line:Optional\\[int\\]=None_, _end\\_column:Optional\\[int\\]=None_, _end\\_pos:Optional\\[int\\]=None_)\n\nA string with meta-information, that is produced by the lexer.\n\nWhen parsing text, the resulting chunks of the input that haven’t been discarded,\nwill end up in the tree as Token instances. The Token class inherits from Python’s `str`,\nso normal string comparisons and operations will work as expected.\n\ntype [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.type \"Permalink to this definition\")\n\nName of the token (as specified in grammar)\n\nType:\n\nstr\n\nvalue [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.value \"Permalink to this definition\")\n\nValue of the token (redundant, as `token.value == token` will always be true)\n\nType:\n\nAny\n\nstart\\_pos [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.start_pos \"Permalink to this definition\")\n\nThe index of the token in the text\n\nType:\n\nOptional\\[int\\]\n\nline [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.line \"Permalink to this definition\")\n\nThe line of the token in the text (starting with 1)\n\nType:\n\nOptional\\[int\\]\n\ncolumn [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.column \"Permalink to this definition\")\n\nThe column of the token in the text (starting with 1)\n\nType:\n\nOptional\\[int\\]\n\nend\\_line [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.end_line \"Permalink to this definition\")\n\nThe line where the token ends\n\nType:\n\nOptional\\[int\\]\n\nend\\_column [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.end_column \"Permalink to this definition\")\n\nThe next column after the end of the token. For example,\nif the token is a single character with a column value of 4,\nend\\_column will be 5.\n\nType:\n\nOptional\\[int\\]\n\nend\\_pos [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token.end_pos \"Permalink to this definition\")\n\nthe index where the token ends (basically `start_pos + len(token)`)\n\nType:\n\nOptional\\[int\\]\n\n## Transformer, Visitor & Interpreter [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#transformer-visitor-interpreter \"Permalink to this heading\")\n\nSee [Transformers & Visitors](https://lark-parser.readthedocs.io/en/stable/visitors.html).\n\n## ForestVisitor, ForestTransformer, & TreeForestTransformer [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#forestvisitor-foresttransformer-treeforesttransformer \"Permalink to this heading\")\n\nSee [Working with the SPPF](https://lark-parser.readthedocs.io/en/stable/forest.html).\n\n## UnexpectedInput [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#unexpectedinput \"Permalink to this heading\")\n\n_class_ lark.exceptions.UnexpectedInput [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedInput \"Permalink to this definition\")\n\nUnexpectedInput Error.\n\nUsed as a base class for the following exceptions:\n\n- `UnexpectedCharacters`: The lexer encountered an unexpected string\n\n- `UnexpectedToken`: The parser received an unexpected token\n\n- `UnexpectedEOF`: The parser expected a token, but the input ended\n\n\nAfter catching one of these exceptions, you may call the following helper methods to create a nicer error message.\n\nget\\_context( _text:str_, _span:int=40_)→str [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedInput.get_context \"Permalink to this definition\")\n\nReturns a pretty string pinpointing the error in the text,\nwith span amount of context characters around it.\n\nNote\n\nThe parser doesn’t hold a copy of the text it has to parse,\nso you have to provide it again\n\nmatch\\_examples( _parse\\_fn:Callable\\[\\[str\\], [Tree](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Tree \"lark.Tree\")\\]_, _examples:Union\\[Mapping\\[T,Iterable\\[str\\]\\],Iterable\\[Tuple\\[T,Iterable\\[str\\]\\]\\]\\]_, _token\\_type\\_match\\_fallback:bool=False_, _use\\_accepts:bool=True_)→Optional\\[T\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedInput.match_examples \"Permalink to this definition\")\n\nAllows you to detect what’s wrong in the input text by matching\nagainst example errors.\n\nGiven a parser instance and a dictionary mapping some label with\nsome malformed syntax examples, it’ll return the label for the\nexample that bests matches the current error. The function will\niterate the dictionary until it finds a matching error, and\nreturn the corresponding value.\n\nFor an example usage, see examples/error\\_reporting\\_lalr.py\n\nParameters:\n\n- **parse\\_fn** – parse function (usually `lark_instance.parse`)\n\n- **examples** – dictionary of `{'example_string': value}`.\n\n- **use\\_accepts** – Recommended to keep this as `use_accepts=True`.\n\n\n_class_ lark.exceptions.UnexpectedToken( _token_, _expected_, _considered\\_rules=None_, _state=None_, _interactive\\_parser=None_, _terminals\\_by\\_name=None_, _token\\_history=None_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedToken \"Permalink to this definition\")\n\nAn exception that is raised by the parser, when the token it received\ndoesn’t match any valid step forward.\n\nParameters:\n\n- **token** – The mismatched token\n\n- **expected** – The set of expected tokens\n\n- **considered\\_rules** – Which rules were considered, to deduce the expected tokens\n\n- **state** – A value representing the parser state. Do not rely on its value or type.\n\n- **interactive\\_parser** – An instance of `InteractiveParser`, that is initialized to the point of failure,\nand can be used for debugging and error handling.\n\n\nNote: These parameters are available as attributes of the instance.\n\n_class_ lark.exceptions.UnexpectedCharacters( _seq_, _lex\\_pos_, _line_, _column_, _allowed=None_, _considered\\_tokens=None_, _state=None_, _token\\_history=None_, _terminals\\_by\\_name=None_, _considered\\_rules=None_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedCharacters \"Permalink to this definition\")\n\nAn exception that is raised by the lexer, when it cannot match the next\nstring of characters to any of its terminals.\n\n_class_ lark.exceptions.UnexpectedEOF( _expected_, _state=None_, _terminals\\_by\\_name=None_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.exceptions.UnexpectedEOF \"Permalink to this definition\")\n\nAn exception that is raised by the parser, when the input ends while it still expects a token.\n\n## InteractiveParser [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#interactiveparser \"Permalink to this heading\")\n\n_class_ lark.parsers.lalr\\_interactive\\_parser.InteractiveParser( _parser_, _parser\\_state:ParserState_, _lexer\\_thread:LexerThread_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser \"Permalink to this definition\")\n\nInteractiveParser gives you advanced control over parsing and error handling when parsing with LALR.\n\nFor a simpler interface, see the `on_error` argument to `Lark.parse()`.\n\nfeed\\_token( _token:[Token](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token \"lark.lexer.Token\")_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.feed_token \"Permalink to this definition\")\n\nFeed the parser with a token, and advance it to the next state, as if it received it from the lexer.\n\nNote that `token` has to be an instance of `Token`.\n\nexhaust\\_lexer()→List\\[ [Token](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.Token \"lark.lexer.Token\")\\] [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.exhaust_lexer \"Permalink to this definition\")\n\nTry to feed the rest of the lexer state into the interactive parser.\n\nNote that this modifies the instance in place and does not feed an ‘$END’ Token\n\nas\\_immutable() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.as_immutable \"Permalink to this definition\")\n\nConvert to an `ImmutableInteractiveParser`.\n\npretty() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.pretty \"Permalink to this definition\")\n\nPrint the output of `choices()` in a way that’s easier to read.\n\nchoices() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.choices \"Permalink to this definition\")\n\nReturns a dictionary of token types, matched to their action in the parser.\n\nOnly returns token types that are accepted by the current state.\n\nUpdated by `feed_token()`.\n\naccepts() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.accepts \"Permalink to this definition\")\n\nReturns the set of possible tokens that will advance the parser into a new valid state.\n\nresume\\_parse() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.InteractiveParser.resume_parse \"Permalink to this definition\")\n\nResume automated parsing from the current state.\n\n_class_ lark.parsers.lalr\\_interactive\\_parser.ImmutableInteractiveParser( _parser_, _parser\\_state:ParserState_, _lexer\\_thread:LexerThread_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser \"Permalink to this definition\")\n\nSame as `InteractiveParser`, but operations create a new instance instead\nof changing it in-place.\n\nfeed\\_token( _token_) [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.feed_token \"Permalink to this definition\")\n\nFeed the parser with a token, and advance it to the next state, as if it received it from the lexer.\n\nNote that `token` has to be an instance of `Token`.\n\nexhaust\\_lexer() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.exhaust_lexer \"Permalink to this definition\")\n\nTry to feed the rest of the lexer state into the parser.\n\nNote that this returns a new ImmutableInteractiveParser and does not feed an ‘$END’ Token\n\nas\\_mutable() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.as_mutable \"Permalink to this definition\")\n\nConvert to an `InteractiveParser`.\n\nchoices() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.choices \"Permalink to this definition\")\n\nReturns a dictionary of token types, matched to their action in the parser.\n\nOnly returns token types that are accepted by the current state.\n\nUpdated by `feed_token()`.\n\npretty() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.pretty \"Permalink to this definition\")\n\nPrint the output of `choices()` in a way that’s easier to read.\n\nresume\\_parse() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.resume_parse \"Permalink to this definition\")\n\nResume automated parsing from the current state.\n\naccepts() [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.parsers.lalr_interactive_parser.ImmutableInteractiveParser.accepts \"Permalink to this definition\")\n\nReturns the set of possible tokens that will advance the parser into a new valid state.\n\n## ast\\_utils [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#ast-utils \"Permalink to this heading\")\n\nFor an example of using `ast_utils`, see [/examples/advanced/create\\_ast.py](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html)\n\n_class_ lark.ast\\_utils.Ast [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.ast_utils.Ast \"Permalink to this definition\")\n\nAbstract class\n\nSubclasses will be collected by create\\_transformer()\n\n_class_ lark.ast\\_utils.AsList [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.ast_utils.AsList \"Permalink to this definition\")\n\nAbstract class\n\nSubclasses will be instantiated with the parse results as a single list, instead of as arguments.\n\nlark.ast\\_utils.create\\_transformer( _ast\\_module:module_, _transformer:~typing.Optional\\[~lark.visitors.Transformer\\]=None_, _decorator\\_factory:~typing.Callable=<functionv\\_args>_)→[Transformer](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer \"lark.visitors.Transformer\") [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.ast_utils.create_transformer \"Permalink to this definition\")\n\nCollects Ast subclasses from the given module, and creates a Lark transformer that builds the AST.\n\nFor each class, we create a corresponding rule in the transformer, with a matching name.\nCamelCase names will be converted into snake\\_case. Example: “CodeBlock” -> “code\\_block”.\n\nClasses starting with an underscore (\\_) will be skipped.\n\nParameters:\n\n- **ast\\_module** – A Python module containing all the subclasses of `ast_utils.Ast`\n\n- **transformer** ( _Optional_ _\\[_ [_Transformer_](https://lark-parser.readthedocs.io/en/stable/visitors.html#lark.visitors.Transformer \"lark.visitors.Transformer\") _\\]_) – An initial transformer. Its attributes may be overwritten.\n\n- **decorator\\_factory** ( _Callable_) – An optional callable accepting two booleans, inline, and meta,\nand returning a decorator for the methods of `transformer`. (default: `v_args`).\n\n\n## Indenter [](https://lark-parser.readthedocs.io/en/stable/classes.html\\#indenter \"Permalink to this heading\")\n\n_class_ lark.indenter.Indenter [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.indenter.Indenter \"Permalink to this definition\")\n\nThis is a postlexer that “injects” indent/dedent tokens based on indentation.\n\nIt keeps track of the current indentation, as well as the current level of parentheses.\nInside parentheses, the indentation is ignored, and no indent/dedent tokens get generated.\n\nNote: This is an abstract class. To use it, inherit and implement all its abstract methods:\n\n- tab\\_len\n\n- NL\\_type\n\n- OPEN\\_PAREN\\_types, CLOSE\\_PAREN\\_types\n\n- INDENT\\_type, DEDENT\\_type\n\n\nSee also: the `postlex` option in Lark.\n\n_class_ lark.indenter.PythonIndenter [](https://lark-parser.readthedocs.io/en/stable/classes.html#lark.indenter.PythonIndenter \"Permalink to this definition\")\n\nA postlexer that “injects” \\_INDENT/\\_DEDENT tokens based on indentation, according to the Python syntax.\n\nSee also: the `postlex` option in Lark.\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/classes.html)**[stable](https://lark-parser.readthedocs.io/en/stable/classes.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "API Reference — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/classes.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/classes.html",
        "status_code": 200,
        "scrape_id": "2f821c10-905f-457a-8464-462d68a6561e",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/63680f346bf793a45964b4e687bde3d9/calc.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Basic calculator\\n\\nA simple example of a REPL calculator\\n\\nThis example shows how to write a basic calculator with variables.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark, Transformer, v_args\\n\\n\\ntry:\\n    input = raw_input   # For Python2 compatibility\\nexcept NameError:\\n    pass\\n\\n\\ncalc_grammar = \\\"\\\"\\\"\\n    ?start: sum\\n          | NAME \\\"=\\\" sum    -> assign_var\\n\\n    ?sum: product\\n        | sum \\\"+\\\" product   -> add\\n        | sum \\\"-\\\" product   -> sub\\n\\n    ?product: atom\\n        | product \\\"*\\\" atom  -> mul\\n        | product \\\"/\\\" atom  -> div\\n\\n    ?atom: NUMBER           -> number\\n         | \\\"-\\\" atom         -> neg\\n         | NAME             -> var\\n         | \\\"(\\\" sum \\\")\\\"\\n\\n    %import common.CNAME -> NAME\\n    %import common.NUMBER\\n    %import common.WS_INLINE\\n\\n    %ignore WS_INLINE\\n\\\"\\\"\\\"\\n\\n\\n@v_args(inline=True)    # Affects the signatures of the methods\\nclass CalculateTree(Transformer):\\n    from operator import add, sub, mul, truediv as div, neg\\n    number = float\\n\\n    def __init__(self):\\n        self.vars = {}\\n\\n    def assign_var(self, name, value):\\n        self.vars[name] = value\\n        return value\\n\\n    def var(self, name):\\n        try:\\n            return self.vars[name]\\n        except KeyError:\\n            raise Exception(\\\"Variable not found: %s\\\" % name)\\n\\n\\ncalc_parser = Lark(calc_grammar, parser='lalr', transformer=CalculateTree())\\ncalc = calc_parser.parse\\n\\n\\ndef main():\\n    while True:\\n        try:\\n            s = input('> ')\\n        except EOFError:\\n            break\\n        print(calc(s))\\n\\n\\ndef test():\\n    print(calc(\\\"a = 1+2\\\"))\\n    print(calc(\\\"1+a*-3\\\"))\\n\\n\\nif __name__ == '__main__':\\n    # test()\\n    main()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/63680f346bf793a45964b4e687bde3d9/calc.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/63680f346bf793a45964b4e687bde3d9/calc.ipynb",
        "status_code": 200,
        "scrape_id": "cf05dbff-0f57-44dc-bfaf-83f50b3a7e80",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2cc75b757e7515472722c8c02d4fe4e4/error_reporting_lalr.py",
      "markdown": "```\n\"\"\"\nExample-Driven Error Reporting\n==============================\n\nA demonstration of example-driven error reporting with the LALR parser\n(See also: error_reporting_earley.py)\n\"\"\"\nfrom lark import Lark, UnexpectedInput\n\nfrom _json_parser import json_grammar   # Using the grammar from the json_parser example\n\njson_parser = Lark(json_grammar, parser='lalr')\n\nclass JsonSyntaxError(SyntaxError):\n    def __str__(self):\n        context, line, column = self.args\n        return '%s at line %s, column %s.\\n\\n%s' % (self.label, line, column, context)\n\nclass JsonMissingValue(JsonSyntaxError):\n    label = 'Missing Value'\n\nclass JsonMissingOpening(JsonSyntaxError):\n    label = 'Missing Opening'\n\nclass JsonMissingClosing(JsonSyntaxError):\n    label = 'Missing Closing'\n\nclass JsonMissingComma(JsonSyntaxError):\n    label = 'Missing Comma'\n\nclass JsonTrailingComma(JsonSyntaxError):\n    label = 'Trailing Comma'\n\ndef parse(json_text):\n    try:\n        j = json_parser.parse(json_text)\n    except UnexpectedInput as u:\n        exc_class = u.match_examples(json_parser.parse, {\n            JsonMissingOpening: ['{\"foo\": ]}',\n                                 '{\"foor\": }}',\n                                 '{\"foo\": }'],\n            JsonMissingClosing: ['{\"foo\": [}',\\\n                                 '{',\\\n                                 '{\"a\": 1',\\\n                                 '[1'],\\\n            JsonMissingComma: ['[1 2]',\\\n                               '[false 1]',\\\n                               '[\"b\" 1]',\\\n                               '{\"a\":true 1:4}',\\\n                               '{\"a\":1 1:4}',\\\n                               '{\"a\":\"b\" 1:4}'],\\\n            JsonTrailingComma: ['[,]',\\\n                                '[1,]',\\\n                                '[1,2,]',\\\n                                '{\"foo\":1,}',\\\n                                '{\"foo\":false,\"bar\":true,}']\\\n        }, use_accepts=True)\\\n        if not exc_class:\\\n            raise\\\n        raise exc_class(u.get_context(json_text), u.line, u.column)\\\n\\\ndef test():\\\n    try:\\\n        parse('{\"example1\": \"value\"')\\\n    except JsonMissingClosing as e:\\\n        print(e)\\\n\\\n    try:\\\n        parse('{\"example2\": ] ')\\\n    except JsonMissingOpening as e:\\\n        print(e)\\\n\\\nif __name__ == '__main__':\\\n    test()\\\n\\\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2cc75b757e7515472722c8c02d4fe4e4/error_reporting_lalr.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/2cc75b757e7515472722c8c02d4fe4e4/error_reporting_lalr.py",
        "status_code": 200,
        "scrape_id": "70365743-848a-4159-88cb-49ce1aa86344",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/5811ce5e933efd9af1ae8e52d16a3a4f/custom_lexer.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Custom lexer\\n\\nDemonstrates using a custom lexer to parse a non-textual stream of data\\n\\nYou can use a custom lexer to tokenize text when the lexers offered by Lark\\nare too slow, or not flexible enough.\\n\\nYou can also use it (as shown in this example) to tokenize streams of objects.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark, Transformer, v_args\\nfrom lark.lexer import Lexer, Token\\n\\nclass TypeLexer(Lexer):\\n    def __init__(self, lexer_conf):\\n        pass\\n\\n    def lex(self, data):\\n        for obj in data:\\n            if isinstance(obj, int):\\n                yield Token('INT', obj)\\n            elif isinstance(obj, (type(''), type(u''))):\\n                yield Token('STR', obj)\\n            else:\\n                raise TypeError(obj)\\n\\nparser = Lark(\\\"\\\"\\\"\\n        start: data_item+\\n        data_item: STR INT*\\n\\n        %declare STR INT\\n        \\\"\\\"\\\", parser='lalr', lexer=TypeLexer)\\n\\n\\nclass ParseToDict(Transformer):\\n    @v_args(inline=True)\\n    def data_item(self, name, *numbers):\\n        return name.value, [n.value for n in numbers]\\n\\n    start = dict\\n\\n\\ndef test():\\n    data = ['alice', 1, 27, 3, 'bob', 4, 'carrie', 'dan', 8, 6]\\n\\n    print(data)\\n\\n    tree = parser.parse(data)\\n    res = ParseToDict().transform(tree)\\n\\n    print('-->')\\n    print(res) # prints {'alice': [1, 27, 3], 'bob': [4], 'carrie': [], 'dan': [8, 6]}\\n\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/5811ce5e933efd9af1ae8e52d16a3a4f/custom_lexer.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/5811ce5e933efd9af1ae8e52d16a3a4f/custom_lexer.ipynb",
        "status_code": 200,
        "scrape_id": "94e431fe-6604-4448-9f6d-85ac7d5d4359",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Grammar Composition\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/composition/index.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html \"Syntax Highlighting\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_json.html \"<no title>\")\n\n* * *\n\n# Grammar Composition [](https://lark-parser.readthedocs.io/en/stable/examples/composition/\\#grammar-composition \"Permalink to this heading\")\n\nThis example shows how to do grammar composition in Lark, by creating a new\nfile format that allows both CSV and JSON to co-exist.\n\nWe show how, by using namespaces, Lark grammars and their transformers can be fully reused -\nthey don’t need to care if their grammar is used directly, or being imported, or who is doing the importing.\n\nSee [main.py](https://github.com/lark-parser/lark/blob/master/examples/composition/main.py) for more details.\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_eval_json_thumb.png)\n\nsphx\\_glr\\_examples\\_composition\\_eval\\_json.py\n\nTransformer for evaluating json.lark\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_eval_csv_thumb.png)\n\nsphx\\_glr\\_examples\\_composition\\_eval\\_csv.py\n\nTransformer for evaluating csv.lark\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_main_thumb.png)\n\n[Grammar Composition](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html#sphx-glr-examples-composition-main-py)\n\nGrammar Composition\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/composition/)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/composition/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Grammar Composition — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/composition",
        "status_code": 200,
        "scrape_id": "1dd02b95-e0ea-4179-864b-c9cb984e256a",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3a11fd47a1fb670a6759747d618a244e/error_handling.py",
      "markdown": "```\n\"\"\"\nError handling using an interactive parser\n==========================================\n\nThis example demonstrates error handling using an interactive parser in LALR\n\nWhen the parser encounters an UnexpectedToken exception, it creates a\nan interactive parser with the current parse-state, and lets you control how\nto proceed step-by-step. When you've achieved the correct parse-state,\nyou can resume the run by returning True.\n\"\"\"\n\nfrom lark import Token\n\nfrom _json_parser import json_parser\n\ndef ignore_errors(e):\n    if e.token.type == 'COMMA':\n        # Skip comma\n        return True\n    elif e.token.type == 'SIGNED_NUMBER':\n        # Try to feed a comma and retry the number\n        e.interactive_parser.feed_token(Token('COMMA', ','))\n        e.interactive_parser.feed_token(e.token)\n        return True\n\n    # Unhandled error. Will stop parse and raise exception\n    return False\n\ndef main():\n    s = \"[0 1, 2,, 3,,, 4, 5 6 ]\"\n    res = json_parser.parse(s, on_error=ignore_errors)\n    print(res)      # prints [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n\nmain()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3a11fd47a1fb670a6759747d618a244e/error_handling.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/3a11fd47a1fb670a6759747d618a244e/error_handling.py",
        "status_code": 200,
        "scrape_id": "3f748598-50a8-485d-ac42-b6ecdaef3cab",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/57b38708c982e98764460c3e288a1ff5/reconstruct_python.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Reconstruct Python\\n\\nDemonstrates how Lark's experimental text-reconstruction feature can recreate\\nfunctional Python code from its parse-tree, using just the correct grammar and\\na small formatter.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Token, Lark\\nfrom lark.reconstruct import Reconstructor\\nfrom lark.indenter import PythonIndenter\\n\\n# Official Python grammar by Lark\\npython_parser3 = Lark.open_from_package('lark', 'python.lark', ['grammars'],\\n                                        parser='lalr', postlex=PythonIndenter(), start='file_input',\\n                                        maybe_placeholders=False    # Necessary for reconstructor\\n                                        )\\n\\nSPACE_AFTER = set(',+-*/~@<>=\\\"|:')\\nSPACE_BEFORE = (SPACE_AFTER - set(',:')) | set('\\\\'')\\n\\n\\ndef special(sym):\\n    return Token('SPECIAL', sym.name)\\n\\ndef postproc(items):\\n    stack = ['\\\\n']\\n    actions = []\\n    last_was_whitespace = True\\n    for item in items:\\n        if isinstance(item, Token) and item.type == 'SPECIAL':\\n            actions.append(item.value)\\n        else:\\n            if actions:\\n                assert actions[0] == '_NEWLINE' and '_NEWLINE' not in actions[1:], actions\\n\\n                for a in actions[1:]:\\n                    if a == '_INDENT':\\n                        stack.append(stack[-1] + ' ' * 4)\\n                    else:\\n                        assert a == '_DEDENT'\\n                        stack.pop()\\n                actions.clear()\\n                yield stack[-1]\\n                last_was_whitespace = True\\n            if not last_was_whitespace:\\n                if item[0] in SPACE_BEFORE:\\n                    yield ' '\\n            yield item\\n            last_was_whitespace = item[-1].isspace()\\n            if not last_was_whitespace:\\n                if item[-1] in SPACE_AFTER:\\n                    yield ' '\\n                    last_was_whitespace = True\\n    yield \\\"\\\\n\\\"\\n\\n\\nclass PythonReconstructor:\\n    def __init__(self, parser):\\n        self._recons = Reconstructor(parser, {'_NEWLINE': special, '_DEDENT': special, '_INDENT': special})\\n\\n    def reconstruct(self, tree):\\n        return self._recons.reconstruct(tree, postproc)\\n\\n\\ndef test():\\n    python_reconstructor = PythonReconstructor(python_parser3)\\n\\n    self_contents = open(__file__).read()\\n\\n    tree = python_parser3.parse(self_contents+'\\\\n')\\n    output = python_reconstructor.reconstruct(tree)\\n\\n    tree_new = python_parser3.parse(output)\\n    print(tree.pretty())\\n    print(tree_new.pretty())\\n    # assert tree.pretty() == tree_new.pretty()\\n    assert tree == tree_new\\n\\n    print(output)\\n\\n\\nif __name__ == '__main__':\\n    test()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/57b38708c982e98764460c3e288a1ff5/reconstruct_python.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/57b38708c982e98764460c3e288a1ff5/reconstruct_python.ipynb",
        "status_code": 200,
        "scrape_id": "fb50801e-4e43-400c-9abf-4966c4bb345e",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6dea8dbfb244508aaa3b8283470f8c2d/prioritizer.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Custom SPPF Prioritizer\\n\\nThis example demonstrates how to subclass ``ForestVisitor`` to make a custom\\nSPPF node prioritizer to be used in conjunction with ``TreeForestTransformer``.\\n\\nOur prioritizer will count the number of descendants of a node that are tokens.\\nBy negating this count, our prioritizer will prefer nodes with fewer token\\ndescendants. Thus, we choose the more specific parse.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"from lark import Lark\\nfrom lark.parsers.earley_forest import ForestVisitor, TreeForestTransformer\\n\\nclass TokenPrioritizer(ForestVisitor):\\n\\n    def visit_symbol_node_in(self, node):\\n        # visit the entire forest by returning node.children\\n        return node.children\\n\\n    def visit_packed_node_in(self, node):\\n        return node.children\\n\\n    def visit_symbol_node_out(self, node):\\n        priority = 0\\n        for child in node.children:\\n            # Tokens do not have a priority attribute\\n            # count them as -1\\n            priority += getattr(child, 'priority', -1)\\n        node.priority = priority\\n\\n    def visit_packed_node_out(self, node):\\n        priority = 0\\n        for child in node.children:\\n            priority += getattr(child, 'priority', -1)\\n        node.priority = priority\\n\\n    def on_cycle(self, node, path):\\n        raise Exception(\\\"Oops, we encountered a cycle.\\\")\\n\\ngrammar = \\\"\\\"\\\"\\nstart: hello \\\" \\\" world | hello_world\\nhello: \\\"Hello\\\"\\nworld: \\\"World\\\"\\nhello_world: \\\"Hello World\\\"\\n\\\"\\\"\\\"\\n\\nparser = Lark(grammar, parser='earley', ambiguity='forest')\\nforest = parser.parse(\\\"Hello World\\\")\\n\\nprint(\\\"Default prioritizer:\\\")\\ntree = TreeForestTransformer(resolve_ambiguity=True).transform(forest)\\nprint(tree.pretty())\\n\\nforest = parser.parse(\\\"Hello World\\\")\\n\\nprint(\\\"Custom prioritizer:\\\")\\ntree = TreeForestTransformer(resolve_ambiguity=True, prioritizer=TokenPrioritizer()).transform(forest)\\nprint(tree.pretty())\\n\\n# Output:\\n#\\n# Default prioritizer:\\n# start\\n#   hello Hello\\n#\\n#   world World\\n#\\n# Custom prioritizer:\\n# start\\n#   hello_world   Hello World\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6dea8dbfb244508aaa3b8283470f8c2d/prioritizer.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/6dea8dbfb244508aaa3b8283470f8c2d/prioritizer.ipynb",
        "status_code": 200,
        "scrape_id": "639d8ffc-6f9e-40a8-bb74-164811330b22",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/207f80f4ec59e1e363837373665f649f/turtle_dsl.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Turtle DSL\\n\\nImplements a LOGO-like toy language for Python\\u2019s turtle, with interpreter.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"try:\\n    input = raw_input   # For Python2 compatibility\\nexcept NameError:\\n    pass\\n\\nimport turtle\\n\\nfrom lark import Lark\\n\\nturtle_grammar = \\\"\\\"\\\"\\n    start: instruction+\\n\\n    instruction: MOVEMENT NUMBER            -> movement\\n               | \\\"c\\\" COLOR [COLOR]          -> change_color\\n               | \\\"fill\\\" code_block          -> fill\\n               | \\\"repeat\\\" NUMBER code_block -> repeat\\n\\n    code_block: \\\"{\\\" instruction+ \\\"}\\\"\\n\\n    MOVEMENT: \\\"f\\\"|\\\"b\\\"|\\\"l\\\"|\\\"r\\\"\\n    COLOR: LETTER+\\n\\n    %import common.LETTER\\n    %import common.INT -> NUMBER\\n    %import common.WS\\n    %ignore WS\\n\\\"\\\"\\\"\\n\\nparser = Lark(turtle_grammar)\\n\\ndef run_instruction(t):\\n    if t.data == 'change_color':\\n        turtle.color(*t.children)   # We just pass the color names as-is\\n\\n    elif t.data == 'movement':\\n        name, number = t.children\\n        { 'f': turtle.fd,\\n          'b': turtle.bk,\\n          'l': turtle.lt,\\n          'r': turtle.rt, }[name](int(number))\\n\\n    elif t.data == 'repeat':\\n        count, block = t.children\\n        for i in range(int(count)):\\n            run_instruction(block)\\n\\n    elif t.data == 'fill':\\n        turtle.begin_fill()\\n        run_instruction(t.children[0])\\n        turtle.end_fill()\\n\\n    elif t.data == 'code_block':\\n        for cmd in t.children:\\n            run_instruction(cmd)\\n    else:\\n        raise SyntaxError('Unknown instruction: %s' % t.data)\\n\\n\\ndef run_turtle(program):\\n    parse_tree = parser.parse(program)\\n    for inst in parse_tree.children:\\n        run_instruction(inst)\\n\\ndef main():\\n    while True:\\n        code = input('> ')\\n        try:\\n            run_turtle(code)\\n        except Exception as e:\\n            print(e)\\n\\ndef test():\\n    text = \\\"\\\"\\\"\\n        c red yellow\\n        fill { repeat 36 {\\n            f200 l170\\n        }}\\n    \\\"\\\"\\\"\\n    run_turtle(text)\\n\\nif __name__ == '__main__':\\n    # test()\\n    main()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/207f80f4ec59e1e363837373665f649f/turtle_dsl.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/207f80f4ec59e1e363837373665f649f/turtle_dsl.ipynb",
        "status_code": 200,
        "scrape_id": "7574d01d-cbd7-420e-8bd9-2a4593adc0a5",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/11091a0f6990e281219479476971fa12/eval_json.py",
      "markdown": "```\n\"Transformer for evaluating json.lark\"\n\nfrom lark import Transformer, v_args\n\nclass JsonTreeToJson(Transformer):\n    @v_args(inline=True)\n    def string(self, s):\n        return s[1:-1].replace('\\\\\"', '\"')\n\n    array = list\n    pair = tuple\n    object = dict\n    number = v_args(inline=True)(float)\n\n    null = lambda self, _: None\n    true = lambda self, _: True\n    false = lambda self, _: False\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/11091a0f6990e281219479476971fa12/eval_json.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/11091a0f6990e281219479476971fa12/eval_json.py",
        "status_code": 200,
        "scrape_id": "49cfff3c-6d77-42bd-9ad4-145de9443e24",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Grammar Composition](https://lark-parser.readthedocs.io/en/stable/examples/composition/index.html)\n- Grammar Composition\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/composition/main.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/composition/eval_csv.html \"<no title>\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/grammars/index.html \"Example Grammars\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html#sphx-glr-download-examples-composition-main-py)\nto download the full example code\n\n# Grammar Composition [](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html\\#grammar-composition \"Permalink to this heading\")\n\nThis example shows how to do grammar composition in Lark, by creating a new\nfile format that allows both CSV and JSON to co-exist.\n\n1. We define `storage.lark`, which imports both `csv.lark` and `json.lark`,\n\n\n> and allows them to be used one after the other.\n>\n> In the generated tree, each imported rule/terminal is automatically prefixed (with `json__` or [\\`\\`](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html#id1) [csv\\_\\_](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html#id3)),\n> which creates an implicit namespace and allows them to coexist without collisions.\n\n2. We merge their respective transformers (unaware of each other) into a new base transformer.\nThe resulting transformer can evaluate both JSON and CSV in the parse tree.\n\n\n> The methods of each transformer are renamed into their appropriate namespace, using the given prefix.\n> This approach allows full re-use: the transformers don’t need to care if their grammar is used directly,\n> or being imported, or who is doing the importing.\n\n```\nfrom pathlib import Path\nfrom lark import Lark\nfrom json import dumps\nfrom lark.visitors import Transformer, merge_transformers\n\nfrom eval_csv import CsvTreeToPandasDict\nfrom eval_json import JsonTreeToJson\n\n__dir__ = Path(__file__).parent\n\nclass Storage(Transformer):\n    def start(self, children):\n        return children\n\nstorage_transformer = merge_transformers(Storage(), csv=CsvTreeToPandasDict(), json=JsonTreeToJson())\n\nparser = Lark.open(\"storage.lark\", rel_to=__file__)\n\ndef main():\n    json_tree = parser.parse(dumps({\"test\": \"a\", \"dict\": { \"list\": [1, 1.2] }}))\n    res = storage_transformer.transform(json_tree)\n    print(\"Just JSON: \", res)\n\n    csv_json_tree = parser.parse(open(__dir__ / 'combined_csv_and_json.txt').read())\n    res = storage_transformer.transform(csv_json_tree)\n    print(\"JSON + CSV: \", dumps(res, indent=2))\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: main.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/98afe2f1c3b9485fcb8bdeebbbf0234f/main.py)\n\n[`Download Jupyter notebook: main.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/9edfb38ad3bc19fc2b92c728275b9008/main.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/composition/main.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Grammar Composition — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/composition/main.html",
        "status_code": 200,
        "scrape_id": "c2c71bd1-442d-40af-908f-efd7b8a5a999",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.298Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Custom lexer\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/custom_lexer.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html \"Reconstruct a JSON\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html \"Transform a Forest\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html#sphx-glr-download-examples-advanced-custom-lexer-py)\nto download the full example code\n\n# Custom lexer [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html\\#custom-lexer \"Permalink to this heading\")\n\nDemonstrates using a custom lexer to parse a non-textual stream of data\n\nYou can use a custom lexer to tokenize text when the lexers offered by Lark\nare too slow, or not flexible enough.\n\nYou can also use it (as shown in this example) to tokenize streams of objects.\n\n```\nfrom lark import Lark, Transformer, v_args\nfrom lark.lexer import Lexer, Token\n\nclass TypeLexer(Lexer):\n    def __init__(self, lexer_conf):\n        pass\n\n    def lex(self, data):\n        for obj in data:\n            if isinstance(obj, int):\n                yield Token('INT', obj)\n            elif isinstance(obj, (type(''), type(u''))):\n                yield Token('STR', obj)\n            else:\n                raise TypeError(obj)\n\nparser = Lark(\"\"\"\n        start: data_item+\n        data_item: STR INT*\n\n        %declare STR INT\n        \"\"\", parser='lalr', lexer=TypeLexer)\n\nclass ParseToDict(Transformer):\n    @v_args(inline=True)\n    def data_item(self, name, *numbers):\n        return name.value, [n.value for n in numbers]\n\n    start = dict\n\ndef test():\n    data = ['alice', 1, 27, 3, 'bob', 4, 'carrie', 'dan', 8, 6]\n\n    print(data)\n\n    tree = parser.parse(data)\n    res = ParseToDict().transform(tree)\n\n    print('-->')\n    print(res) # prints {'alice': [1, 27, 3], 'bob': [4], 'carrie': [], 'dan': [8, 6]}\n\nif __name__ == '__main__':\n    test()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: custom_lexer.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/4667ab58050962ac05455b953c59244f/custom_lexer.py)\n\n[`Download Jupyter notebook: custom_lexer.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/5811ce5e933efd9af1ae8e52d16a3a4f/custom_lexer.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/custom_lexer.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Custom lexer — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html",
        "status_code": 200,
        "scrape_id": "6e9f9070-113d-4d24-ac76-4e6c87414017",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Earley’s dynamic lexer\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/conf_earley.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html \"Templates\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html \"Error handling using an interactive parser\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html#sphx-glr-download-examples-advanced-conf-earley-py)\nto download the full example code\n\n# Earley’s dynamic lexer [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html\\#earleys-dynamic-lexer \"Permalink to this heading\")\n\nDemonstrates the power of Earley’s dynamic lexer on a toy configuration language\n\nUsing a lexer for configuration files is tricky, because values don’t\nhave to be surrounded by delimiters. Using a basic lexer for this just won’t work.\n\nIn this example we use a dynamic lexer and let the Earley parser resolve the ambiguity.\n\nAnother approach is to use the contextual lexer with LALR. It is less powerful than Earley,\nbut it can handle some ambiguity when lexing and it’s much faster.\nSee examples/conf\\_lalr.py for an example of that approach.\n\n```\nfrom lark import Lark\n\nparser = Lark(r\"\"\"\n        start: _NL? section+\n        section: \"[\" NAME \"]\" _NL item+\n        item: NAME \"=\" VALUE? _NL\n\n        NAME: /\\w/+\n        VALUE: /./+\n\n        %import common.NEWLINE -> _NL\n        %import common.WS_INLINE\n        %ignore WS_INLINE\n    \"\"\", parser=\"earley\")\n\ndef test():\n    sample_conf = \"\"\"\n[bla]\n\na=Hello\nthis=\"that\",4\nempty=\n\"\"\"\n\n    r = parser.parse(sample_conf)\n    print (r.pretty())\n\nif __name__ == '__main__':\n    test()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: conf_earley.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/1bc3cb4e14f2c898c0bf16247304d5b2/conf_earley.py)\n\n[`Download Jupyter notebook: conf_earley.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/f034a71a096a9049dcf409ec85c36943/conf_earley.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/conf_earley.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Earley’s dynamic lexer — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html",
        "status_code": 200,
        "scrape_id": "216a8a04-8120-4afe-b8ca-d4e0ef9c6932",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Advanced Examples\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/index.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/json_parser.html \"Simple JSON Parser\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html \"LALR’s contextual lexer\")\n\n* * *\n\n# Advanced Examples [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html\\#advanced-examples \"Permalink to this heading\")\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_conf_lalr_thumb.png)\n\n[LALR’s contextual lexer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html#sphx-glr-examples-advanced-conf-lalr-py)\n\nLALR’s contextual lexer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_templates_thumb.png)\n\n[Templates](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html#sphx-glr-examples-advanced-templates-py)\n\nTemplates\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_conf_earley_thumb.png)\n\n[Earley’s dynamic lexer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html#sphx-glr-examples-advanced-conf-earley-py)\n\nEarley’s dynamic lexer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_error_handling_thumb.png)\n\n[Error handling using an interactive parser](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_handling.html#sphx-glr-examples-advanced-error-handling-py)\n\nError handling using an interactive parser\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_reconstruct_json_thumb.png)\n\n[Reconstruct a JSON](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_json.html#sphx-glr-examples-advanced-reconstruct-json-py)\n\nReconstruct a JSON\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_custom_lexer_thumb.png)\n\n[Custom lexer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/custom_lexer.html#sphx-glr-examples-advanced-custom-lexer-py)\n\nCustom lexer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_tree_forest_transformer_thumb.png)\n\n[Transform a Forest](https://lark-parser.readthedocs.io/en/stable/examples/advanced/tree_forest_transformer.html#sphx-glr-examples-advanced-tree-forest-transformer-py)\n\nTransform a Forest\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr__json_parser_thumb.png)\n\n[Simple JSON Parser](https://lark-parser.readthedocs.io/en/stable/examples/advanced/_json_parser.html#sphx-glr-examples-advanced-json-parser-py)\n\nSimple JSON Parser\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_prioritizer_thumb.png)\n\n[Custom SPPF Prioritizer](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html#sphx-glr-examples-advanced-prioritizer-py)\n\nCustom SPPF Prioritizer\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_py3to2_thumb.png)\n\n[Python 3 to Python 2 converter (tree templates)](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html#sphx-glr-examples-advanced-py3to2-py)\n\nPython 3 to Python 2 converter (tree templates)\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_python_parser_thumb.png)\n\n[Grammar-complete Python Parser](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html#sphx-glr-examples-advanced-python-parser-py)\n\nGrammar-complete Python Parser\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_create_ast_thumb.png)\n\n[Creating an AST from the parse tree](https://lark-parser.readthedocs.io/en/stable/examples/advanced/create_ast.html#sphx-glr-examples-advanced-create-ast-py)\n\nCreating an AST from the parse tree\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_error_reporting_earley_thumb.png)\n\n[Example-Driven Error Reporting](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_earley.html#sphx-glr-examples-advanced-error-reporting-earley-py)\n\nExample-Driven Error Reporting\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_error_reporting_lalr_thumb.png)\n\n[Example-Driven Error Reporting](https://lark-parser.readthedocs.io/en/stable/examples/advanced/error_reporting_lalr.html#sphx-glr-examples-advanced-error-reporting-lalr-py)\n\nExample-Driven Error Reporting\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_reconstruct_python_thumb.png)\n\n[Reconstruct Python](https://lark-parser.readthedocs.io/en/stable/examples/advanced/reconstruct_python.html#sphx-glr-examples-advanced-reconstruct-python-py)\n\nReconstruct Python\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_dynamic_complete_thumb.png)\n\n[Using lexer dynamic\\_complete](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html#sphx-glr-examples-advanced-dynamic-complete-py)\n\nUsing lexer dynamic\\_complete\n\n![](https://lark-parser.readthedocs.io/en/stable/_images/sphx_glr_qscintilla_json_thumb.png)\n\n[Syntax Highlighting](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html#sphx-glr-examples-advanced-qscintilla-json-py)\n\nSyntax Highlighting\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Advanced Examples — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html",
        "status_code": 200,
        "scrape_id": "074dcba4-e82c-473a-930e-70b30f09c45c",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/47174f1088585b541b7296c461639c79/eval_csv.py",
      "markdown": "```\n\"Transformer for evaluating csv.lark\"\n\nfrom lark import Transformer\n\nclass CsvTreeToPandasDict(Transformer):\n    INT = int\n    FLOAT = float\n    SIGNED_FLOAT = float\n    WORD = str\n    NON_SEPARATOR_STRING = str\n\n    def row(self, children):\n        return children\n\n    def start(self, children):\n        data = {}\n\n        header = children[0].children\n        for heading in header:\n            data[heading] = []\n\n        for row in children[1:]:\n            for i, element in enumerate(row):\n                data[header[i]].append(element)\n\n        return data\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/47174f1088585b541b7296c461639c79/eval_csv.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/47174f1088585b541b7296c461639c79/eval_csv.py",
        "status_code": 200,
        "scrape_id": "dd18cc80-3382-4437-afc8-865360255182",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Templates\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/templates.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_lalr.html \"LALR’s contextual lexer\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/conf_earley.html \"Earley’s dynamic lexer\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html#sphx-glr-download-examples-advanced-templates-py)\nto download the full example code\n\n# Templates [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html\\#templates \"Permalink to this heading\")\n\nThis example shows how to use Lark’s templates to achieve cleaner grammars\n\n```\nfrom lark import Lark\n\ngrammar = r\"\"\"\nstart: list | dict\n\nlist: \"[\" _seperated{atom, \",\"} \"]\"\ndict: \"{\" _seperated{key_value, \",\"} \"}\"\nkey_value: atom \":\" atom\n\n_seperated{x, sep}: x (sep x)*  // Define a sequence of 'x sep x sep x ...'\n\natom: NUMBER | ESCAPED_STRING\n\n%import common (NUMBER, ESCAPED_STRING, WS)\n%ignore WS\n\"\"\"\n\nparser = Lark(grammar)\n\nprint(parser.parse('[1, \"a\", 2]'))\nprint(parser.parse('{\"a\": 2, \"b\": 6}'))\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: templates.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/d3b43c711b7f9a6aeee99f79cf861539/templates.py)\n\n[`Download Jupyter notebook: templates.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/6619e43bab1bed7430fa709940e67aa2/templates.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/templates.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Templates — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/templates.html",
        "status_code": 200,
        "scrape_id": "b8c1047d-07b3-442c-a168-e451cf24b656",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/60290154124d6b16926446036bb711d6/python_parser.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Grammar-complete Python Parser\\n\\nA fully-working Python 2 & 3 parser (but not production ready yet!)\\n\\nThis example demonstrates usage of the included Python grammars\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import sys\\nimport os, os.path\\nfrom io import open\\nimport glob, time\\n\\nfrom lark import Lark\\nfrom lark.indenter import PythonIndenter\\n\\n\\nkwargs = dict(postlex=PythonIndenter(), start='file_input')\\n\\n# Official Python grammar by Lark\\npython_parser3 = Lark.open_from_package('lark', 'python.lark', ['grammars'], parser='lalr', **kwargs)\\n\\n# Local Python2 grammar\\npython_parser2 = Lark.open('python2.lark', rel_to=__file__, parser='lalr', **kwargs)\\npython_parser2_earley = Lark.open('python2.lark', rel_to=__file__, parser='earley', lexer='basic', **kwargs)\\n\\ntry:\\n    xrange\\nexcept NameError:\\n    chosen_parser = python_parser3\\nelse:\\n    chosen_parser = python_parser2\\n\\n\\ndef _read(fn, *args):\\n    kwargs = {'encoding': 'iso-8859-1'}\\n    with open(fn, *args, **kwargs) as f:\\n        return f.read()\\n\\ndef _get_lib_path():\\n    if os.name == 'nt':\\n        if 'PyPy' in sys.version:\\n            return os.path.join(sys.base_prefix, 'lib-python', sys.winver)\\n        else:\\n            return os.path.join(sys.base_prefix, 'Lib')\\n    else:\\n        return [x for x in sys.path if x.endswith('%s.%s' % sys.version_info[:2])][0]\\n\\ndef test_python_lib():\\n    path = _get_lib_path()\\n\\n    start = time.time()\\n    files = glob.glob(path+'/*.py')\\n    total_kb = 0\\n    for f in files:\\n        r = _read(os.path.join(path, f))\\n        kb = len(r) / 1024\\n        print( '%s -\\\\t%.1f kb' % (f, kb))\\n        chosen_parser.parse(r + '\\\\n')\\n        total_kb += kb\\n\\n    end = time.time()\\n    print( \\\"test_python_lib (%d files, %.1f kb), time: %.2f secs\\\"%(len(files), total_kb, end-start) )\\n\\ndef test_earley_equals_lalr():\\n    path = _get_lib_path()\\n\\n    files = glob.glob(path+'/*.py')\\n    for f in files:\\n        print( f )\\n        tree1 = python_parser2.parse(_read(os.path.join(path, f)) + '\\\\n')\\n        tree2 = python_parser2_earley.parse(_read(os.path.join(path, f)) + '\\\\n')\\n        assert tree1 == tree2\\n\\n\\nif __name__ == '__main__':\\n    test_python_lib()\\n    # test_earley_equals_lalr()\\n    # python_parser3.parse(_read(sys.argv[1]) + '\\\\n')\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/60290154124d6b16926446036bb711d6/python_parser.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/60290154124d6b16926446036bb711d6/python_parser.ipynb",
        "status_code": 200,
        "scrape_id": "34b935a8-618d-4307-b687-d674365b9007",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Syntax Highlighting\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/qscintilla_json.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/dynamic_complete.html \"Using lexer dynamic_complete\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/composition/index.html \"Grammar Composition\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html#sphx-glr-download-examples-advanced-qscintilla-json-py)\nto download the full example code\n\n# Syntax Highlighting [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html\\#syntax-highlighting \"Permalink to this heading\")\n\nThis example shows how to write a syntax-highlighted editor with Qt and Lark\n\nRequirements:\n\n> PyQt5==5.15.8\n> QScintilla==2.13.4\n\n```\nimport sys\nimport textwrap\n\nfrom PyQt5.QtWidgets import QApplication\nfrom PyQt5.QtGui import QColor, QFont, QFontMetrics\n\nfrom PyQt5.Qsci import QsciScintilla\nfrom PyQt5.Qsci import QsciLexerCustom\n\nfrom lark import Lark\n\nclass LexerJson(QsciLexerCustom):\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n        self.create_parser()\n        self.create_styles()\n\n    def create_styles(self):\n        deeppink = QColor(249, 38, 114)\n        khaki = QColor(230, 219, 116)\n        mediumpurple = QColor(174, 129, 255)\n        mediumturquoise = QColor(81, 217, 205)\n        yellowgreen = QColor(166, 226, 46)\n        lightcyan = QColor(213, 248, 232)\n        darkslategrey = QColor(39, 40, 34)\n\n        styles = {\n            0: mediumturquoise,\n            1: mediumpurple,\n            2: yellowgreen,\n            3: deeppink,\n            4: khaki,\n            5: lightcyan\n        }\n\n        for style, color in styles.items():\n            self.setColor(color, style)\n            self.setPaper(darkslategrey, style)\n            self.setFont(self.parent().font(), style)\n\n        self.token_styles = {\n            \"COLON\": 5,\n            \"COMMA\": 5,\n            \"LBRACE\": 5,\n            \"LSQB\": 5,\n            \"RBRACE\": 5,\n            \"RSQB\": 5,\n            \"FALSE\": 0,\n            \"NULL\": 0,\n            \"TRUE\": 0,\n            \"STRING\": 4,\n            \"NUMBER\": 1,\n        }\n\n    def create_parser(self):\n        grammar = '''\n            anons: \":\" \"{\" \"}\" \",\" \"[\" \"]\"\n            TRUE: \"true\"\n            FALSE: \"false\"\n            NULL: \"NULL\"\n            %import common.ESCAPED_STRING -> STRING\n            %import common.SIGNED_NUMBER  -> NUMBER\n            %import common.WS\n            %ignore WS\n        '''\n\n        self.lark = Lark(grammar, parser=None, lexer='basic')\n        # All tokens: print([t.name for t in self.lark.parser.lexer.tokens])\n\n    def defaultPaper(self, style):\n        return QColor(39, 40, 34)\n\n    def language(self):\n        return \"Json\"\n\n    def description(self, style):\n        return {v: k for k, v in self.token_styles.items()}.get(style, \"\")\n\n    def styleText(self, start, end):\n        self.startStyling(start)\n        text = self.parent().text()[start:end]\n        last_pos = 0\n\n        try:\n            for token in self.lark.lex(text):\n                ws_len = token.start_pos - last_pos\n                if ws_len:\n                    self.setStyling(ws_len, 0)    # whitespace\n\n                token_len = len(bytearray(token, \"utf-8\"))\n                self.setStyling(\n                    token_len, self.token_styles.get(token.type, 0))\n\n                last_pos = token.start_pos + token_len\n        except Exception as e:\n            print(e)\n\nclass EditorAll(QsciScintilla):\n\n    def __init__(self, parent=None):\n        super().__init__(parent)\n\n        # Set font defaults\n        font = QFont()\n        font.setFamily('Consolas')\n        font.setFixedPitch(True)\n        font.setPointSize(8)\n        font.setBold(True)\n        self.setFont(font)\n\n        # Set margin defaults\n        fontmetrics = QFontMetrics(font)\n        self.setMarginsFont(font)\n        self.setMarginWidth(0, fontmetrics.width(\"000\") + 6)\n        self.setMarginLineNumbers(0, True)\n        self.setMarginsForegroundColor(QColor(128, 128, 128))\n        self.setMarginsBackgroundColor(QColor(39, 40, 34))\n        self.setMarginType(1, self.SymbolMargin)\n        self.setMarginWidth(1, 12)\n\n        # Set indentation defaults\n        self.setIndentationsUseTabs(False)\n        self.setIndentationWidth(4)\n        self.setBackspaceUnindents(True)\n        self.setIndentationGuides(True)\n\n        # self.setFolding(QsciScintilla.CircledFoldStyle)\n\n        # Set caret defaults\n        self.setCaretForegroundColor(QColor(247, 247, 241))\n        self.setCaretWidth(2)\n\n        # Set selection color defaults\n        self.setSelectionBackgroundColor(QColor(61, 61, 52))\n        self.resetSelectionForegroundColor()\n\n        # Set multiselection defaults\n        self.SendScintilla(QsciScintilla.SCI_SETMULTIPLESELECTION, True)\n        self.SendScintilla(QsciScintilla.SCI_SETMULTIPASTE, 1)\n        self.SendScintilla(\n            QsciScintilla.SCI_SETADDITIONALSELECTIONTYPING, True)\n\n        lexer = LexerJson(self)\n        self.setLexer(lexer)\n\nEXAMPLE_TEXT = textwrap.dedent(\"\"\"\\\n        {\n            \"_id\": \"5b05ffcbcf8e597939b3f5ca\",\n            \"about\": \"Excepteur consequat commodo esse voluptate aute aliquip ad sint deserunt commodo eiusmod irure. Sint aliquip sit magna duis eu est culpa aliqua excepteur ut tempor nulla. Aliqua ex pariatur id labore sit. Quis sit ex aliqua veniam exercitation laboris anim adipisicing. Lorem nisi reprehenderit ullamco labore qui sit ut aliqua tempor consequat pariatur proident.\",\n            \"address\": \"665 Malbone Street, Thornport, Louisiana, 243\",\n            \"age\": 23,\n            \"balance\": \"$3,216.91\",\n            \"company\": \"BULLJUICE\",\n            \"email\": \"elisekelley@bulljuice.com\",\n            \"eyeColor\": \"brown\",\n            \"gender\": \"female\",\n            \"guid\": \"d3a6d865-0f64-4042-8a78-4f53de9b0707\",\n            \"index\": 0,\n            \"isActive\": false,\n            \"isActive2\": true,\n            \"latitude\": -18.660714,\n            \"longitude\": -85.378048,\n            \"name\": \"Elise Kelley\",\n            \"phone\": \"+1 (808) 543-3966\",\n            \"picture\": \"http://placehold.it/32x32\",\n            \"registered\": \"2017-09-30T03:47:40 -02:00\",\n            \"tags\": [\\\n                \"et\",\\\n                \"nostrud\",\\\n                \"in\",\\\n                \"fugiat\",\\\n                \"incididunt\",\\\n                \"labore\",\\\n                \"nostrud\"\\\n            ]\n        }\\\n    \"\"\")\n\ndef main():\n    app = QApplication(sys.argv)\n    ex = EditorAll()\n    ex.setWindowTitle(__file__)\n    ex.setText(EXAMPLE_TEXT)\n    ex.resize(800, 600)\n    ex.show()\n    sys.exit(app.exec_())\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: qscintilla_json.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/1e229dcdb521be752d4349e61ead59d1/qscintilla_json.py)\n\n[`Download Jupyter notebook: qscintilla_json.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/9056f9d3440746d8fe151c31173e18e6/qscintilla_json.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/qscintilla_json.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Syntax Highlighting — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/qscintilla_json.html",
        "status_code": 200,
        "scrape_id": "ea94dc84-cb77-4f1d-812b-7230934ff583",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/b9abd703bb1b061d8ae5f6ab1b9393e8/lark_grammar.py",
      "markdown": "```\n\"\"\"\nLark Grammar\n============\n\nA reference implementation of the Lark grammar (using LALR(1))\n\"\"\"\nimport lark\nfrom pathlib import Path\n\nexamples_path = Path(__file__).parent\nlark_path = Path(lark.__file__).parent\n\nparser = lark.Lark.open(lark_path / 'grammars/lark.lark', rel_to=__file__, parser=\"lalr\")\n\ngrammar_files = [\\\n    examples_path / 'advanced/python2.lark',\\\n    examples_path / 'relative-imports/multiples.lark',\\\n    examples_path / 'relative-imports/multiple2.lark',\\\n    examples_path / 'relative-imports/multiple3.lark',\\\n    examples_path / 'tests/no_newline_at_end.lark',\\\n    examples_path / 'tests/negative_priority.lark',\\\n    examples_path / 'standalone/json.lark',\\\n    lark_path / 'grammars/common.lark',\\\n    lark_path / 'grammars/lark.lark',\\\n    lark_path / 'grammars/unicode.lark',\\\n    lark_path / 'grammars/python.lark',\\\n]\n\ndef test():\n    for grammar_file in grammar_files:\n        tree = parser.parse(open(grammar_file).read())\n    print(\"All grammars parsed successfully\")\n\nif __name__ == '__main__':\n    test()\n\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/b9abd703bb1b061d8ae5f6ab1b9393e8/lark_grammar.py",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/b9abd703bb1b061d8ae5f6ab1b9393e8/lark_grammar.py",
        "status_code": 200,
        "scrape_id": "9763e1aa-92c2-49bc-8489-4590737fe200",
        "content_type": "text/x-python",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/adf07a4514e9cfb278aef018e6994028/reconstruct_json.ipynb",
      "markdown": "```\n{\n  \"cells\": [\\\n    {\\\n      \"cell_type\": \"markdown\",\\\n      \"metadata\": {},\\\n      \"source\": [\\\n        \"\\n# Reconstruct a JSON\\n\\nDemonstrates the experimental text-reconstruction feature\\n\\nThe Reconstructor takes a parse tree (already filtered from punctuation, of course),\\nand reconstructs it into correct text, that can be parsed correctly.\\nIt can be useful for creating \\\"hooks\\\" to alter data before handing it to other parsers. You can also use it to generate samples from scratch.\\n\"\\\n      ]\\\n    },\\\n    {\\\n      \"cell_type\": \"code\",\\\n      \"execution_count\": null,\\\n      \"metadata\": {\\\n        \"collapsed\": false\\\n      },\\\n      \"outputs\": [],\\\n      \"source\": [\\\n        \"import json\\n\\nfrom lark import Lark\\nfrom lark.reconstruct import Reconstructor\\n\\nfrom _json_parser import json_grammar\\n\\ntest_json = '''\\n    {\\n        \\\"empty_object\\\" : {},\\n        \\\"empty_array\\\"  : [],\\n        \\\"booleans\\\"     : { \\\"YES\\\" : true, \\\"NO\\\" : false },\\n        \\\"numbers\\\"      : [ 0, 1, -2, 3.3, 4.4e5, 6.6e-7 ],\\n        \\\"strings\\\"      : [ \\\"This\\\", [ \\\"And\\\" , \\\"That\\\", \\\"And a \\\\\\\\\\\"b\\\" ] ],\\n        \\\"nothing\\\"      : null\\n    }\\n'''\\n\\ndef test_earley():\\n\\n    json_parser = Lark(json_grammar, maybe_placeholders=False)\\n    tree = json_parser.parse(test_json)\\n\\n    new_json = Reconstructor(json_parser).reconstruct(tree)\\n    print (new_json)\\n    print (json.loads(new_json) == json.loads(test_json))\\n\\n\\ndef test_lalr():\\n\\n    json_parser = Lark(json_grammar, parser='lalr', maybe_placeholders=False)\\n    tree = json_parser.parse(test_json)\\n\\n    new_json = Reconstructor(json_parser).reconstruct(tree)\\n    print (new_json)\\n    print (json.loads(new_json) == json.loads(test_json))\\n\\ntest_earley()\\ntest_lalr()\"\\\n      ]\\\n    }\\\n  ],\n  \"metadata\": {\n    \"kernelspec\": {\n      \"display_name\": \"Python 3\",\n      \"language\": \"python\",\n      \"name\": \"python3\"\n    },\n    \"language_info\": {\n      \"codemirror_mode\": {\n        \"name\": \"ipython\",\n        \"version\": 3\n      },\n      \"file_extension\": \".py\",\n      \"mimetype\": \"text/x-python\",\n      \"name\": \"python\",\n      \"nbconvert_exporter\": \"python\",\n      \"pygments_lexer\": \"ipython3\",\n      \"version\": \"3.7.17\"\n    }\n  },\n  \"nbformat\": 4,\n  \"nbformat_minor\": 0\n}\n```",
      "metadata": {
        "url": "https://lark-parser.readthedocs.io/en/stable/_downloads/adf07a4514e9cfb278aef018e6994028/reconstruct_json.ipynb",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/_downloads/adf07a4514e9cfb278aef018e6994028/reconstruct_json.ipynb",
        "status_code": 200,
        "scrape_id": "47a05d0d-8c6b-4332-a996-ca6a7ffff091",
        "content_type": "application/x-ipynb+json",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- [Advanced Examples](https://lark-parser.readthedocs.io/en/stable/examples/advanced/index.html)\n- Python 3 to Python 2 converter (tree templates)\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/advanced/py3to2.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/advanced/prioritizer.html \"Custom SPPF Prioritizer\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/advanced/python_parser.html \"Grammar-complete Python Parser\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html#sphx-glr-download-examples-advanced-py3to2-py)\nto download the full example code\n\n# Python 3 to Python 2 converter (tree templates) [](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html\\#python-3-to-python-2-converter-tree-templates \"Permalink to this heading\")\n\nThis example demonstrates how to translate between two trees using tree templates.\nIt parses Python 3, translates it to a Python 2 AST, and then outputs the result as Python 2 code.\n\nUses reconstruct\\_python.py for generating the final Python 2 code.\n\n```\nfrom lark import Lark\nfrom lark.tree_templates import TemplateConf, TemplateTranslator\n\nfrom lark.indenter import PythonIndenter\nfrom reconstruct_python import PythonReconstructor\n\n#\n# 1. Define a Python parser that also accepts template vars in the code (in the form of $var)\n#\nTEMPLATED_PYTHON = r\"\"\"\n%import python (single_input, file_input, eval_input, atom, var, stmt, expr, testlist_star_expr, _NEWLINE, _INDENT, _DEDENT, COMMENT, NAME)\n\n%extend atom: TEMPLATE_NAME -> var\n\nTEMPLATE_NAME: \"$\" NAME\n\n?template_start: (stmt | testlist_star_expr _NEWLINE)\n\n%ignore /[\\t \\f]+/          // WS\n%ignore /\\\\[\\t \\f]*\\r?\\n/   // LINE_CONT\n%ignore COMMENT\n\"\"\"\n\nparser = Lark(TEMPLATED_PYTHON, parser='lalr', start=['single_input', 'file_input', 'eval_input', 'template_start'], postlex=PythonIndenter(), maybe_placeholders=False)\n\ndef parse_template(s):\n    return parser.parse(s + '\\n', start='template_start')\n\ndef parse_code(s):\n    return parser.parse(s + '\\n', start='file_input')\n\n#\n# 2. Define translations using templates (each template code is parsed to a template tree)\n#\n\npytemplate = TemplateConf(parse=parse_template)\n\ntranslations_3to2 = {\n    'yield from $a':\n        'for _tmp in $a: yield _tmp',\n\n    'raise $e from $x':\n            'raise $e',\n\n    '$a / $b':\n        'float($a) / $b',\n}\ntranslations_3to2 = {pytemplate(k): pytemplate(v) for k, v in translations_3to2.items()}\n\n#\n# 3. Translate and reconstruct Python 3 code into valid Python 2 code\n#\n\npython_reconstruct = PythonReconstructor(parser)\n\ndef translate_py3to2(code):\n    tree = parse_code(code)\n    tree = TemplateTranslator(translations_3to2).translate(tree)\n    return python_reconstruct.reconstruct(tree)\n\n#\n# Test Code\n#\n\n_TEST_CODE = '''\nif a / 2 > 1:\n    yield from [1,2,3]\nelse:\n    raise ValueError(a) from e\n\n'''\n\ndef test():\n    print(_TEST_CODE)\n    print('   ----->    ')\n    print(translate_py3to2(_TEST_CODE))\n\nif __name__ == '__main__':\n    test()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: py3to2.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/347194332333371dddab71778db00fd5/py3to2.py)\n\n[`Download Jupyter notebook: py3to2.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/c1123c2587eda70bc64752df00c577b1/py3to2.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/advanced/py3to2.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Python 3 to Python 2 converter (tree templates) — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/advanced/py3to2.html",
        "status_code": 200,
        "scrape_id": "1efeb16f-9dda-435c-9ef9-cad2add756f7",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.678Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/forest.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- Working with the SPPF\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/forest.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/visitors.html \"Transformers & Visitors\") [Next](https://lark-parser.readthedocs.io/en/stable/tools.html \"Tools (Stand-alone, Nearley)\")\n\n* * *\n\n# Working with the SPPF [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#working-with-the-sppf \"Permalink to this heading\")\n\nWhen parsing with Earley, Lark provides the `ambiguity='forest'` option\nto obtain the shared packed parse forest (SPPF) produced by the parser as\nan alternative to it being automatically converted to a tree.\n\nLark provides a few tools to facilitate working with the SPPF. Here are some\nthings to consider when deciding whether or not to use the SPPF.\n\n**Pros**\n\n- Efficient storage of highly ambiguous parses\n\n- Precise handling of ambiguities\n\n- Custom rule prioritizers\n\n- Ability to handle infinite ambiguities\n\n- Directly transform forest -> object instead of forest -> tree -> object\n\n\n**Cons**\n\n- More complex than working with a tree\n\n- SPPF may contain nodes corresponding to rules generated internally\n\n- Loss of Lark grammar features:\n\n  - Rules starting with ‘\\_’ are not inlined in the SPPF\n\n  - Rules starting with ‘?’ are never inlined in the SPPF\n\n  - All tokens will appear in the SPPF\n\n## SymbolNode [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#symbolnode \"Permalink to this heading\")\n\n_class_ lark.parsers.earley\\_forest.SymbolNode( _s_, _start_, _end_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.SymbolNode \"Permalink to this definition\")\n\nA Symbol Node represents a symbol (or Intermediate LR0).\n\nSymbol nodes are keyed by the symbol (s). For intermediate nodes\ns will be an LR0, stored as a tuple of (rule, ptr). For completed symbol\nnodes, s will be a string representing the non-terminal origin (i.e.\nthe left hand side of the rule).\n\nThe children of a Symbol or Intermediate Node will always be Packed Nodes;\nwith each Packed Node child representing a single derivation of a production.\n\nHence a Symbol Node with a single child is unambiguous.\n\nParameters:\n\n- **s** – A Symbol, or a tuple of (rule, ptr) for an intermediate node.\n\n- **start** – For dynamic lexers, the index of the start of the substring matched by this symbol (inclusive).\n\n- **end** – For dynamic lexers, the index of the end of the substring matched by this symbol (exclusive).\n\n\nProperties:\n\nis\\_intermediate: True if this node is an intermediate node.\npriority: The priority of the node’s symbol.\n\n_property_ is\\_ambiguous [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.SymbolNode.is_ambiguous \"Permalink to this definition\")\n\nReturns True if this node is ambiguous.\n\n_property_ children [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.SymbolNode.children \"Permalink to this definition\")\n\nReturns a list of this node’s children sorted from greatest to\nleast priority.\n\n## PackedNode [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#packednode \"Permalink to this heading\")\n\n_class_ lark.parsers.earley\\_forest.PackedNode( _parent_, _s_, _rule_, _start_, _left_, _right_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.PackedNode \"Permalink to this definition\")\n\nA Packed Node represents a single derivation in a symbol node.\n\nParameters:\n\n- **rule** – The rule associated with this node.\n\n- **parent** – The parent of this node.\n\n- **left** – The left child of this node. `None` if one does not exist.\n\n- **right** – The right child of this node. `None` if one does not exist.\n\n- **priority** – The priority of this node.\n\n\n_property_ children [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.PackedNode.children \"Permalink to this definition\")\n\nReturns a list of this node’s children.\n\n## ForestVisitor [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#forestvisitor \"Permalink to this heading\")\n\n_class_ lark.parsers.earley\\_forest.ForestVisitor( _single\\_visit=False_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor \"Permalink to this definition\")\n\nAn abstract base class for building forest visitors.\n\nThis class performs a controllable depth-first walk of an SPPF.\nThe visitor will not enter cycles and will backtrack if one is encountered.\nSubclasses are notified of cycles through the `on_cycle` method.\n\nBehavior for visit events is defined by overriding the\n`visit*node*` functions.\n\nThe walk is controlled by the return values of the `visit*node_in`\nmethods. Returning a node(s) will schedule them to be visited. The visitor\nwill begin to backtrack if no nodes are returned.\n\nParameters:\n\n**single\\_visit** – If `True`, non-Token nodes will only be visited once.\n\nvisit\\_token\\_node( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.visit_token_node \"Permalink to this definition\")\n\nCalled when a `Token` is visited. `Token` nodes are always leaves.\n\nvisit\\_symbol\\_node\\_in( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.visit_symbol_node_in \"Permalink to this definition\")\n\nCalled when a symbol node is visited. Nodes that are returned\nwill be scheduled to be visited. If `visit_intermediate_node_in`\nis not implemented, this function will be called for intermediate\nnodes as well.\n\nvisit\\_symbol\\_node\\_out( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.visit_symbol_node_out \"Permalink to this definition\")\n\nCalled after all nodes returned from a corresponding `visit_symbol_node_in`\ncall have been visited. If `visit_intermediate_node_out`\nis not implemented, this function will be called for intermediate\nnodes as well.\n\nvisit\\_packed\\_node\\_in( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.visit_packed_node_in \"Permalink to this definition\")\n\nCalled when a packed node is visited. Nodes that are returned\nwill be scheduled to be visited.\n\nvisit\\_packed\\_node\\_out( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.visit_packed_node_out \"Permalink to this definition\")\n\nCalled after all nodes returned from a corresponding `visit_packed_node_in`\ncall have been visited.\n\non\\_cycle( _node_, _path_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.on_cycle \"Permalink to this definition\")\n\nCalled when a cycle is encountered.\n\nParameters:\n\n- **node** – The node that causes a cycle.\n\n- **path** – The list of nodes being visited: nodes that have been\nentered but not exited. The first element is the root in a forest\nvisit, and the last element is the node visited most recently.\n`path` should be treated as read-only.\n\n\nget\\_cycle\\_in\\_path( _node_, _path_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestVisitor.get_cycle_in_path \"Permalink to this definition\")\n\nA utility function for use in `on_cycle` to obtain a slice of\n`path` that only contains the nodes that make up the cycle.\n\n## ForestTransformer [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#foresttransformer \"Permalink to this heading\")\n\n_class_ lark.parsers.earley\\_forest.ForestTransformer [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestTransformer \"Permalink to this definition\")\n\nThe base class for a bottom-up forest transformation. Most users will\nwant to use `TreeForestTransformer` instead as it has a friendlier\ninterface and covers most use cases.\n\nTransformations are applied via inheritance and overriding of the\n`transform*node` methods.\n\n`transform_token_node` receives a `Token` as an argument.\nAll other methods receive the node that is being transformed and\na list of the results of the transformations of that node’s children.\nThe return value of these methods are the resulting transformations.\n\nIf `Discard` is raised in a node’s transformation, no data from that node\nwill be passed to its parent’s transformation.\n\ntransform( _root_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestTransformer.transform \"Permalink to this definition\")\n\nPerform a transformation on an SPPF.\n\ntransform\\_symbol\\_node( _node_, _data_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestTransformer.transform_symbol_node \"Permalink to this definition\")\n\nTransform a symbol node.\n\ntransform\\_intermediate\\_node( _node_, _data_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestTransformer.transform_intermediate_node \"Permalink to this definition\")\n\nTransform an intermediate node.\n\ntransform\\_packed\\_node( _node_, _data_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestTransformer.transform_packed_node \"Permalink to this definition\")\n\nTransform a packed node.\n\ntransform\\_token\\_node( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.ForestTransformer.transform_token_node \"Permalink to this definition\")\n\nTransform a `Token`.\n\n## TreeForestTransformer [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#treeforesttransformer \"Permalink to this heading\")\n\n_class_ lark.parsers.earley\\_forest.TreeForestTransformer( _tree\\_class=<class'lark.tree.Tree'>_, _prioritizer=<lark.parsers.earley\\_forest.ForestSumVisitorobject>_, _resolve\\_ambiguity=True_, _use\\_cache=False_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.TreeForestTransformer \"Permalink to this definition\")\n\nA `ForestTransformer` with a tree `Transformer`-like interface.\nBy default, it will construct a tree.\n\nMethods provided via inheritance are called based on the rule/symbol\nnames of nodes in the forest.\n\nMethods that act on rules will receive a list of the results of the\ntransformations of the rule’s children. By default, trees and tokens.\n\nMethods that act on tokens will receive a token.\n\nAlternatively, methods that act on rules may be annotated with\n`handles_ambiguity`. In this case, the function will receive a list\nof all the transformations of all the derivations of the rule.\nBy default, a list of trees where each tree.data is equal to the\nrule name or one of its aliases.\n\nNon-tree transformations are made possible by override of\n`__default__`, `__default_token__`, and `__default_ambig__`.\n\nNote\n\nTree shaping features such as inlined rules and token filtering are\nnot built into the transformation. Positions are also not propagated.\n\nParameters:\n\n- **tree\\_class** – The tree class to use for construction\n\n- **prioritizer** – A `ForestVisitor` that manipulates the priorities of nodes in the SPPF.\n\n- **resolve\\_ambiguity** – If True, ambiguities will be resolved based on priorities.\n\n- **use\\_cache** ( _bool_) – If True, caches the results of some transformations,\npotentially improving performance when `resolve_ambiguity==False`.\nOnly use if you know what you are doing: i.e. All transformation\nfunctions are pure and referentially transparent.\n\n\n\\_\\_default\\_\\_( _name_, _data_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.TreeForestTransformer.__default__ \"Permalink to this definition\")\n\nDefault operation on tree (for override).\n\nReturns a tree with name with data as children.\n\n\\_\\_default\\_ambig\\_\\_( _name_, _data_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.TreeForestTransformer.__default_ambig__ \"Permalink to this definition\")\n\nDefault operation on ambiguous rule (for override).\n\nWraps data in an ‘\\_ambig\\_’ node if it contains more than\none element.\n\n\\_\\_default\\_token\\_\\_( _node_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.TreeForestTransformer.__default_token__ \"Permalink to this definition\")\n\nDefault operation on `Token` (for override).\n\nReturns `node`.\n\n## handles\\_ambiguity [](https://lark-parser.readthedocs.io/en/stable/forest.html\\#handles-ambiguity \"Permalink to this heading\")\n\nlark.parsers.earley\\_forest.handles\\_ambiguity( _func_) [](https://lark-parser.readthedocs.io/en/stable/forest.html#lark.parsers.earley_forest.handles_ambiguity \"Permalink to this definition\")\n\nDecorator for methods of subclasses of `TreeForestTransformer`.\nDenotes that the method should receive a list of transformed derivations.\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/forest.html)**[stable](https://lark-parser.readthedocs.io/en/stable/forest.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Working with the SPPF — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/forest.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/forest.html",
        "status_code": 200,
        "scrape_id": "a0fa3dc3-f86b-4551-8488-fa61c6a680b6",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    },
    {
      "url": "https://lark-parser.readthedocs.io/en/stable/examples/calc.html",
      "markdown": "- [Home](https://lark-parser.readthedocs.io/en/stable/index.html)\n- [Examples for Lark](https://lark-parser.readthedocs.io/en/stable/examples/index.html)\n- Basic calculator\n- [Edit on GitHub](https://github.com/lark-parser/lark/blob/acfe33d943a1310f3ca26145eb2896bc5c4955c9/docs/examples/calc.rst)\n\n[Previous](https://lark-parser.readthedocs.io/en/stable/examples/fruitflies.html \"Handling Ambiguity\") [Next](https://lark-parser.readthedocs.io/en/stable/examples/turtle_dsl.html \"Turtle DSL\")\n\n* * *\n\nNote\n\n[Go to the end](https://lark-parser.readthedocs.io/en/stable/examples/calc.html#sphx-glr-download-examples-calc-py)\nto download the full example code\n\n# Basic calculator [](https://lark-parser.readthedocs.io/en/stable/examples/calc.html\\#basic-calculator \"Permalink to this heading\")\n\nA simple example of a REPL calculator\n\nThis example shows how to write a basic calculator with variables.\n\n```\nfrom lark import Lark, Transformer, v_args\n\ntry:\n    input = raw_input   # For Python2 compatibility\nexcept NameError:\n    pass\n\ncalc_grammar = \"\"\"\n    ?start: sum\n          | NAME \"=\" sum    -> assign_var\n\n    ?sum: product\n        | sum \"+\" product   -> add\n        | sum \"-\" product   -> sub\n\n    ?product: atom\n        | product \"*\" atom  -> mul\n        | product \"/\" atom  -> div\n\n    ?atom: NUMBER           -> number\n         | \"-\" atom         -> neg\n         | NAME             -> var\n         | \"(\" sum \")\"\n\n    %import common.CNAME -> NAME\n    %import common.NUMBER\n    %import common.WS_INLINE\n\n    %ignore WS_INLINE\n\"\"\"\n\n@v_args(inline=True)    # Affects the signatures of the methods\nclass CalculateTree(Transformer):\n    from operator import add, sub, mul, truediv as div, neg\n    number = float\n\n    def __init__(self):\n        self.vars = {}\n\n    def assign_var(self, name, value):\n        self.vars[name] = value\n        return value\n\n    def var(self, name):\n        try:\n            return self.vars[name]\n        except KeyError:\n            raise Exception(\"Variable not found: %s\" % name)\n\ncalc_parser = Lark(calc_grammar, parser='lalr', transformer=CalculateTree())\ncalc = calc_parser.parse\n\ndef main():\n    while True:\n        try:\n            s = input('> ')\n        except EOFError:\n            break\n        print(calc(s))\n\ndef test():\n    print(calc(\"a = 1+2\"))\n    print(calc(\"1+a*-3\"))\n\nif __name__ == '__main__':\n    # test()\n    main()\n\n```\n\n**Total running time of the script:** (0 minutes 0.000 seconds)\n\n[`Download Python source code: calc.py`](https://lark-parser.readthedocs.io/en/stable/_downloads/50b59008a60a728670b293084a6fe042/calc.py)\n\n[`Download Jupyter notebook: calc.ipynb`](https://lark-parser.readthedocs.io/en/stable/_downloads/63680f346bf793a45964b4e687bde3d9/calc.ipynb)\n\n[Gallery generated by Sphinx-Gallery](https://sphinx-gallery.github.io/)\n\nVersions[latest](https://lark-parser.readthedocs.io/en/latest/examples/calc.html)**[stable](https://lark-parser.readthedocs.io/en/stable/examples/calc.html)**Downloads[PDF](https://lark-parser.readthedocs.io/_/downloads/en/stable/pdf/)[HTML](https://lark-parser.readthedocs.io/_/downloads/en/stable/htmlzip/)[EPUB](https://lark-parser.readthedocs.io/_/downloads/en/stable/epub/)On Read the Docs[Project Home](https://app.readthedocs.org/projects/lark-parser/?utm_source=lark-parser&utm_content=flyout)[Builds](https://app.readthedocs.org/projects/lark-parser/builds/?utm_source=lark-parser&utm_content=flyout)Search\n\n* * *\n\n[Addons documentation](https://docs.readthedocs.io/page/addons.html?utm_source=lark-parser&utm_content=flyout) ― Hosted by\n[Read the Docs](https://about.readthedocs.com/?utm_source=lark-parser&utm_content=flyout)",
      "metadata": {
        "title": "Basic calculator — Lark  documentation",
        "url": "https://lark-parser.readthedocs.io/en/stable/examples/calc.html",
        "language": "en",
        "source_url": "https://lark-parser.readthedocs.io/en/stable/examples/calc.html",
        "status_code": 200,
        "scrape_id": "b09462fc-26ef-46a8-83cd-bbe734518fe7",
        "content_type": "text/html; charset=utf-8",
        "proxy_used": "basic",
        "cache_state": "hit",
        "cached_at": "2025-09-17T15:42:00.521Z",
        "credits_used": 1
      }
    }
  ],
  "follow_up_documents": [],
  "llm_decisions": [],
  "skipped_urls": [],
  "triage_runs": [],
  "prefix_suppressions": [],
  "key_map": {}
}